<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Chu Xing</title><link>https://xzygis.github.io/</link><description>Recent content on Chu Xing</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Sat, 03 Dec 2022 19:21:25 +0800</lastBuildDate><atom:link href="https://xzygis.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>About</title><link>https://xzygis.github.io/about/</link><pubDate>Thu, 03 Dec 2020 21:38:52 +0800</pubDate><guid>https://xzygis.github.io/about/</guid><description>&lt;p>Hugo is a static site engine written in Go.&lt;/p>
&lt;p>It makes use of a variety of open source projects including:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/spf13/cobra">Cobra&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/spf13/viper">Viper&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/spf13/jWalterWeatherman">J Walter Weatherman&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/spf13/cast">Cast&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Learn more and contribute on &lt;a href="https://github.com/gohugoio">GitHub&lt;/a>.&lt;/p></description></item><item><title>Hugo Quick Start</title><link>https://xzygis.github.io/2022/12/03/hugo-quick-start/</link><pubDate>Sat, 03 Dec 2022 19:21:25 +0800</pubDate><guid>https://xzygis.github.io/2022/12/03/hugo-quick-start/</guid><description>&lt;h1 id="intall">Intall&lt;/h1>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>go install github.com/gohugoio/hugo@latest
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="quick-start">Quick Start&lt;/h1>
&lt;blockquote>
&lt;p>&lt;a href="https://gohugo.io/getting-started/quick-start/">https://gohugo.io/getting-started/quick-start/&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>运行以下命令创建一个使用&lt;code>Ananke&lt;/code>主题的网站：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>hugo new site quickstart
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>cd quickstart
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>git init
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>git submodule add https://github.com/theNewDynamic/gohugo-theme-ananke themes/ananke
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>echo &lt;span style="color:#e6db74">&amp;#34;theme = &amp;#39;ananke&amp;#39;&amp;#34;&lt;/span> &amp;gt;&amp;gt; config.toml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hugo server
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="add-content">Add Content&lt;/h1>
&lt;p>给网站增加新的网页：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>hugo new posts/my-first-post.md
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Hugo在&lt;code>content/posts&lt;/code>目录创建了&lt;code>my-first-post.md&lt;/code>文件，文件内容如下：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>title: &lt;span style="color:#e6db74">&amp;#34;My First Post&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>date: 2022-11-20T09:03:20-08:00
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>draft: true
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>修改并保存文件后启动Hugo服务器可以预览网站，可以使用以下的任一命令以包含draft内容：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>hugo server --buildDrafts
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hugo server -D
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="configure-the-site">Configure the site&lt;/h1>
&lt;p>可以通过根目录的&lt;code>config.toml&lt;/code>文件配置网站相关信息：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>baseURL &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;http://example.org/&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>languageCode &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;en-us&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>title &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;My New Hugo Site&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>theme &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;ananke&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="publish-the-site">Publish the site&lt;/h1>
&lt;p>生成站点的静态文件，文件将生成到根目录下的&lt;code>public&lt;/code>目录&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>hugo
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="host-on-github">Host on GitHub&lt;/h1>
&lt;blockquote>
&lt;p>&lt;a href="https://gohugo.io/hosting-and-deployment/hosting-on-github/">https://gohugo.io/hosting-and-deployment/hosting-on-github/&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;ol>
&lt;li>创建名为&lt;code>&amp;lt;USERNAME&amp;gt;.github.io&lt;/code> 或 &lt;code>&amp;lt;ORGANIZATION&amp;gt;.github.io&lt;/code>的GitHub仓库&lt;/li>
&lt;li>在仓库中新增文件&lt;code>.github/workflows/gh-pages.yml&lt;/code>并填写以下内容：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">github pages&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">on&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">push&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">branches&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">main &lt;/span> &lt;span style="color:#75715e"># Set a branch that will trigger a deployment&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">pull_request&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">jobs&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">deploy&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">runs-on&lt;/span>: &lt;span style="color:#ae81ff">ubuntu-22.04&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">steps&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">uses&lt;/span>: &lt;span style="color:#ae81ff">actions/checkout@v3&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">with&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">submodules&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span> &lt;span style="color:#75715e"># Fetch Hugo themes (true OR recursive)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">fetch-depth&lt;/span>: &lt;span style="color:#ae81ff">0&lt;/span> &lt;span style="color:#75715e"># Fetch all history for .GitInfo and .Lastmod&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Setup Hugo&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">uses&lt;/span>: &lt;span style="color:#ae81ff">peaceiris/actions-hugo@v2&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">with&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">hugo-version&lt;/span>: &lt;span style="color:#e6db74">&amp;#39;latest&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># extended: true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Build&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">run&lt;/span>: &lt;span style="color:#ae81ff">hugo --minify&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Deploy&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">uses&lt;/span>: &lt;span style="color:#ae81ff">peaceiris/actions-gh-pages@v3&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">if&lt;/span>: &lt;span style="color:#ae81ff">github.ref == &amp;#39;refs/heads/main&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">with&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">github_token&lt;/span>: &lt;span style="color:#ae81ff">${{ secrets.GITHUB_TOKEN }}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">publish_dir&lt;/span>: &lt;span style="color:#ae81ff">./public&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>把&lt;code>config.toml&lt;/code>中的&lt;code>baseURL&lt;/code>修改为&lt;code>https://&amp;lt;USERNAME&amp;gt;.github.io&lt;/code>。&lt;/p>
&lt;p>Ref：&lt;/p>
&lt;ol>
&lt;li>&lt;a href="https://github.com/gohugoio/hugo">https://github.com/gohugoio/hugo&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.xianmin.org/post/2022/07-familiar-one-keybinding-style/">https://www.xianmin.org/post/2022/07-familiar-one-keybinding-style/&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>Redis底层数据结构介绍</title><link>https://xzygis.github.io/2022/11/30/redis%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%BB%8B%E7%BB%8D/</link><pubDate>Wed, 30 Nov 2022 22:03:21 +0000</pubDate><guid>https://xzygis.github.io/2022/11/30/redis%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%BB%8B%E7%BB%8D/</guid><description>&lt;h1 id="简单动态字符串">简单动态字符串&lt;/h1>
&lt;p>每个sds.h/sdshdr结构表示一个SDS值：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-c" data-lang="c">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">struct&lt;/span> sdshdr {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//记录buf数组中已使用字节的数量
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#75715e">//等于SDS所保存字符串的长度
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">int&lt;/span> len;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//记录buf数组中未使用字节的数量
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">int&lt;/span> free;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//字节数组，用于保存字符串
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">char&lt;/span> buf[];
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>};
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="sds与c字符串的区别">SDS与C字符串的区别&lt;/h2>
&lt;ul>
&lt;li>常数时间复杂度获取字符串长度&lt;/li>
&lt;li>杜绝缓冲区溢出&lt;/li>
&lt;li>减少修改字符串带来的内存重分配次数（空间预分配、惰性空间释放）&lt;/li>
&lt;li>二进制安全&lt;/li>
&lt;li>兼容部分C字符串函数&lt;/li>
&lt;/ul>
&lt;!-- raw HTML omitted -->
&lt;h1 id="链表">链表&lt;/h1>
&lt;p>当一个列表键包含了数量比较多的元素，又或者列表中包含的元素都是比较长的字符串时，Redis就会使用链表作为列表键的底层实现。&lt;/p>
&lt;p>每个链表节点使用一个adlist.h/listNode结构来表示：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-c" data-lang="c">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">typedef&lt;/span> &lt;span style="color:#66d9ef">struct&lt;/span> listNode {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// 前置节点
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">struct&lt;/span> listNode &lt;span style="color:#f92672">*&lt;/span> prev;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// 后置节点
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">struct&lt;/span> listNode &lt;span style="color:#f92672">*&lt;/span> next;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//节点的值
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#f92672">*&lt;/span> value;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}listNode;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>每个链表节点由一个listNode结构来表示，每个节点都有一个指向前置节点和后置节点的指针，所以Redis的链表实现是双端链表。
每个链表使用一个list结构来表示，这个结构带有表头节点指针、表尾节点指针，以及链表长度等信息。
因为链表表头节点的前置节点和表尾节点的后置节点都指向NULL，所以Redis的链表实现是无环链表。&lt;/p>
&lt;p>虽然仅仅使用多个listNode结构就可以组成链表，但使用adlist.h/list来持有链表的话，操作起来会更方便：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-c" data-lang="c">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">typedef&lt;/span> &lt;span style="color:#66d9ef">struct&lt;/span> list {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">表头节点&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> listNode &lt;span style="color:#f92672">*&lt;/span> head;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">表尾节点&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> listNode &lt;span style="color:#f92672">*&lt;/span> tail;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">链表所包含的节点数量&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">unsigned&lt;/span> &lt;span style="color:#66d9ef">long&lt;/span> len;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">节点值复制函数&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#f92672">*&lt;/span>(&lt;span style="color:#f92672">*&lt;/span>dup)(&lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#f92672">*&lt;/span>ptr);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">节点值释放函数&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">void&lt;/span> (&lt;span style="color:#f92672">*&lt;/span>free)(&lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#f92672">*&lt;/span>ptr);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">节点值对比函数&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">int&lt;/span> (&lt;span style="color:#f92672">*&lt;/span>match)(&lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#f92672">*&lt;/span>ptr,&lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#f92672">*&lt;/span>key);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>} list;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>通过为链表设置不同的类型特定函数，Redis的链表可以用于保存各种不同类型的值。&lt;/p>
&lt;h1 id="字典">字典&lt;/h1>
&lt;p>字典，又称为符号表（symbol table）、关联数组（associative array）或映射（map），是一种用于保存键值对（key-value pair）的抽象数据结构。&lt;/p>
&lt;p>当一个哈希键包含的键值对比较多，又或者键值对中的元素都是比较长的字符串时，Redis就会使用字典作为哈希键的底层实现。&lt;/p>
&lt;p>Redis字典所使用的哈希表由dict.h/dictht结构定义：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-c" data-lang="c">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">typedef&lt;/span> &lt;span style="color:#66d9ef">struct&lt;/span> dictht {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//哈希表数组
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> dictEntry &lt;span style="color:#f92672">**&lt;/span>table;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//哈希表大小
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">unsigned&lt;/span> &lt;span style="color:#66d9ef">long&lt;/span> size;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//哈希表大小掩码，用于计算索引值
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#75715e">//总是等于size-1
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">unsigned&lt;/span> &lt;span style="color:#66d9ef">long&lt;/span> sizemask;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//该哈希表已有节点的数量
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">unsigned&lt;/span> &lt;span style="color:#66d9ef">long&lt;/span> used;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>} dictht;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>table属性是一个数组，数组中的每个元素都是一个指向dict.h/dictEntry结构的指针，每个dictEntry结构保存着一个键值对。size属性记录了哈希表的大小，也即是table数组的大小，而used属性则记录了哈希表目前已有节点（键值对）的数量。sizemask属性的值总是等于size-1，这个属性和哈希值一起决定一个键应该被放到table数组的哪个索引上面。&lt;/p>
&lt;p>哈希表节点使用dictEntry结构表示，每个dictEntry结构都保存着一个键值对：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-c" data-lang="c">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">typedef&lt;/span> &lt;span style="color:#66d9ef">struct&lt;/span> dictEntry {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//键
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#f92672">*&lt;/span>key;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//值
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">union&lt;/span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#f92672">*&lt;/span>val;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> uint64_tu64;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> int64_ts64;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> } v;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//指向下个哈希表节点，形成链表
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">struct&lt;/span> dictEntry &lt;span style="color:#f92672">*&lt;/span>next;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>} dictEntry;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>key属性保存着键值对中的键，而v属性则保存着键值对中的值，其中键值对的值可以是一个指针，或者是一个uint64_t整数，又或者是一个int64_t整数。next属性是指向另一个哈希表节点的指针，这个指针可以将多个哈希值相同的键值对连接在一次，以此来解决键冲突（collision）的问题。&lt;/p>
&lt;p>Redis中的字典由dict.h/dict结构表示：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-c" data-lang="c">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">typedef&lt;/span> &lt;span style="color:#66d9ef">struct&lt;/span> dict {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//类型特定函数
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> dictType &lt;span style="color:#f92672">*&lt;/span>type;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//私有数据
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#f92672">*&lt;/span>privdata;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//哈希表
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> dictht ht[&lt;span style="color:#ae81ff">2&lt;/span>];
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// rehash索引
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#75715e">//当rehash不在进行时，值为-1
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> in trehashidx; &lt;span style="color:#75715e">/* rehashing not in progress if rehashidx == -1 */&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>} dict;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>type属性和privdata属性是针对不同类型的键值对，为创建多态字典而设置的：&lt;/p>
&lt;ul>
&lt;li>type属性是一个指向dictType结构的指针，每个dictType结构保存了一簇用于操作特定类型键值对的函数，Redis会为用途不同的字典设置不同的类型特定函数。&lt;/li>
&lt;li>而privdata属性则保存了需要传给那些类型特定函数的可选参数。&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-c" data-lang="c">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">typedef&lt;/span> &lt;span style="color:#66d9ef">struct&lt;/span> dictType {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//计算哈希值的函数
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">unsigned&lt;/span> &lt;span style="color:#66d9ef">int&lt;/span> (&lt;span style="color:#f92672">*&lt;/span>hashFunction)(&lt;span style="color:#66d9ef">const&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#f92672">*&lt;/span>key);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//复制键的函数
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#f92672">*&lt;/span>(&lt;span style="color:#f92672">*&lt;/span>keyDup)(&lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#f92672">*&lt;/span>privdata, &lt;span style="color:#66d9ef">const&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#f92672">*&lt;/span>key);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//复制值的函数
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#f92672">*&lt;/span>(&lt;span style="color:#f92672">*&lt;/span>valDup)(&lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#f92672">*&lt;/span>privdata, &lt;span style="color:#66d9ef">const&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#f92672">*&lt;/span>obj);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//对比键的函数
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">int&lt;/span> (&lt;span style="color:#f92672">*&lt;/span>keyCompare)(&lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#f92672">*&lt;/span>privdata, &lt;span style="color:#66d9ef">const&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#f92672">*&lt;/span>key1, &lt;span style="color:#66d9ef">const&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#f92672">*&lt;/span>key2);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//销毁键的函数
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> (&lt;span style="color:#f92672">*&lt;/span>keyDestructor)(&lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#f92672">*&lt;/span>privdata, &lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#f92672">*&lt;/span>key);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//销毁值的函数
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> (&lt;span style="color:#f92672">*&lt;/span>valDestructor)(&lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#f92672">*&lt;/span>privdata, &lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#f92672">*&lt;/span>obj);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>} dictType;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>ht属性是一个包含两个项的数组，数组中的每个项都是一个dictht哈希表，一般情况下，字典只使用ht[0]哈希表，ht[1]哈希表只会在对ht[0]哈希表进行rehash时使用。除了ht[1]之外，另一个和rehash有关的属性就是rehashidx，它记录了rehash目前的进度，如果目前没有在进行rehash，那么它的值为-1。&lt;/p>
&lt;p>当要将一个新的键值对添加到字典里面时，程序需要先根据键值对的键计算出哈希值和索引值，然后再根据索引值，将包含新键值对的哈希表节点放到哈希表数组的指定索引上面。&lt;/p>
&lt;p>Redis计算哈希值和索引值的方法如下：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-c" data-lang="c">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">#使用字典设置的哈希函数，计算键key的哈希值
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>hash &lt;span style="color:#f92672">=&lt;/span> dict&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">＞&lt;/span>type&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">＞&lt;/span>&lt;span style="color:#a6e22e">hashFunction&lt;/span>(key);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">#使用哈希表的sizemask属性和哈希值，计算出索引值
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">#根据情况不同，ht[x]可以是ht[0]或者ht[1]
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>index &lt;span style="color:#f92672">=&lt;/span> hash &lt;span style="color:#f92672">&amp;amp;&lt;/span> dict&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">＞&lt;/span>ht[x].sizemask;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Redis的哈希表使用链地址法（separate chaining）来解决键冲突，每个哈希表节点都有一个next指针，多个哈希表节点可以用next指针构成一个单向链表，被分配到同一个索引上的多个节点可以用这个单向链表连接起来，这就解决了键冲突的问题。&lt;/p>
&lt;h2 id="rehash">rehash&lt;/h2>
&lt;p>根据BGSAVE命令或BGREWRITEAOF命令是否正在执行，服务器执行扩展操作所需的负载因子并不相同，这是因为在执行BGSAVE命令或BGREWRITEAOF命令的过程中，Redis需要创建当前服务器进程的子进程，而大多数操作系统都采用写时复制（copy-on-write）技术来优化子进程的使用效率，所以在子进程存在期间，服务器会提高执行扩展操作所需的负载因子，从而尽可能地避免在子进程存在期间进行哈希表扩展操作，这可以避免不必要的内存写入操作，最大限度地节约内存。&lt;/p>
&lt;p>为了避免rehash对服务器性能造成影响，服务器不是一次性将ht[0]里面的所有键值对全部rehash到ht[1]，而是分多次、渐进式地将ht[0]里面的键值对慢慢地rehash到ht[1]。&lt;/p>
&lt;p>哈希表渐进式rehash的详细步骤：&lt;/p>
&lt;ul>
&lt;li>为ht[1]分配空间，让字典同时持有ht[0]和ht[1]两个哈希表。&lt;/li>
&lt;li>在字典中维持一个索引计数器变量rehashidx，并将它的值设置为0，表示rehash工作正式开始。&lt;/li>
&lt;li>在rehash进行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作以外，还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]，当rehash工作完成之后，程序将rehashidx属性的值增一。&lt;/li>
&lt;li>随着字典操作的不断执行，最终在某个时间点上，ht[0]的所有键值对都会被rehash至ht[1]，这时程序将rehashidx属性的值设为-1，表示rehash操作已完成。渐进式rehash的好处在于它采取分而治之的方式，将rehash键值对所需的计算工作均摊到对字典的每个添加、删除、查找和更新操作上，从而避免了集中式rehash而带来的庞大计算量。&lt;/li>
&lt;/ul>
&lt;p>因为在进行渐进式rehash的过程中，字典会同时使用ht[0]和ht[1]两个哈希表，所以在渐进式rehash进行期间，字典的删除（delete）、查找（find）、更新（update）等操作会在两个哈希表上进行。例如，要在字典里面查找一个键的话，程序会先在ht[0]里面进行查找，如果没找到的话，就会继续到ht[1]里面进行查找，诸如此类。&lt;/p>
&lt;p>另外，在渐进式rehash执行期间，新添加到字典的键值对一律会被保存到ht[1]里面，而ht[0]则不再进行任何添加操作，这一措施保证了ht[0]包含的键值对数量会只减不增，并随着rehash操作的执行而最终变成空表。&lt;/p>
&lt;h1 id="跳跃表">跳跃表&lt;/h1>
&lt;p>跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。跳跃表支持平均O（logN）、最坏O（N）复杂度的节点查找，还可以通过顺序性操作来批量处理节点。在大部分情况下，跳跃表的效率可以和平衡树相媲美，并且因为跳跃表的实现比平衡树要来得更为简单，所以有不少程序都使用跳跃表来代替平衡树。Redis使用跳跃表作为有序集合键的底层实现之一，如果一个有序集合包含的元素数量比较多，又或者有序集合中元素的成员（member）是比较长的字符串时，Redis就会使用跳跃表来作为有序集合键的底层实现。&lt;/p>
&lt;p>跳跃表节点的实现由redis.h/zskiplistNode结构定义：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-c" data-lang="c">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">typedef&lt;/span> &lt;span style="color:#66d9ef">struct&lt;/span> zskiplistNode {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//层
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">struct&lt;/span> zskiplistLevel {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//前进指针
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">struct&lt;/span> zskiplistNode &lt;span style="color:#f92672">*&lt;/span>forward;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//跨度
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">unsigned&lt;/span> &lt;span style="color:#66d9ef">int&lt;/span> span;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> } level[];
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//后退指针
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">struct&lt;/span> zskiplistNode &lt;span style="color:#f92672">*&lt;/span>backward;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//分值
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">double&lt;/span> score;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//成员对象
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> robj &lt;span style="color:#f92672">*&lt;/span>obj;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>} zskiplistNode;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>每次创建一个新跳跃表节点的时候，程序都根据幂次定律（power law，越大的数出现的概率越小）随机生成一个介于1和32之间的值作为level数组的大小，这个大小就是层的“高度”。&lt;/p>
&lt;p>跨度（span）实际上是用来计算排位（rank）的：在查找某个节点的过程中，将沿途访问过的所有层的跨度累计起来，得到的结果就是目标节点在跳跃表中的排位。&lt;/p>
&lt;p>节点的后退指针（backward属性）用于从表尾向表头方向访问节点：跟可以一次跳过多个节点的前进指针不同，因为每个节点只有一个后退指针，所以每次只能后退至前一个节点。&lt;/p>
&lt;p>zskiplist结构的定义如下：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-c" data-lang="c">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">typedef&lt;/span> &lt;span style="color:#66d9ef">struct&lt;/span> zskiplist {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//表头节点和表尾节点
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> structz skiplistNode &lt;span style="color:#f92672">*&lt;/span>header, &lt;span style="color:#f92672">*&lt;/span>tail;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//表中节点的数量
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">unsigned&lt;/span> &lt;span style="color:#66d9ef">long&lt;/span> length;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//表中层数最大的节点的层数
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">int&lt;/span> level;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>} zskiplist;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="整数集合">整数集合&lt;/h1>
&lt;p>整数集合（intset）是集合键的底层实现之一，当一个集合只包含整数值元素，并且这个集合的元素数量不多时，Redis就会使用整数集合作为集合键的底层实现。&lt;/p>
&lt;p>每个intset.h/intset结构表示一个整数集合：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-c" data-lang="c">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">typedef&lt;/span> &lt;span style="color:#66d9ef">struct&lt;/span> intset {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//编码方式
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">uint32_t&lt;/span> encoding;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//集合包含的元素数量
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">uint32_t&lt;/span> length;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//保存元素的数组
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">int8_t&lt;/span> contents[];
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>} intset;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>contents数组是整数集合的底层实现：整数集合的每个元素都是contents数组的一个数组项（item），各个项在数组中按值的大小从小到大有序地排列，并且数组中不包含任何重复项。&lt;/p>
&lt;p>因为引发升级的新元素的长度总是比整数集合现有所有元素的长度都大，所以这个新元素的值要么就大于所有现有元素，要么就小于所有现有元素：&lt;/p>
&lt;p>要让一个数组可以同时保存int16_t、int32_t、int64_t三种类型的值，最简单的做法就是直接使用int64_t类型的数组作为整数集合的底层实现。不过这样一来，即使添加到整数集合里面的都是int16_t类型或者int32_t类型的值，数组都需要使用int64_t类型的空间去保存它们，从而出现浪费内存的情况。而整数集合现在的做法既可以让集合能同时保存三种不同类型的值，又可以确保升级操作只会在有需要的时候进行，这可以尽量节省内存。&lt;/p>
&lt;p>整数集合不支持降级操作，一旦对数组进行了升级，编码就会一直保持升级后的状态。&lt;/p>
&lt;h1 id="压缩列表">压缩列表&lt;/h1>
&lt;p>压缩列表（ziplist）是列表键和哈希键的底层实现之一。当一个列表键只包含少量列表项，并且每个列表项要么就是小整数值，要么就是长度比较短的字符串，那么Redis就会使用压缩列表来做列表键的底层实现。&lt;/p>
&lt;p>压缩列表是Redis为了节约内存而开发的，是由一系列特殊编码的连续内存块组成的顺序型（sequential）数据结构。一个压缩列表可以包含任意多个节点（entry），每个节点可以保存一个字节数组或者一个整数值。&lt;/p>
&lt;p>ziplist的组成部分：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>| zlbytes | ztail | zlen | entry1 | entry2 | ... | entryN | zlend |
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>每个压缩列表节点都由previous_entry_length、encoding、content三个部分组成:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>| previous_entry_length | encoding | content |
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>添加新节点到压缩列表，或者从压缩列表中删除节点，可能会引发连锁更新操作，但这种操作出现的几率并不高。&lt;/p>
&lt;p>尽管连锁更新的复杂度较高，但它真正造成性能问题的几率是很低的：&lt;/p>
&lt;ul>
&lt;li>首先，压缩列表里要恰好有多个连续的、长度介于250字节至253字节之间的节点，连锁更新才有可能被引发，在实际中，这种情况并不多见；-&lt;/li>
&lt;li>其次，即使出现连锁更新，但只要被更新的节点数量不多，就不会对性能造成任何影响：比如说，对三五个节点进行连锁更新是绝对不会影响性能的；&lt;/li>
&lt;/ul></description></item><item><title>Tair:分布式键/值存储系统</title><link>https://xzygis.github.io/2022/11/27/tair%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%AE/%E5%80%BC%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/</link><pubDate>Sun, 27 Nov 2022 23:11:28 +0000</pubDate><guid>https://xzygis.github.io/2022/11/27/tair%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%AE/%E5%80%BC%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/</guid><description>&lt;h1 id="产品概览">产品概览&lt;/h1>
&lt;p>Tair 是快速访问内存 (MDB)/持久性 (LDB) 存储服务。&lt;/p>
&lt;p>Tair采用高性能、高可用的分布式集群架构，可以满足企业对读写性能和可扩展容量的高要求。&lt;/p>
&lt;h1 id="系统架构">系统架构&lt;/h1>
&lt;p>Tair 集群具有三个必要的模块：ConfigServer、DataServer 和客户端。&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>&lt;img src="tair_structure.jpg" alt="Architecture">&lt;/p>
&lt;p>通常，一个 Tair 集群包括两个 ConfigServer 和多个 DataServer。 两个 ConfigServer 充当主服务器和备用服务器。 DataServer 和 ConfigServer 之间的心跳检查用于检查集群中活跃的和可用的 DataServer，以建立集群中数据的分布（比较表）。 DataServers 按照 ConfigServer 的指示存储、复制和迁移数据。当客户端启动时，它从 ConfigServer 获取数据分布信息。客户端根据这些数据分布信息，与对应的DataServer进行交互，执行用户的请求。&lt;/p>
&lt;p>在架构上，ConfigServer 的作用类似于传统应用系统中的中心节点。整个集群服务依赖于ConfigServer。 事实上，Tair 的 ConfigServers 是非常轻量级的。当一个工作的 ConfigServer 遇到停机时间时，另一个 ConfigServer 会在几秒钟内自动接管。 即使两个 ConfigServer 同时停机，只要 DataServer 没有变化，Tair 也可以正常运行。 用户只需要将应用程序连接到 ConfigServers，不需要知道内部节点的详细信息。&lt;/p>
&lt;h2 id="configserver">ConfigServer&lt;/h2>
&lt;p>两个 ConfigServers 作为主服务器和备用服务器。&lt;/p>
&lt;p>集群的实时和可用 DataServer 节点信息是使用 ConfigServer 和 DataServer 之间的心跳检查确定的。&lt;/p>
&lt;p>ConfigServer根据DataServer节点信息构建数据分布表，展示数据在集群中的分布情况。&lt;/p>
&lt;p>ConfigServer 提供数据分发表查询服务。&lt;/p>
&lt;p>ConfigServer 调度数据服务器之间的数据迁移和复制。&lt;/p>
&lt;h2 id="dataservers-数据服务器">DataServers 数据服务器&lt;/h2>
&lt;p>DataServers 提供存储引擎。&lt;/p>
&lt;p>DataServers 接收客户端发起的操作，例如 put/get/remove。&lt;/p>
&lt;p>DataServers 迁移和复制数据。&lt;/p>
&lt;p>DataServers 提供访问统计信息。&lt;/p>
&lt;h2 id="clients-客户端">Clients 客户端&lt;/h2>
&lt;p>客户端提供用于访问 Tair 集群的 API。&lt;/p>
&lt;p>客户端更新和缓存数据分发表。&lt;/p>
&lt;p>客户端提供LocalCache，防止过热的数据访问影响Tair集群服务。&lt;/p>
&lt;p>客户端控制流量。&lt;/p>
&lt;h1 id="产品特点">产品特点&lt;/h1>
&lt;h2 id="分布式架构">分布式架构&lt;/h2>
&lt;p>分布式集群架构用于提供自动灾难恢复和故障转移。&lt;/p>
&lt;p>支持负载均衡，数据分布均匀。&lt;/p>
&lt;p>系统存储空间和吞吐量性能可以弹性伸缩，解决数据量和QPS性能限制。&lt;/p>
&lt;p>功能齐全且用户友好的访问&lt;/p>
&lt;p>数据结构丰富。 支持单级键值结构和二级索引结构。&lt;/p>
&lt;p>支持各种用途。 还支持计数器模式。&lt;/p>
&lt;p>支持数据过期和版本控制。&lt;/p>
&lt;h2 id="version-支持">Version 支持&lt;/h2>
&lt;p>Tair 中的每个数据都包含版本号，版本号在每次更新后都会递增。这个特性有助于防止由于数据的并发更新导致的问题。&lt;/p>
&lt;p>比如，系统有一个 value 为 “a,b,c”，A 和 B 同时 get 到这个 value。A 执行操作，在后面添加一个 d，value 为 “a,b,c,d”。B 执行操作添加一个 e，value 为”a,b,c,e”。如果不加控制，无论 A 和 B 谁先更新成功，它的更新都会被后到的更新覆盖。&lt;/p>
&lt;p>Tair 无法解决这个问题，但是引入了 version 机制避免这样的问题。还是拿刚才的例子，A 和 B 取到数据，假设版本号为 10，A 先更新，更新成功后，value 为”a,b,c,d”，与此同时，版本号会变为 11。当 B 更新时，由于其基于的版本号是 10，服务器会拒绝更新，从而避免 A 的更新被覆盖。B 可以选择 get 新版本的 value，然后在其基础上修改，也可以选择强行更新。&lt;/p>
&lt;h2 id="item-支持">Item 支持&lt;/h2>
&lt;p>Tair 还支持将 value 视为一个 item 数组，对 value 中的部分 item 进行操作。比如有个 key 的 value 为 [1,2,3,4,5]，我们可以只获取前两个 item，返回 [1,2]，也可以删除第一个 item，还支持将数据删除，并返回被删除的数据，通过这个接口可以实现一个原子的分布式 FIFO 的队列。&lt;/p>
&lt;h1 id="用途">用途&lt;/h1>
&lt;h2 id="数据库缓存">数据库缓存&lt;/h2>
&lt;p>随着业务量的增加，对数据库系统的并发请求越来越多，数据库系统的负载越来越重。当数据库系统过载时，响应速度会变慢，在极端情况下甚至会导致服务中断。&lt;/p>
&lt;p>为了解决这个问题，Tair MDB 可以与数据库产品一起部署，以提供高吞吐量和低延迟的存储。&lt;/p>
&lt;p>MDB 响应速度快，一般毫秒级完成请求。而且，MDB 支持更高的 QPS 速率，可以处理比数据库更多的并发请求。&lt;/p>
&lt;p>通过观察业务，用户可以将热点数据存储在MDB中，显着减轻数据库的负载。这不仅降低了数据库成本，还提高了系统可用性。&lt;/p>
&lt;h2 id="临时数据存储">临时数据存储&lt;/h2>
&lt;p>社交网站、电商网站、游戏、广告等应用需要维护大量的临时数据。&lt;/p>
&lt;p>在 MDB 中存储临时数据可以减少内存管理开销和应用程序负载。在分布式环境中，MDB可以作为统一的全局存储，可以防止单点故障造成的数据丢失，解决多个应用之间同步的问题。&lt;/p>
&lt;p>一个常见的例子是使用 MDB 作为会话管理器。如果网站采用分布式部署，并且流量很大，同一用户的不同请求可能会发送到不同的Web服务器。&lt;/p>
&lt;p>在这种情况下，MDB 可以作为全局存储解决方案来保存会话数据、用户令牌、权限信息等数据。&lt;/p>
&lt;h2 id="数据存储">数据存储&lt;/h2>
&lt;p>推荐和广告业务通常需要离线计算大量数据。 LDB 支持持久存储并提供卓越的性能。&lt;/p>
&lt;p>支持在线服务，允许用户定期将离线数据导入LDB进行在线服务。&lt;/p>
&lt;p>经过计算，列表业务可以将最终列表存储在LDB中，直接展示给前端应用程序。&lt;/p>
&lt;p>这样，LDB 就满足了存储和高速访问的需求。&lt;/p>
&lt;h2 id="黑名单白名单">黑名单/白名单&lt;/h2>
&lt;p>安全应用程序有许多黑名单/白名单方案。这些黑名单/白名单场景的特点是命中率低、访问量大、数据丢失导致业务损失。&lt;/p>
&lt;p>LDB 支持数据持久化和高访问量，因此在这些场景中被广泛使用。&lt;/p>
&lt;h2 id="分布式锁">分布式锁&lt;/h2>
&lt;p>分布式锁通常用于防止多线程并发导致的数据不一致和逻辑混乱。分布式锁可以使用 Tair 的版本特性或计算功能来实现。&lt;/p>
&lt;p>得益于LBS的持久化，即使服务宕机，锁也不会丢失，可以正常释放。&lt;/p></description></item><item><title>程序员做需求时容易忽视的若干问题</title><link>https://xzygis.github.io/2022/11/20/%E7%A8%8B%E5%BA%8F%E5%91%98%E5%81%9A%E9%9C%80%E6%B1%82%E6%97%B6%E5%AE%B9%E6%98%93%E5%BF%BD%E8%A7%86%E7%9A%84%E8%8B%A5%E5%B9%B2%E9%97%AE%E9%A2%98/</link><pubDate>Sun, 20 Nov 2022 23:33:08 +0000</pubDate><guid>https://xzygis.github.io/2022/11/20/%E7%A8%8B%E5%BA%8F%E5%91%98%E5%81%9A%E9%9C%80%E6%B1%82%E6%97%B6%E5%AE%B9%E6%98%93%E5%BF%BD%E8%A7%86%E7%9A%84%E8%8B%A5%E5%B9%B2%E9%97%AE%E9%A2%98/</guid><description>&lt;p>程序员大部分时间都在承接一个个的需求，在做需求的过程中，有一些问题是我们容易忽视的，究其原因，主要是在做需求的过程中缺少思考，或者思考不够全面。而思考的缺失，正是导致部分人所说的“做业务需求没有成长”的主要原因之一。今天主要从研发流程中重要的几个阶段出发，跟大家谈谈做需求的过程中有哪些是我们容易忽视的问题。&lt;/p>
&lt;h1 id="需求分析">需求分析&lt;/h1>
&lt;p>PM是我们的需求的最主要来源，在需求分析阶段，需要避免的问题是：一、没有理解清楚需求细节，而直接进入后续的方案设计和开发阶段；二、需求里说怎么干，我们就怎么干。
问题一容易造成的结果是，功能开发上线完成了，结果发现不是PM想要的，导致不必要的返工成本。另外，由于没有真正理清需求，也有可能导致项目的整体架构设计产生重大偏差，从而给后续的架构迭代留下隐患。
问题二容易造成的结果是，PM想做的功能点都做好了，却只是解决了一个本就不存在的问题，导致人力的浪费。特斯拉进行生产线自动化的时候，有一个零件的自动化安装总是出问题，特斯拉的工程师为了优化这个自动化流程，投入了大量的资金和精力。 后来马斯克问他们的技术人员，为什么需要这个零件，结果发现大家居然并不清楚。最后证明其实在电动车上，根本不需要这个零件。
为了避免以上两个问题，当我们接到PM需求时，应该详细地了解需求的功能细节，以及这个需求需要解决的问题是什么，最终是服务于什么目的，是否有助于达成业务的总体目标。以电商行业为例，我们应该思考所做的需求是否有助于提升商品的导购和流通效率，是否能帮卖家多挣钱，是否能帮买家更快找到想要的商品，是否能帮助平台提升竞争力。&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;h1 id="方案设计">方案设计&lt;/h1>
&lt;p>在方案设计阶段，需要避免的问题是：“这个需求很简单，不用走方案设计和评审环节了，我直接开发吧，很快就可以上线了”。有些需求可能只是简单的修改一两个接口，或者只是对现有的流程做部分调整，这往往容易让我们过于自信，认为直接开干也不会有问题。其实，在我们真正理清楚方案之前，它并不简单，而确保我们真正理清方案的方式，就是按照部门的方案设计模板，把技术方案写出来，对照CheckList，逐一完成各个检查项。
所谓磨刀不误砍柴工，在方案设计阶段多花一些时间，可以帮助我们建设出更加合理的系统架构，让我们在技术架构上不断积累资产，资产的不断增值会让我们在能力建设和研发效率等方面长期受益。相反，如果我们忽视了方案设计，则会不断地积累技术债，后续需要投入很多精力去还债。&lt;/p>
&lt;h1 id="代码开发">代码开发&lt;/h1>
&lt;p>在代码开发方面，需要避免的问题是：“对工程质量要求低，认为能实现功能就行”。实际上，代码也是一种语言，它不仅用于人与机器之间的交流，而且也用于人与人之间的交流。逻辑复杂、晦涩难懂的代码可能会导致以下问题：一、隐藏bug，而且往往很不好改；二、后续有功能迭代时，逻辑修改非常复杂。
逻辑的正确性，是我们编码时的最低要求，编码时应该尽可能的追求信、达、雅。在编码方面主要给两点建议：一、遵守公司和部门的研发规范，包括分支规范、代码规范等；二、写代码时要多思考自己的写法是不是最优的，还有没有更好的写法。&lt;/p>
&lt;h1 id="服务上线">服务上线&lt;/h1>
&lt;p>在服务上线阶段，需要避免的是观察不细致，想当然的认为没问题，结果到最后导致了一个大问题。在上线阶段，我们应该加强检查，从多角度对服务进行观察，包括：上游角度、服务本身角度、下游角度，观察的指标，既包括错误率、时延、错误日志等通用指标，也包括业务自定义指标（应该在方案设计阶段考虑清楚后续有什么手段可以观测服务是否正常）。
值得一提的是，服务上线完成并不是结束，而是一个新的开始。我们需要采取各种手段保障服务的稳定运行，并不断发现其中的可优化点，推动服务SLI稳步提升。&lt;/p></description></item><item><title>给新人程序员的职场建议</title><link>https://xzygis.github.io/2022/11/20/%E7%BB%99%E6%96%B0%E4%BA%BA%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E8%81%8C%E5%9C%BA%E5%BB%BA%E8%AE%AE/</link><pubDate>Sun, 20 Nov 2022 22:01:20 +0000</pubDate><guid>https://xzygis.github.io/2022/11/20/%E7%BB%99%E6%96%B0%E4%BA%BA%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E8%81%8C%E5%9C%BA%E5%BB%BA%E8%AE%AE/</guid><description>&lt;p>我是一位在大厂打拼多年的程序员，今天想结合自己的工作经历给新人程序员们提出若干建议，希望能够在一定程度上帮助大家在职场脱颖而出。&lt;/p>
&lt;h1 id="积极主动">积极主动&lt;/h1>
&lt;p>第一个建议是要积极主动，有owner意识，勇于承担工作职责，并在工作中做出成绩。
首先，领取任务或接受任务应该积极主动。在工作中可以主动向领导提出来自己对什么方向的项目感兴趣，希望承担什么样的任务。当领导知道你是积极主动的人，而且也发现你确实有能力胜任某项工作时，就会优先想到你。在领导主动布置工作任务时，也不应该过多的考虑这项工作好不好干、难度怎么样，而是应该要积极主动的接受。
其次，在执行任务的过程中，应该发挥主观能动性，从而使成果达到预期或尽可能的超出预期。这就要求我们理清任务的本质，思考任务背后的更深层次的逻辑，从而确定目标、理清思路、拆解任务、贯彻执行。这里特别需要避免的是，简单地成为“任务执行器”，即机械的执行任务，而不知道做完这个任务之后能解决什么问题，后续又还需要做什么。&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;h1 id="善于沟通">善于沟通&lt;/h1>
&lt;p>作为研发，工作中不免要和很多同事进行沟通，比如跟PM对接需求、跟其他前后端RD聊技术方案、跟QA聊测试用例等，因此高效的沟通可以在很大程度上提升我们的工作效率。在善于沟通方面，主要的建议是：一、不要与人争吵；二、换位思考。
争吵不能解决任何的问题，反而容易让人丧失理智，而且容易影响自己在旁观者心里的印象。换位思考是解决沟通问题的利器，先谈对方最关心的点，让对方感受到你的真诚。遇到分歧时，先找共同点，求同存异，往往事半功倍。&lt;/p>
&lt;h1 id="保持好奇心">保持好奇心&lt;/h1>
&lt;p>软件研发方面的技术日新月异，不断有新的编程语言、存储组件、技术框架等出现，为了保持保持和增加自己的核心竞争力，对于工作中用到的相关组件和框架，应该不断去挖掘背后的底层原理。比如说工作中用到了HTTP协议，那么就应该思考：为什么会有HTTP？它的演进过程是怎样的？有什么设计理念是值得我们学习的？它还有什么缺陷是需要改进的吗？
除了熟悉工作中用到的技术组件的原理之外，也应该多关注一些前沿的技术趋势，了解业界同行的一些优秀的实践经验，可能的方式包括关注InfoQ、美团技术博客等公众号发布的高质量文档。
这里特别需要避免的是，整天抱怨自己的工作只是CRUD，认为自己的工作没价值，但是却不愿去发掘自己的工作背后的有价值的东西。&lt;/p>
&lt;h1 id="引人注目">引人注目&lt;/h1>
&lt;p>程序员是技术性很强的工作，技术是我们的立身之本，但我们也要避免只会研究技术、埋头苦干。对于交到我们手里的工作，我们要尽可能地做好，同时也需要积极地向领导汇报进展和成果，这样领导才会知道事情的进度是可控的、成果是可预期的，对于你个人的工作产出也自然心里有数了。
在引人注目方面，另外很重要的一点是：发表文章。如果只有你自己知道你是绝顶高手，是没有意义的，你需要通过发表文章的方式表述所学所思所想，让其他人知道你的实力，从而扩大你的影响力。&lt;/p></description></item><item><title>浅谈Bloom Filter基本原理及使用方式</title><link>https://xzygis.github.io/2021/06/12/%E6%B5%85%E8%B0%88bloom-filter%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F/</link><pubDate>Sat, 12 Jun 2021 16:22:56 +0000</pubDate><guid>https://xzygis.github.io/2021/06/12/%E6%B5%85%E8%B0%88bloom-filter%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F/</guid><description>&lt;p>一提到元素查找，我们会很自然的想到&lt;code>HashMap&lt;/code>。通过将哈希函数作用于key上，我们得到了哈希值，基于哈希值我们可以去表里的相应位置获取对应的数据。除了存在哈希冲突问题之外，&lt;code>HashMap&lt;/code>一个很大的问题就是空间效率低。引入&lt;code>Bloom Filter&lt;/code>则可以很好的解决空间效率的问题。&lt;/p>
&lt;h2 id="原理">原理&lt;/h2>
&lt;p>Bloom Filter是一种空间效率很高的随机数据结构，Bloom filter 可以看做是对bit-map 的扩展，布隆过滤器被设计为一个具有N的元素的位数组A（bit array），初始时所有的位都置为0。&lt;/p>
&lt;p>当一个元素被加入集合时，通过K个Hash函数将这个元素映射成一个位阵列（Bit array）中的K个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了。&lt;/p>
&lt;ul>
&lt;li>如果这些点有任何一个 0，则被检索元素一定不在；&lt;/li>
&lt;li>如果都是 1，则被检索元素很可能在。&lt;/li>
&lt;/ul>
&lt;!-- raw HTML omitted -->
&lt;h2 id="添加元素">添加元素&lt;/h2>
&lt;p>要添加一个元素，我们需要提供k个哈希函数。每个函数都能返回一个值，这个值必须能够作为位数组的索引（可以通过对数组长度进行取模得到）。然后，我们把位数组在这个索引处的值设为1。例如，第一个哈希函数作用于元素I上，返回x。类似的，第二个第三个哈希函数返回y与z，那么：
&lt;code>A[x]=A[y]=A[z] = 1&lt;/code>&lt;/p>
&lt;h2 id="查找元素">查找元素&lt;/h2>
&lt;p>查找的过程与上面的过程类似，元素将会被会被不同的哈希函数处理三次，每个哈希函数都返回一个作为位数组索引值的整数，然后我们检测位数组在x、y与z处的值是否为1。如果有一处不为1，那么就说明这个元素没有被添加到这个布隆过滤器中。如果都为1，就说明这个元素在布隆过滤器里面。当然，会有一定误判的概率。&lt;/p>
&lt;h2 id="算法优化">算法优化&lt;/h2>
&lt;p>通过上面的解释我们可以知道，如果想设计出一个好的布隆过滤器，我们必须遵循以下准则：&lt;/p>
&lt;ul>
&lt;li>好的哈希函数能够尽可能的返回宽范围的哈希值。&lt;/li>
&lt;li>位数组的大小（用m表示）非常重要：如果太小，那么所有的位很快就都会被赋值为1，这样就增加了误判的几率。&lt;/li>
&lt;li>哈希函数的个数（用k表示）对索引值的均匀分配也很重要。&lt;/li>
&lt;/ul>
&lt;p>计算m的公式如下：
&lt;code>m = - nlog p / (log2)^2&lt;/code>
这里p为可接受的误判率。&lt;/p>
&lt;p>计算k的公式如下：
&lt;code>k = m/n log(2)&lt;/code>
这里k=哈希函数个数，m=位数组个数，n=待检测元素的个数（后面会用到这几个字母）。&lt;/p>
&lt;h2 id="哈希算法">哈希算法&lt;/h2>
&lt;p>哈希算法是影响布隆过滤器性能的地方。我们需要选择一个效率高但不耗时的哈希函数，在论文《更少的哈希函数，相同的性能指标：构造一个更好的布隆过滤器》中，讨论了如何选用2个哈希函数来模拟k个哈希函数。首先，我们需要计算两个哈希函数h1(x)与h2(x)。然后，我们可以用这两个哈希函数来模仿产生k个哈希函数的效果：
&lt;code>gi(x) = h1(x) + ih2(x)&lt;/code>
这里i的取值范围是1到k的整数。&lt;/p>
&lt;p>Google Guava类库使用这个技巧实现了一个布隆过滤器，哈希算法的主要逻辑如下：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-java" data-lang="java">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">long&lt;/span> hash64 &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#f92672">...;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">int&lt;/span> hash1 &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#f92672">(&lt;/span>&lt;span style="color:#66d9ef">int&lt;/span>&lt;span style="color:#f92672">)&lt;/span> hash64&lt;span style="color:#f92672">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">int&lt;/span> hash2 &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#f92672">(&lt;/span>&lt;span style="color:#66d9ef">int&lt;/span>&lt;span style="color:#f92672">)&lt;/span> &lt;span style="color:#f92672">(&lt;/span>hash64 &lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">32&lt;/span>&lt;span style="color:#f92672">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> &lt;span style="color:#f92672">(&lt;/span>&lt;span style="color:#66d9ef">int&lt;/span> i &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>&lt;span style="color:#f92672">;&lt;/span> i &lt;span style="color:#f92672">&amp;lt;=&lt;/span> numHashFunctions&lt;span style="color:#f92672">;&lt;/span> i&lt;span style="color:#f92672">++)&lt;/span> &lt;span style="color:#f92672">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">int&lt;/span> combinedHash &lt;span style="color:#f92672">=&lt;/span> hash1 &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#f92672">(&lt;/span>i &lt;span style="color:#f92672">*&lt;/span> hash2&lt;span style="color:#f92672">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// Flip all the bits if it&amp;#39;s negative (guaranteed positive number)
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#f92672">(&lt;/span>combinedHash &lt;span style="color:#f92672">&amp;lt;&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>&lt;span style="color:#f92672">)&lt;/span> &lt;span style="color:#f92672">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> combinedHash &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#f92672">~&lt;/span>combinedHash&lt;span style="color:#f92672">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Guava中的Bloom Filter使用示例：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-java" data-lang="java">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">int&lt;/span> expectedInsertions &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#f92672">...;&lt;/span> &lt;span style="color:#75715e">//待检测元素的个数
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">double&lt;/span> fpp &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">0.03&lt;/span>&lt;span style="color:#f92672">;&lt;/span> &lt;span style="color:#75715e">//误判率(desired false positive probability)
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>BloomFilter&lt;span style="color:#f92672">&amp;lt;&lt;/span>CharSequence&lt;span style="color:#f92672">&amp;gt;&lt;/span> bloomFilter &lt;span style="color:#f92672">=&lt;/span> BloomFilter&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#a6e22e">create&lt;/span>&lt;span style="color:#f92672">(&lt;/span>Funnels&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#a6e22e">stringFunnel&lt;/span>&lt;span style="color:#f92672">(&lt;/span>Charset&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#a6e22e">forName&lt;/span>&lt;span style="color:#f92672">(&lt;/span>&lt;span style="color:#e6db74">&amp;#34;UTF-8&amp;#34;&lt;/span>&lt;span style="color:#f92672">)),&lt;/span> expectedInsertions&lt;span style="color:#f92672">,&lt;/span>fpp&lt;span style="color:#f92672">);&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="优点">优点&lt;/h2>
&lt;p>它的优点是空间效率和查询时间都远远超过一般的算法，布隆过滤器存储空间和插入/查询时间都是常数O(k)。另外, 散列函数相互之间没有关系，方便由硬件并行实现。布隆过滤器不需要存储元素本身，在某些对保密要求非常严格的场合有优势。&lt;/p>
&lt;h2 id="缺点">缺点&lt;/h2>
&lt;p>布隆过滤器的缺点和优点一样明显，误算率是其中之一。&lt;/p>
&lt;p>另外，一般情况下不能从布隆过滤器中删除元素。我们很容易想到把位数组变成整数数组，每插入一个元素相应的计数器加 1，这样删除元素时将计数器减掉就可以了。然而要保证安全地删除元素并非如此简单。首先我们必须保证删除的元素的确在布隆过滤器里面，而这一点单凭这个过滤器是无法保证的。&lt;/p>
&lt;p>参考来源：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.javacodegeeks.com/2014/07/how-to-use-bloom-filter-to-build-a-large-in-memory-cache-in-java.html">https://www.javacodegeeks.com/2014/07/how-to-use-bloom-filter-to-build-a-large-in-memory-cache-in-java.html&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.cnblogs.com/haippy/archive/2012/07/13/2590351.html">https://www.cnblogs.com/haippy/archive/2012/07/13/2590351.html&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://segmentfault.com/a/1190000002729689">https://segmentfault.com/a/1190000002729689&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Linux文件传输的三种方式</title><link>https://xzygis.github.io/2021/06/12/linux%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F/</link><pubDate>Sat, 12 Jun 2021 16:14:22 +0000</pubDate><guid>https://xzygis.github.io/2021/06/12/linux%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F/</guid><description>&lt;h1 id="1-nc命令">1 nc命令&lt;/h1>
&lt;p>执行如下命令，在目标机器(假设ip为&lt;code>10.11.12.13&lt;/code>)上监听端口&lt;code>8415&lt;/code>&lt;/p>
&lt;pre tabindex="0">&lt;code>nc -l 8415 &amp;gt; data.txt
&lt;/code>&lt;/pre>&lt;p>往目标机器发送数据&lt;/p>
&lt;pre tabindex="0">&lt;code>nc -v 10.11.12.13 8415 &amp;lt; ~/Downloads/data.txt
&lt;/code>&lt;/pre>&lt;h1 id="2-simplehttpserver">2 SimpleHTTPServer&lt;/h1>
&lt;p>在服务器(假设ip为&lt;code>10.11.12.13&lt;/code>)上执行如下命令:&lt;/p>
&lt;pre tabindex="0">&lt;code>python -m SimpleHTTPServer 8411
&lt;/code>&lt;/pre>&lt;p>然后在本地机器打开浏览器，输入&lt;code>http://10.11.12.13:8411/&lt;/code>可以访问。&lt;/p>
&lt;h1 id="3-scp命令">3 scp命令&lt;/h1>
&lt;p>Linux scp命令用于Linux之间复制文件和目录。&lt;/p>
&lt;p>scp是 secure copy的缩写, scp是linux系统下基于ssh登陆进行安全的远程文件拷贝命令。&lt;/p>
&lt;p>在目标机器执行如下命令：&lt;/p>
&lt;pre tabindex="0">&lt;code>scp -l 700000 username@dev.test.com:~/data.txt ./
&lt;/code>&lt;/pre>&lt;p>即可把目标机器dev.test.com的文件~/data.txt拷贝到当前目录。&lt;/p></description></item><item><title>Websocket介绍</title><link>https://xzygis.github.io/2021/06/12/websocket%E4%BB%8B%E7%BB%8D/</link><pubDate>Sat, 12 Jun 2021 15:25:21 +0000</pubDate><guid>https://xzygis.github.io/2021/06/12/websocket%E4%BB%8B%E7%BB%8D/</guid><description>&lt;h1 id="什么是websocket">什么是WebSocket？&lt;/h1>
&lt;p>WebSocket是一种网络传输协议，可在单个TCP连接上进行全双工通信，位于OSI模型的应用层。WebSocket协议在2011年由IETF标准化为RFC 6455，后由RFC 7936补充规范。&lt;/p>
&lt;p>WebSocket使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。在WebSocket API中，浏览器和服务器只需要完成一次握手，两者之间就可以创建持久性的连接，并进行双向数据传输。&lt;/p>
&lt;h2 id="有哪些优点">有哪些优点？&lt;/h2>
&lt;ol>
&lt;li>较少的控制开销。在连接创建后，服务器和客户端之间交换数据时，用于协议控制的数据包头部相对较小。在不包含扩展的情况下，对于服务器到客户端的内容，此头部大小只有2至10字节（和数据包长度有关）；对于客户端到服务器的内容，此头部还需要加上额外的4字节的掩码。相对于HTTP请求每次都要携带完整的头部，此项开销显著减少了。&lt;/li>
&lt;li>强的实时性。由于协议是全双工的，所以服务器可以随时主动给客户端下发数据。相对于HTTP请求需要等待客户端发起请求服务端才能响应，延迟明显更少；即使是和Comet等类似的长轮询比较，其也能在短时间内更多次地传递数据。&lt;/li>
&lt;li>保持连接状态。与HTTP不同的是，Websocket需要先创建连接，这就使得其成为一种有状态的协议，之后通信时可以省略部分状态信息。而HTTP请求可能需要在每个请求都携带状态信息（如身份认证等）。&lt;/li>
&lt;li>更好的二进制支持。Websocket定义了二进制帧，相对HTTP，可以更轻松地处理二进制内容。&lt;/li>
&lt;li>可以支持扩展。Websocket定义了扩展，用户可以扩展协议、实现部分自定义的子协议。如部分浏览器支持压缩等。&lt;/li>
&lt;/ol>
&lt;!-- raw HTML omitted -->
&lt;h1 id="握手协议">握手协议&lt;/h1>
&lt;p>WebSocket是一种与HTTP不同的协议。两者都位于OSI模型的应用层，并且都依赖于传输层的TCP协议。 虽然它们不同，但是RFC 6455中规定：it is designed to work over HTTP ports 80 and 443 as well as to support HTTP proxies and intermediaries（WebSocket通过HTTP端口80和443进行工作，并支持HTTP代理和中介），从而使其与HTTP协议兼容。 为了实现兼容性，WebSocket握手使用HTTP Upgrade头从HTTP协议更改为WebSocket协议。&lt;/p>
&lt;h2 id="握手例子">握手例子&lt;/h2>
&lt;p>一个典型的Websocket握手请求如下：&lt;/p>
&lt;p>客户端请求：&lt;/p>
&lt;pre tabindex="0">&lt;code>GET /chat HTTP/1.1
Host: server.example.com
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ==
Origin: http://example.com
Sec-WebSocket-Protocol: chat, superchat
Sec-WebSocket-Version: 13
&lt;/code>&lt;/pre>&lt;p>服务器回应：&lt;/p>
&lt;pre tabindex="0">&lt;code>HTTP/1.1 101 Switching Protocols
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Accept: s3pPLMBiTxaQ9kYGzzhZRbK+xOo=
Sec-WebSocket-Protocol: chat
&lt;/code>&lt;/pre>&lt;h2 id="字段说明">字段说明&lt;/h2>
&lt;ul>
&lt;li>Connection必须设置Upgrade，表示客户端希望连接升级。&lt;/li>
&lt;li>Upgrade字段必须设置Websocket，表示希望升级到Websocket协议。&lt;/li>
&lt;li>Sec-WebSocket-Key是随机的字符串，服务器端会用这些数据来构造出一个SHA-1的信息摘要。把“Sec-WebSocket-Key”加上一个特殊字符串“258EAFA5-E914-47DA-95CA-C5AB0DC85B11”，然后计算SHA-1摘要，之后进行Base64编码，将结果做为“Sec-WebSocket-Accept”头的值，返回给客户端。如此操作，可以尽量避免普通HTTP请求被误认为Websocket协议。&lt;/li>
&lt;li>Sec-WebSocket-Version 表示支持的Websocket版本。RFC6455要求使用的版本是13，之前草案的版本均应当弃用。&lt;/li>
&lt;li>Origin字段是必须的。如果缺少origin字段，WebSocket服务器需要回复HTTP 403 状态码（禁止访问）。&lt;/li>
&lt;/ul>
&lt;h2 id="体验一下">体验一下&lt;/h2>
&lt;blockquote>
&lt;p>&lt;a href="https://www.websocket.org/echo.html">https://www.websocket.org/echo.html&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="websocket.org-1.png" alt="Connect">&lt;/p>
&lt;p>握手报文：&lt;/p>
&lt;p>&lt;img src="websocket.org-2.png" alt="握手报文">&lt;/p>
&lt;p>数据传输：&lt;/p>
&lt;p>&lt;img src="websocket.org-3.png" alt="握手报文">&lt;/p>
&lt;h1 id="数据帧">数据帧&lt;/h1>
&lt;p>WebSocket客户端、服务端通信的最小单位是帧（frame），由1个或多个帧组成一条完整的消息（message）。&lt;/p>
&lt;ul>
&lt;li>发送端：将消息切割成多个帧，并发送给服务端；&lt;/li>
&lt;li>接收端：接收消息帧，并将关联的帧重新组装成完整的消息；&lt;/li>
&lt;/ul>
&lt;h2 id="帧结构">帧结构&lt;/h2>
&lt;pre tabindex="0">&lt;code> +-+-+-+-+-------+-+-------------+-------------------------------+
|F|R|R|R| opcode|M| Payload len | Extended payload length |
|I|S|S|S| (4) |A| (7) | (16/64) |
|N|V|V|V| |S| | (if payload len==126/127) |
| |1|2|3| |K| | |
+-+-+-+-+-------+-+-------------+ - - - - - - - - - - - - - - - +
| Extended payload length continued, if payload len == 127 |
+ - - - - - - - - - - - - - - - +-------------------------------+
| |Masking-key, if MASK set to 1 |
+-------------------------------+-------------------------------+
| Masking-key (continued) | Payload Data |
+-------------------------------- - - - - - - - - - - - - - - - +
: Payload Data continued ... :
+ - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - +
| Payload Data continued ... |
+---------------------------------------------------------------+
&lt;/code>&lt;/pre>&lt;h2 id="字段说明-1">字段说明&lt;/h2>
&lt;p>FIN：1个比特。
如果是1，表示这是消息（message）的最后一个分片（fragment），如果是0，表示不是是消息（message）的最后一个分片（fragment）。&lt;/p>
&lt;p>RSV1, RSV2, RSV3：各占1个比特。
一般情况下全为0。当客户端、服务端协商采用WebSocket扩展时，这三个标志位可以非0，且值的含义由扩展进行定义。如果出现非零的值，且并没有采用WebSocket扩展，连接出错。&lt;/p>
&lt;p>Opcode: 4个比特。
操作代码，Opcode的值决定了应该如何解析后续的数据载荷（data payload）。如果操作代码是不认识的，那么接收端应该断开连接（fail the connection）。可选的操作代码如下：&lt;/p>
&lt;ul>
&lt;li>%x0：表示一个延续帧。当Opcode为0时，表示本次数据传输采用了数据分片，当前收到的数据帧为其中一个数据分片。&lt;/li>
&lt;li>%x1：表示这是一个文本帧（frame）&lt;/li>
&lt;li>%x2：表示这是一个二进制帧（frame）&lt;/li>
&lt;li>%x3-7：保留的操作代码，用于后续定义的非控制帧。&lt;/li>
&lt;li>%x8：表示连接断开。&lt;/li>
&lt;li>%x9：表示这是一个ping操作。&lt;/li>
&lt;li>%xA：表示这是一个pong操作。&lt;/li>
&lt;li>%xB-F：保留的操作代码，用于后续定义的控制帧。&lt;/li>
&lt;/ul>
&lt;p>Mask: 1个比特。
表示是否要对数据载荷进行掩码操作。从客户端向服务端发送数据时，需要对数据进行掩码操作；从服务端向客户端发送数据时，不需要对数据进行掩码操作。
如果服务端接收到的数据没有进行过掩码操作，服务端需要断开连接。
如果Mask是1，那么在Masking-key中会定义一个掩码键（masking key），并用这个掩码键来对数据载荷进行反掩码。所有客户端发送到服务端的数据帧，Mask都是1。
掩码的算法、用途在下一小节讲解。&lt;/p>
&lt;p>Payload length：数据载荷的长度，单位是字节。为7位，或7+16位，或1+64位。
假设数Payload length === x，如果&lt;/p>
&lt;ul>
&lt;li>x为0~126：数据的长度为x字节。&lt;/li>
&lt;li>x为126：后续2个字节代表一个16位的无符号整数，该无符号整数的值为数据的长度。&lt;/li>
&lt;li>x为127：后续8个字节代表一个64位的无符号整数（最高位为0），该无符号整数的值为数据的长度。&lt;/li>
&lt;/ul>
&lt;p>此外，如果payload length占用了多个字节的话，payload length的二进制表达采用网络序（big endian，重要的位在前）。&lt;/p>
&lt;p>Masking-key：0或4字节（32位）
所有从客户端传送到服务端的数据帧，数据载荷都进行了掩码操作，Mask为1，且携带了4字节的Masking-key。如果Mask为0，则没有Masking-key。
备注：载荷数据的长度，不包括mask key的长度。&lt;/p>
&lt;p>Payload data：(x+y) 字节&lt;/p>
&lt;ul>
&lt;li>载荷数据：包括了扩展数据、应用数据。其中，扩展数据x字节，应用数据y字节。&lt;/li>
&lt;li>扩展数据：如果没有协商使用扩展的话，扩展数据数据为0字节。所有的扩展都必须声明扩展数据的长度，或者可以如何计算出扩展数据的长度。此外，扩展如何使用必须在握手阶段就协商好。如果扩展数据存在，那么载荷数据长度必须将扩展数据的长度包含在内。&lt;/li>
&lt;li>应用数据：任意的应用数据，在扩展数据之后（如果存在扩展数据），占据了数据帧剩余的位置。载荷数据长度 减去 扩展数据长度，就得到应用数据的长度。&lt;/li>
&lt;/ul>
&lt;h2 id="掩码算法">掩码算法&lt;/h2>
&lt;p>掩码键（Masking-key）是由客户端挑选出来的32位的随机数。掩码操作不会影响数据载荷的长度。掩码、反掩码操作都采用如下算法：&lt;/p>
&lt;p>首先，预设：&lt;/p>
&lt;ul>
&lt;li>original-octet-i：为原始数据的第i字节。&lt;/li>
&lt;li>transformed-octet-i：为转换后的数据的第i字节。&lt;/li>
&lt;li>j：为i mod 4的结果。&lt;/li>
&lt;li>masking-key-octet-j：为mask key第j字节。&lt;/li>
&lt;/ul>
&lt;p>流程为： original-octet-i 与 masking-key-octet-j 异或后，得到 transformed-octet-i。&lt;/p>
&lt;p>伪代码大概是：&lt;/p>
&lt;pre tabindex="0">&lt;code>var DECODED = &amp;#34;&amp;#34;;
for (var i = 0; i &amp;lt; ENCODED.length; i++) {
DECODED[i] = ENCODED[i] ^ MASK[i % 4];
}
&lt;/code>&lt;/pre>&lt;p>数据掩码的作用：
WebSocket 协议中，数据掩码的作用是增强协议的安全性。但数据掩码并不是为了保护数据本身，因为算法本身是公开的，运算也不复杂。除了加密通道本身，似乎没有太多有效的保护通信安全的办法。
那么为什么还要引入掩码计算呢，除了增加计算机器的运算量外似乎并没有太多的收益（这也是不少同学疑惑的点）。
答案还是两个字：安全。但并不是为了防止数据泄密，而是为了防止早期版本的协议中存在的代理缓存污染攻击（proxy cache poisoning attacks）等问题。&lt;/p>
&lt;h1 id="数据传递">数据传递&lt;/h1>
&lt;p>一旦WebSocket客户端、服务端建立连接后，后续的操作都是基于数据帧的传递。
WebSocket根据opcode来区分操作的类型。比如0x8表示断开连接，0x0-0x2表示数据交互。&lt;/p>
&lt;h2 id="数据分片">数据分片&lt;/h2>
&lt;p>WebSocket的每条消息可能被切分成多个数据帧。当WebSocket的接收方收到一个数据帧时，会根据FIN的值来判断，是否已经收到消息的最后一个数据帧。
FIN=1表示当前数据帧为消息的最后一个数据帧，此时接收方已经收到完整的消息，可以对消息进行处理。FIN=0，则接收方还需要继续监听接收其余的数据帧。
此外，opcode在数据交换的场景下，表示的是数据的类型。0x01表示文本，0x02表示二进制。而0x00比较特殊，表示延续帧（continuation frame），顾名思义，就是完整消息对应的数据帧还没接收完。&lt;/p>
&lt;h2 id="数据分片例子">数据分片例子&lt;/h2>
&lt;p>下面例子来自MDN，可以很好地演示数据的分片。客户端向服务端两次发送消息，服务端收到消息后回应客户端，这里主要看客户端往服务端发送的消息。&lt;/p>
&lt;p>&lt;em>第一条消息&lt;/em>&lt;/p>
&lt;p>FIN=1, 表示是当前消息的最后一个数据帧。服务端收到当前数据帧后，可以处理消息。opcode=0x1，表示客户端发送的是文本类型。&lt;/p>
&lt;p>&lt;em>第二条消息&lt;/em>&lt;/p>
&lt;ol>
&lt;li>FIN=0，opcode=0x1，表示发送的是文本类型，且消息还没发送完成，还有后续的数据帧。&lt;/li>
&lt;li>FIN=0，opcode=0x0，表示消息还没发送完成，还有后续的数据帧，当前的数据帧需要接在上一条数据帧之后。&lt;/li>
&lt;li>FIN=1，opcode=0x0，表示消息已经发送完成，没有后续的数据帧，当前的数据帧需要接在上一条数据帧之后。服务端可以将关联的数据帧组装成完整的消息。&lt;/li>
&lt;/ol>
&lt;pre tabindex="0">&lt;code>Client: FIN=1, opcode=0x1, msg=&amp;#34;hello&amp;#34;
Server: (process complete message immediately) Hi.
Client: FIN=0, opcode=0x1, msg=&amp;#34;and a&amp;#34;
Server: (listening, new message containing text started)
Client: FIN=0, opcode=0x0, msg=&amp;#34;happy new&amp;#34;
Server: (listening, payload concatenated to previous message)
Client: FIN=1, opcode=0x0, msg=&amp;#34;year!&amp;#34;
Server: (process complete message) Happy new year to you too!
&lt;/code>&lt;/pre>&lt;h1 id="心跳">心跳&lt;/h1>
&lt;p>WebSocket 为了保持客户端、服务端的实时双向通信，需要确保客户端、服务端之间的 TCP 通道保持连接没有断开。
对于长时间没有数据往来的连接，如果依旧长时间保持着，可能会浪费包括的连接资源。但不排除有些场景，客户端、服务端虽然长时间没有数据往来，但仍需要保持连接。这个时候，可以采用心跳来实现。&lt;/p>
&lt;ul>
&lt;li>发送方 -&amp;gt; 接收方：ping&lt;/li>
&lt;li>接收方 -&amp;gt; 发送方：pong&lt;/li>
&lt;/ul>
&lt;p>ping、pong 的操作，对应的是 WebSocket 的两个控制帧，opcode分别是0x9、0xA。&lt;/p>
&lt;h1 id="安全性">安全性&lt;/h1>
&lt;p>WebSocket协议中规定在连接建立时检查Upgrade请求中的某些字段（如Origin，查看每次请求是否一致），对于不符合要求的请求立即断开，在通信过程中，也对Frame中的控制位做了很多限制，以便禁止异常连接。
websocket协议中也规定了数据加密传输的方式，允许使用TLS/SSL来对通信加密，默认ws的端口为80，wss端口为433，类似HTTP与HTTPS。&lt;/p>
&lt;h1 id="go实战gorilla-websocket">Go实战：Gorilla WebSocket&lt;/h1>
&lt;blockquote>
&lt;p>Github：https://github.com/gorilla/websocket&lt;/p>
&lt;/blockquote>
&lt;p>文件监控例子（当文件被修改后，把文件发给客户端）：&lt;/p>
&lt;pre tabindex="0">&lt;code>func main() {
http.HandleFunc(&amp;#34;/ws&amp;#34;, serveWs)
if err := http.ListenAndServe(*addr, nil); err != nil {
log.Fatal(err)
}
}
func serveWs(w http.ResponseWriter, r *http.Request) {
//升级为Websocket协议
ws, err := upgrader.Upgrade(w, r, nil)
if err != nil {
if _, ok := err.(websocket.HandshakeError); !ok {
log.Println(err)
}
return
}
var lastMod time.Time
if n, err := strconv.ParseInt(r.FormValue(&amp;#34;lastMod&amp;#34;), 16, 64); err == nil {
lastMod = time.Unix(0, n)
}
go writer(ws, lastMod) //发送数据、Pong
reader(ws) //读数据、处理Ping
}
func writer(ws *websocket.Conn, lastMod time.Time) {
pingTicker := time.NewTicker(pingPeriod)
fileTicker := time.NewTicker(filePeriod)
...
for {
select {
case &amp;lt;-fileTicker.C:
p, fileModified, err := readFileIfModified(lastMod)
...
if fileModified {
ws.SetWriteDeadline(time.Now().Add(writeWait))
if err := ws.WriteMessage(websocket.TextMessage, p); err != nil {
return
}
}
case &amp;lt;-pingTicker.C:
ws.SetWriteDeadline(time.Now().Add(writeWait))
if err := ws.WriteMessage(websocket.PingMessage, []byte{}); err != nil {
return
}
}
}
}
func reader(ws *websocket.Conn) {
defer ws.Close()
ws.SetReadLimit(512)
ws.SetReadDeadline(time.Now().Add(pongWait))
ws.SetPongHandler(func(string) error { ws.SetReadDeadline(time.Now().Add(pongWait)); return nil })
for {
_, _, err := ws.ReadMessage()
if err != nil {
break
}
}
}
&lt;/code>&lt;/pre>&lt;p>其中最重要的几个方法是Upgrade、ReadMessage和WriteMessage，下面逐一介绍。&lt;/p>
&lt;h2 id="upgrade">Upgrade&lt;/h2>
&lt;p>协议升级&lt;/p>
&lt;pre tabindex="0">&lt;code>// Upgrade upgrades the HTTP server connection to the WebSocket protocol.
func (u *Upgrader) Upgrade(w http.ResponseWriter, r *http.Request, responseHeader http.Header) (*Conn, error) {
const badHandshake = &amp;#34;websocket: the client is not using the websocket protocol: &amp;#34;
//检查必要的头部字段
if !tokenListContainsValue(r.Header, &amp;#34;Connection&amp;#34;, &amp;#34;upgrade&amp;#34;) {
return u.returnError(w, r, http.StatusBadRequest, badHandshake+&amp;#34;&amp;#39;upgrade&amp;#39; token not found in &amp;#39;Connection&amp;#39; header&amp;#34;)
}
if !tokenListContainsValue(r.Header, &amp;#34;Upgrade&amp;#34;, &amp;#34;websocket&amp;#34;) {
return u.returnError(w, r, http.StatusBadRequest, badHandshake+&amp;#34;&amp;#39;websocket&amp;#39; token not found in &amp;#39;Upgrade&amp;#39; header&amp;#34;)
}
if r.Method != &amp;#34;GET&amp;#34; {
return u.returnError(w, r, http.StatusMethodNotAllowed, badHandshake+&amp;#34;request method is not GET&amp;#34;)
}
if !tokenListContainsValue(r.Header, &amp;#34;Sec-Websocket-Version&amp;#34;, &amp;#34;13&amp;#34;) {
return u.returnError(w, r, http.StatusBadRequest, &amp;#34;websocket: unsupported version: 13 not found in &amp;#39;Sec-Websocket-Version&amp;#39; header&amp;#34;)
}
if !checkOrigin(r) {
return u.returnError(w, r, http.StatusForbidden, &amp;#34;websocket: request origin not allowed by Upgrader.CheckOrigin&amp;#34;)
}
challengeKey := r.Header.Get(&amp;#34;Sec-Websocket-Key&amp;#34;)
if challengeKey == &amp;#34;&amp;#34; {
return u.returnError(w, r, http.StatusBadRequest, &amp;#34;websocket: not a websocket handshake: &amp;#39;Sec-WebSocket-Key&amp;#39; header is missing or blank&amp;#34;)
}
h, ok := w.(http.Hijacker)
if !ok {
return u.returnError(w, r, http.StatusInternalServerError, &amp;#34;websocket: response does not implement http.Hijacker&amp;#34;)
}
//创建websocket.Conn
c := newConn(netConn, true, u.ReadBufferSize, u.WriteBufferSize, u.WriteBufferPool, br, writeBuf)
var p []byte
p = append(p, &amp;#34;HTTP/1.1 101 Switching Protocols\r\nUpgrade: websocket\r\nConnection: Upgrade\r\nSec-WebSocket-Accept: &amp;#34;...)
p = append(p, computeAcceptKey(challengeKey)...) //计算accept
p = append(p, &amp;#34;\r\n&amp;#34;...)
if c.subprotocol != &amp;#34;&amp;#34; {
p = append(p, &amp;#34;Sec-WebSocket-Protocol: &amp;#34;...)
p = append(p, c.subprotocol...)
p = append(p, &amp;#34;\r\n&amp;#34;...)
}
if _, err = netConn.Write(p); err != nil {
netConn.Close()
return nil, err
}
return c, nil
}
var keyGUID = []byte(&amp;#34;258EAFA5-E914-47DA-95CA-C5AB0DC85B11&amp;#34;)
func computeAcceptKey(challengeKey string) string {
h := sha1.New()
h.Write([]byte(challengeKey))
h.Write(keyGUID)
return base64.StdEncoding.EncodeToString(h.Sum(nil))
}
func newConn(conn net.Conn, isServer bool, readBufferSize, writeBufferSize int, writeBufferPool BufferPool, br *bufio.Reader, writeBuf []byte) *Conn {
c := &amp;amp;Conn{
isServer: isServer,
br: br,
conn: conn,
mu: mu,
readFinal: true,
writeBuf: writeBuf,
writePool: writeBufferPool,
writeBufSize: writeBufferSize,
enableWriteCompression: true,
compressionLevel: defaultCompressionLevel,
}
//设置对应的消息处理Handler
c.SetCloseHandler(nil)
c.SetPingHandler(nil)
c.SetPongHandler(nil)
return c
}
func (c *Conn) SetCloseHandler(h func(code int, text string) error) {
if h == nil {
h = func(code int, text string) error {
message := FormatCloseMessage(code, &amp;#34;&amp;#34;)
c.WriteControl(CloseMessage, message, time.Now().Add(writeWait))
return nil
}
}
c.handleClose = h
}
func (c *Conn) SetPingHandler(h func(appData string) error) {
if h == nil {
h = func(message string) error {
err := c.WriteControl(PongMessage, []byte(message), time.Now().Add(writeWait))
return err
}
}
c.handlePing = h
}
func (c *Conn) SetPongHandler(h func(appData string) error) {
if h == nil {
h = func(string) error { return nil }
}
c.handlePong = h
}
&lt;/code>&lt;/pre>&lt;h2 id="readmessage">ReadMessage&lt;/h2>
&lt;pre tabindex="0">&lt;code>func (c *Conn) ReadMessage() (messageType int, p []byte, err error) {
var r io.Reader
messageType, r, err = c.NextReader()
if err != nil {
return messageType, nil, err
}
p, err = ioutil.ReadAll(r)
return messageType, p, err
}
func (c *Conn) NextReader() (messageType int, r io.Reader, err error) {
for c.readErr == nil {
frameType, err := c.advanceFrame()
if err != nil {
c.readErr = hideTempErr(err)
break
}
if frameType == TextMessage || frameType == BinaryMessage {
c.messageReader = &amp;amp;messageReader{c}
c.reader = c.messageReader
if c.readDecompress {
c.reader = c.newDecompressionReader(c.reader)
}
return frameType, c.reader, nil
}
}
}
//解析数据帧
func (c *Conn) advanceFrame() (int, error) {
p, err := c.read(2)
final := p[0]&amp;amp;finalBit != 0
frameType := int(p[0] &amp;amp; 0xf)
mask := p[1]&amp;amp;maskBit != 0
c.setReadRemaining(int64(p[1] &amp;amp; 0x7f))
switch frameType {
case CloseMessage, PingMessage, PongMessage:
if c.readRemaining &amp;gt; maxControlFramePayloadSize {
return noFrame, c.handleProtocolError(&amp;#34;control frame length &amp;gt; 125&amp;#34;)
}
if !final {
return noFrame, c.handleProtocolError(&amp;#34;control frame not final&amp;#34;)
}
case TextMessage, BinaryMessage:
if !c.readFinal {
return noFrame, c.handleProtocolError(&amp;#34;message start before final message frame&amp;#34;)
}
c.readFinal = final
case continuationFrame:
if c.readFinal {
return noFrame, c.handleProtocolError(&amp;#34;continuation after final message frame&amp;#34;)
}
c.readFinal = final
default:
return noFrame, c.handleProtocolError(&amp;#34;unknown opcode &amp;#34; + strconv.Itoa(frameType))
}
switch c.readRemaining {
case 126:
p, err := c.read(2)
if err := c.setReadRemaining(int64(binary.BigEndian.Uint16(p))); err != nil {
return noFrame, err
}
case 127:
p, err := c.read(8)
if err != nil {
return noFrame, err
}
if err := c.setReadRemaining(int64(binary.BigEndian.Uint64(p))); err != nil {
return noFrame, err
}
}
if mask != c.isServer {
return noFrame, c.handleProtocolError(&amp;#34;incorrect mask flag&amp;#34;)
}
if mask {
c.readMaskPos = 0
p, err := c.read(len(c.readMaskKey))
if err != nil {
return noFrame, err
}
copy(c.readMaskKey[:], p)
}
//处理控制帧
switch frameType {
case PongMessage:
if err := c.handlePong(string(payload)); err != nil {
return noFrame, err
}
case PingMessage:
if err := c.handlePing(string(payload)); err != nil {
return noFrame, err
}
case CloseMessage:
closeCode := CloseNoStatusReceived
closeText := &amp;#34;&amp;#34;
if len(payload) &amp;gt;= 2 {
closeCode = int(binary.BigEndian.Uint16(payload))
if !isValidReceivedCloseCode(closeCode) {
return noFrame, c.handleProtocolError(&amp;#34;invalid close code&amp;#34;)
}
closeText = string(payload[2:])
if !utf8.ValidString(closeText) {
return noFrame, c.handleProtocolError(&amp;#34;invalid utf8 payload in close frame&amp;#34;)
}
}
if err := c.handleClose(closeCode, closeText); err != nil {
return noFrame, err
}
return noFrame, &amp;amp;CloseError{Code: closeCode, Text: closeText}
}
return frameType, nil
}
&lt;/code>&lt;/pre>&lt;h2 id="writemessage">WriteMessage&lt;/h2>
&lt;pre tabindex="0">&lt;code>func (c *Conn) WriteMessage(messageType int, data []byte) error {
var mw messageWriter
// beginMessage prepares a connection and message writer for a new message.
if err := c.beginMessage(&amp;amp;mw, messageType); err != nil {
return err
}
n := copy(c.writeBuf[mw.pos:], data)
mw.pos += n
data = data[n:]
return mw.flushFrame(true, data)
}
//组装数据帧
func (w *messageWriter) flushFrame(final bool, extra []byte) error {
c := w.c
length := w.pos - maxFrameHeaderSize + len(extra)
b0 := byte(w.frameType)
if final {
b0 |= finalBit
}
if w.compress {
b0 |= rsv1Bit
}
w.compress = false
b1 := byte(0)
if !c.isServer {
b1 |= maskBit
}
// Assume that the frame starts at beginning of c.writeBuf.
framePos := 0
if c.isServer {
// Adjust up if mask not included in the header.
framePos = 4
}
switch {
case length &amp;gt;= 65536:
c.writeBuf[framePos] = b0
c.writeBuf[framePos+1] = b1 | 127
binary.BigEndian.PutUint64(c.writeBuf[framePos+2:], uint64(length))
case length &amp;gt; 125:
framePos += 6
c.writeBuf[framePos] = b0
c.writeBuf[framePos+1] = b1 | 126
binary.BigEndian.PutUint16(c.writeBuf[framePos+2:], uint16(length))
default:
framePos += 8
c.writeBuf[framePos] = b0
c.writeBuf[framePos+1] = b1 | byte(length)
}
if !c.isServer {
key := newMaskKey()
copy(c.writeBuf[maxFrameHeaderSize-4:], key[:])
maskBytes(key, 0, c.writeBuf[maxFrameHeaderSize:w.pos])
if len(extra) &amp;gt; 0 {
return w.endMessage(c.writeFatal(errors.New(&amp;#34;websocket: internal error, extra used in client mode&amp;#34;)))
}
}
// Write the buffers to the connection with best-effort detection of
// concurrent writes. See the concurrency section in the package
// documentation for more info.
if c.isWriting {
panic(&amp;#34;concurrent write to websocket connection&amp;#34;)
}
c.isWriting = true
err := c.write(w.frameType, c.writeDeadline, c.writeBuf[framePos:w.pos], extra)
...
return nil
}
&lt;/code>&lt;/pre>&lt;p>Ref：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://datatracker.ietf.org/doc/html/rfc6455#">https://datatracker.ietf.org/doc/html/rfc6455#&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://zh.wikipedia.org/wiki/WebSocket">https://zh.wikipedia.org/wiki/WebSocket&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://www.ruanyifeng.com/blog/2017/05/websocket.html">http://www.ruanyifeng.com/blog/2017/05/websocket.html&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://pkg.go.dev/github.com/gorilla/websocket">https://pkg.go.dev/github.com/gorilla/websocket&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Consul入门手册</title><link>https://xzygis.github.io/2020/01/30/consul%E5%85%A5%E9%97%A8%E6%89%8B%E5%86%8C/</link><pubDate>Thu, 30 Jan 2020 13:35:59 +0000</pubDate><guid>https://xzygis.github.io/2020/01/30/consul%E5%85%A5%E9%97%A8%E6%89%8B%E5%86%8C/</guid><description>&lt;h1 id="consul是什么">Consul是什么？&lt;/h1>
&lt;p>Consul是一个服务发现和配置工具，它是分布式和高可用的，而且极易扩展。&lt;/p>
&lt;p>Consul主要提供了以下特性：&lt;/p>
&lt;ol>
&lt;li>服务发现：Consul使得服务注册和服务发现（通过DNS或HTTP接口）变得非常简单。&lt;/li>
&lt;li>健康检查：健康检查使得Consul可以快速向管理员报告集群状况。将它与服务发现集成，可以防止流量路由到故障节点，实现服务熔断。&lt;/li>
&lt;li>KV存储：灵活的KV存储，可用于尺寸出动态配置、功能特性、协调信息和选举信息等。简单的HTTP API使其易于在任何地方地方。&lt;/li>
&lt;li>多数据中心：Consul支持多数据中心，不需要负责的配置就可以支持任意数量的数据中心。&lt;/li>
&lt;li>服务鉴权（Service Segmentation）：Consul连接基于自动TLS加密和基于签名的鉴权实现安全的服务间通信。&lt;/li>
&lt;/ol>
&lt;p>Consul支持Linux, Mac OS X, FreeBSD, Solaris, Windows等操作系统。&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;h2 id="基本架构">基本架构&lt;/h2>
&lt;p>每个提供服务给Consul的节点都运行了一个Consul Agent。运行一个Agent并不需要对其他服务做发现或读写KV存储。Agent负责对该节点上的服务做健康检查。&lt;/p>
&lt;p>Agent会与一个或多个Consul Server通信。Consul Server通常有多个实例，负责数据存储和备份、选举主节点等。虽然Consul支持在只有一个Server实例的情况下工具，但通常推荐使用3至5个实例，从而避免由于某些异常场景而导致数据丢失。同时，推荐在每个数据中心部署一个Consul集群。&lt;/p>
&lt;p>每个数据中运行了一个Consul server集群。当一个跨数据中心的服务发现和配置请求创建时，本地Consul Server转发请求到远程的数据中心并返回结果.&lt;/p>
&lt;h1 id="安装consul">安装Consul&lt;/h1>
&lt;p>Consul集群的每个节点都必须先安装Consul，安装非常简单。在Mac上安装Consul命令如下：&lt;/p>
&lt;pre tabindex="0">&lt;code>$ brew install consul
&lt;/code>&lt;/pre>&lt;p>安装成功后执行consul命令输出如下结果：&lt;/p>
&lt;pre tabindex="0">&lt;code>$ consul
Usage: consul [--version] [--help] &amp;lt;command&amp;gt; [&amp;lt;args&amp;gt;]
Available commands are:
acl Interact with Consul&amp;#39;s ACLs
agent Runs a Consul agent
catalog Interact with the catalog
config Interact with Consul&amp;#39;s Centralized Configurations
connect Interact with Consul Connect
debug Records a debugging archive for operators
event Fire a new event
exec Executes a command on Consul nodes
force-leave Forces a member of the cluster to enter the &amp;#34;left&amp;#34; state
info Provides debugging information for operators.
intention Interact with Connect service intentions
join Tell Consul agent to join cluster
keygen Generates a new encryption key
keyring Manages gossip layer encryption keys
kv Interact with the key-value store
leave Gracefully leaves the Consul cluster and shuts down
lock Execute a command holding a lock
login Login to Consul using an auth method
logout Destroy a Consul token created with login
maint Controls node or service maintenance mode
members Lists the members of a Consul cluster
monitor Stream logs from a Consul agent
operator Provides cluster-level tools for Consul operators
reload Triggers the agent to reload configuration files
rtt Estimates network round trip time between nodes
services Interact with services
snapshot Saves, restores and inspects snapshots of Consul server state
tls Builtin helpers for creating CAs and certificates
validate Validate config files/directories
version Prints the Consul version
watch Watch for changes in Consul
&lt;/code>&lt;/pre>&lt;h1 id="运行agent">运行Agent&lt;/h1>
&lt;p>完成Consul的安装后，可运行Agent。Agent可以运行为Server或Client模式。每个数据中心至少必须拥有一台server，建议在一个集群中部署或者3至5个Server。部署单一的Server，在出现失败时会不可避免的造成数据丢失.&lt;/p>
&lt;p>其他的Agent运行为Client模式，一个Client是一个非常轻量级的进程，用于注册服务，运行健康检查和转发对Server的查询，Agent必须在集群中的每个主机上运行。&lt;/p>
&lt;h2 id="启动agent">启动Agent&lt;/h2>
&lt;p>命令&lt;code>consul agent -dev&lt;/code>可以启动一个开发模式的Agent，这种模式不能用于生产环境，因为它不持久化任何状态。&lt;/p>
&lt;pre tabindex="0">&lt;code>$ consul agent -dev
==&amp;gt; Starting Consul agent...
Version: &amp;#39;v1.6.1&amp;#39;
Node ID: &amp;#39;2e524113-7caf-643a-80bb-a2fa00c2673b&amp;#39;
Node name: &amp;#39;C02Z35N9LVCF&amp;#39;
Datacenter: &amp;#39;dc1&amp;#39; (Segment: &amp;#39;&amp;lt;all&amp;gt;&amp;#39;)
Server: true (Bootstrap: false)
Client Addr: [127.0.0.1] (HTTP: 8500, HTTPS: -1, gRPC: 8502, DNS: 8600)
Cluster Addr: 127.0.0.1 (LAN: 8301, WAN: 8302)
Encrypt: Gossip: false, TLS-Outgoing: false, TLS-Incoming: false, Auto-Encrypt-TLS: false
==&amp;gt; Log data will now stream in as it occurs:
2019/11/20 21:56:09 [DEBUG] agent: Using random ID &amp;#34;2e524113-7caf-643a-80bb-a2fa00c2673b&amp;#34; as node ID
2019/11/20 21:56:09 [DEBUG] tlsutil: Update with version 1
2019/11/20 21:56:09 [DEBUG] tlsutil: OutgoingRPCWrapper with version 1
2019/11/20 21:56:09 [INFO] raft: Initial configuration (index=1): [{Suffrage:Voter ID:2e524113-7caf-643a-80bb-a2fa00c2673b Address:127.0.0.1:8300}]
2019/11/20 21:56:09 [INFO] raft: Node at 127.0.0.1:8300 [Follower] entering Follower state (Leader: &amp;#34;&amp;#34;)
2019/11/20 21:56:09 [INFO] serf: EventMemberJoin: C02Z35N9LVCF.dc1 127.0.0.1
2019/11/20 21:56:09 [INFO] serf: EventMemberJoin: C02Z35N9LVCF 127.0.0.1
2019/11/20 21:56:09 [INFO] consul: Adding LAN server C02Z35N9LVCF (Addr: tcp/127.0.0.1:8300) (DC: dc1)
2019/11/20 21:56:09 [INFO] consul: Handled member-join event for server &amp;#34;C02Z35N9LVCF.dc1&amp;#34; in area &amp;#34;wan&amp;#34;
2019/11/20 21:56:09 [INFO] agent: Started DNS server 127.0.0.1:8600 (tcp)
2019/11/20 21:56:09 [INFO] agent: Started DNS server 127.0.0.1:8600 (udp)
2019/11/20 21:56:09 [INFO] agent: Started HTTP server on 127.0.0.1:8500 (tcp)
2019/11/20 21:56:09 [INFO] agent: Started gRPC server on 127.0.0.1:8502 (tcp)
2019/11/20 21:56:09 [INFO] agent: started state syncer
==&amp;gt; Consul agent running!
2019/11/20 21:56:09 [WARN] raft: Heartbeat timeout from &amp;#34;&amp;#34; reached, starting election
2019/11/20 21:56:09 [INFO] raft: Node at 127.0.0.1:8300 [Candidate] entering Candidate state in term 2
2019/11/20 21:56:09 [DEBUG] raft: Votes needed: 1
2019/11/20 21:56:09 [DEBUG] raft: Vote granted from 2e524113-7caf-643a-80bb-a2fa00c2673b in term 2. Tally: 1
2019/11/20 21:56:09 [INFO] raft: Election won. Tally: 1
2019/11/20 21:56:09 [INFO] raft: Node at 127.0.0.1:8300 [Leader] entering Leader state
2019/11/20 21:56:09 [INFO] consul: cluster leadership acquired
2019/11/20 21:56:09 [INFO] consul: New leader elected: C02Z35N9LVCF
2019/11/20 21:56:09 [INFO] connect: initialized primary datacenter CA with provider &amp;#34;consul&amp;#34;
2019/11/20 21:56:09 [DEBUG] consul: Skipping self join check for &amp;#34;C02Z35N9LVCF&amp;#34; since the cluster is too small
2019/11/20 21:56:09 [INFO] consul: member &amp;#39;C02Z35N9LVCF&amp;#39; joined, marking health alive
2019/11/20 21:56:09 [DEBUG] agent: Skipping remote check &amp;#34;serfHealth&amp;#34; since it is managed automatically
2019/11/20 21:56:09 [INFO] agent: Synced node info
2019/11/20 21:56:09 [DEBUG] agent: Node info in sync
2019/11/20 21:56:09 [DEBUG] agent: Skipping remote check &amp;#34;serfHealth&amp;#34; since it is managed automatically
2019/11/20 21:56:09 [DEBUG] agent: Node info in sync
2019/11/20 21:56:11 [DEBUG] tlsutil: OutgoingRPCWrapper with version 1
&lt;/code>&lt;/pre>&lt;h2 id="集群成员">集群成员&lt;/h2>
&lt;p>新开一个终端窗口运行&lt;code>consul members&lt;/code>, 就可以看到Consul集群的成员。&lt;/p>
&lt;pre tabindex="0">&lt;code>$ consul members
Node Address Status Type Build Protocol DC Segment
C02Z35N9LVCF 127.0.0.1:8301 alive server 1.6.1 2 dc1 &amp;lt;all&amp;gt;
&lt;/code>&lt;/pre>&lt;p>以上输出显示了我们自己的节点运行的节点、地址、健康状态、自己在集群中的角色、版本信息等。添加&lt;code>-detailed&lt;/code>选项可以查看到额外的信息，如下：&lt;/p>
&lt;pre tabindex="0">&lt;code>$ consul members --detailed
Node Address Status Tags
C02Z35N9LVCF 127.0.0.1:8301 alive acls=0,build=1.6.1:9be6dfc+,dc=dc1,id=2e524113-7caf-643a-80bb-a2fa00c2673b,port=8300,raft_vsn=3,role=consul,segment=&amp;lt;all&amp;gt;,vsn=2,vsn_max=3,vsn_min=2,wan_join_port=8302
&lt;/code>&lt;/pre>&lt;p>&lt;code>members&lt;/code>命令的输出是基于gossip协议，它是最终一致的。这意味着，在任何时候，通过你本地Agent看到的结果可能不能准确匹配server的状态。为了查看到一致的信息，可使用HTTP API(将自动转发)到Consul Server上去进行查询：&lt;/p>
&lt;pre tabindex="0">&lt;code>$ curl localhost:8500/v1/catalog/nodes
[
{
&amp;#34;ID&amp;#34;: &amp;#34;2e524113-7caf-643a-80bb-a2fa00c2673b&amp;#34;,
&amp;#34;Node&amp;#34;: &amp;#34;C02Z35N9LVCF&amp;#34;,
&amp;#34;Address&amp;#34;: &amp;#34;127.0.0.1&amp;#34;,
&amp;#34;Datacenter&amp;#34;: &amp;#34;dc1&amp;#34;,
&amp;#34;TaggedAddresses&amp;#34;: {
&amp;#34;lan&amp;#34;: &amp;#34;127.0.0.1&amp;#34;,
&amp;#34;wan&amp;#34;: &amp;#34;127.0.0.1&amp;#34;
},
&amp;#34;Meta&amp;#34;: {
&amp;#34;consul-network-segment&amp;#34;: &amp;#34;&amp;#34;
},
&amp;#34;CreateIndex&amp;#34;: 9,
&amp;#34;ModifyIndex&amp;#34;: 10
}
]
&lt;/code>&lt;/pre>&lt;h2 id="停止agent">停止Agent&lt;/h2>
&lt;p>你可以使用 Ctrl-C 优雅的关闭Agent，中断Agent之后你可以看到它离开了集群并关闭.
退出后，Consul提醒其他集群成员，这个节点离开了。如果你强行杀掉进程，集群的其他成员应该能检测到这个节点失效了。当一个成员离开，他的服务和检测也会从目录中移除。当一个成员失效了，他的健康状况被简单的标记为危险，但是不会从目录中移除。Consul会自动尝试对失效的节点进行重连，允许他从某些网络条件下恢复过来。&lt;/p>
&lt;h1 id="注册服务">注册服务&lt;/h1>
&lt;p>在之前的步骤我们运行了第一个agent，看到了集群的成员。现在我们将注册第一个服务并查询这些服务。&lt;/p>
&lt;h2 id="定义一个服务">定义一个服务&lt;/h2>
&lt;p>可以通过提供服务定义或者调用HTTP API来注册一个服务，服务定义文件是注册服务的最通用的方式。&lt;/p>
&lt;p>首先，为Consul配置创建一个目录：&lt;/p>
&lt;pre tabindex="0">&lt;code>$ sudo mkdir /etc/consul.d
&lt;/code>&lt;/pre>&lt;p>然后，编写服务定义配置文件。假设我们有一个名叫web的服务运行在 80端口。另外，我们将给他设置一个标签，这样我们可以使用它作为额外的查询方式：&lt;/p>
&lt;pre tabindex="0">&lt;code>echo &amp;#39;{&amp;#34;service&amp;#34;: {&amp;#34;name&amp;#34;: &amp;#34;web&amp;#34;, &amp;#34;tags&amp;#34;: [&amp;#34;rails&amp;#34;], &amp;#34;port&amp;#34;: 80}}&amp;#39; &amp;gt; /etc/consul.d/web.json
&lt;/code>&lt;/pre>&lt;p>重新启动Agent，设置配置目录：&lt;/p>
&lt;pre tabindex="0">&lt;code>$ sudo consul agent -dev -config-dir /etc/consul.d/web.json
==&amp;gt; Starting Consul agent...
Version: &amp;#39;v1.6.1&amp;#39;
Node ID: &amp;#39;feba8d74-4a3a-9b42-305f-eea7da207c9c&amp;#39;
Node name: &amp;#39;C02Z35N9LVCF&amp;#39;
Datacenter: &amp;#39;dc1&amp;#39; (Segment: &amp;#39;&amp;lt;all&amp;gt;&amp;#39;)
Server: true (Bootstrap: false)
Client Addr: [127.0.0.1] (HTTP: 8500, HTTPS: -1, gRPC: 8502, DNS: 8600)
Cluster Addr: 127.0.0.1 (LAN: 8301, WAN: 8302)
Encrypt: Gossip: false, TLS-Outgoing: false, TLS-Incoming: false, Auto-Encrypt-TLS: false
==&amp;gt; Log data will now stream in as it occurs:
2019/11/20 22:17:29 [DEBUG] agent: Using random ID &amp;#34;feba8d74-4a3a-9b42-305f-eea7da207c9c&amp;#34; as node ID
2019/11/20 22:17:29 [DEBUG] tlsutil: Update with version 1
2019/11/20 22:17:29 [DEBUG] tlsutil: OutgoingRPCWrapper with version 1
2019/11/20 22:17:29 [INFO] raft: Initial configuration (index=1): [{Suffrage:Voter ID:feba8d74-4a3a-9b42-305f-eea7da207c9c Address:127.0.0.1:8300}]
2019/11/20 22:17:29 [INFO] raft: Node at 127.0.0.1:8300 [Follower] entering Follower state (Leader: &amp;#34;&amp;#34;)
2019/11/20 22:17:29 [INFO] serf: EventMemberJoin: C02Z35N9LVCF.dc1 127.0.0.1
2019/11/20 22:17:29 [INFO] serf: EventMemberJoin: C02Z35N9LVCF 127.0.0.1
2019/11/20 22:17:29 [INFO] consul: Adding LAN server C02Z35N9LVCF (Addr: tcp/127.0.0.1:8300) (DC: dc1)
2019/11/20 22:17:29 [INFO] consul: Handled member-join event for server &amp;#34;C02Z35N9LVCF.dc1&amp;#34; in area &amp;#34;wan&amp;#34;
2019/11/20 22:17:29 [INFO] agent: Started DNS server 127.0.0.1:8600 (tcp)
2019/11/20 22:17:29 [INFO] agent: Started DNS server 127.0.0.1:8600 (udp)
2019/11/20 22:17:29 [INFO] agent: Started HTTP server on 127.0.0.1:8500 (tcp)
2019/11/20 22:17:29 [INFO] agent: Started gRPC server on 127.0.0.1:8502 (tcp)
2019/11/20 22:17:29 [INFO] agent: started state syncer
==&amp;gt; Consul agent running!
2019/11/20 22:17:30 [WARN] raft: Heartbeat timeout from &amp;#34;&amp;#34; reached, starting election
2019/11/20 22:17:30 [INFO] raft: Node at 127.0.0.1:8300 [Candidate] entering Candidate state in term 2
2019/11/20 22:17:30 [DEBUG] raft: Votes needed: 1
2019/11/20 22:17:30 [DEBUG] raft: Vote granted from feba8d74-4a3a-9b42-305f-eea7da207c9c in term 2. Tally: 1
2019/11/20 22:17:30 [INFO] raft: Election won. Tally: 1
2019/11/20 22:17:30 [INFO] raft: Node at 127.0.0.1:8300 [Leader] entering Leader state
2019/11/20 22:17:30 [INFO] consul: cluster leadership acquired
2019/11/20 22:17:30 [INFO] consul: New leader elected: C02Z35N9LVCF
2019/11/20 22:17:30 [INFO] connect: initialized primary datacenter CA with provider &amp;#34;consul&amp;#34;
2019/11/20 22:17:30 [DEBUG] consul: Skipping self join check for &amp;#34;C02Z35N9LVCF&amp;#34; since the cluster is too small
2019/11/20 22:17:30 [INFO] consul: member &amp;#39;C02Z35N9LVCF&amp;#39; joined, marking health alive
2019/11/20 22:17:30 [DEBUG] agent: Skipping remote check &amp;#34;serfHealth&amp;#34; since it is managed automatically
2019/11/20 22:17:30 [INFO] agent: Synced service &amp;#34;web&amp;#34;
2019/11/20 22:17:30 [DEBUG] agent: Node info in sync
2019/11/20 22:17:32 [DEBUG] tlsutil: OutgoingRPCWrapper with version 1
2019/11/20 22:17:32 [DEBUG] agent: Skipping remote check &amp;#34;serfHealth&amp;#34; since it is managed automatically
2019/11/20 22:17:32 [DEBUG] agent: Service &amp;#34;web&amp;#34; in sync
2019/11/20 22:17:32 [DEBUG] agent: Node info in sync
2019/11/20 22:17:32 [DEBUG] agent: Service &amp;#34;web&amp;#34; in sync
2019/11/20 22:17:32 [DEBUG] agent: Node info in sync
&lt;/code>&lt;/pre>&lt;p>日志中的&lt;code>Synced service 'web'&lt;/code>表示Agent从配置文件中载入了服务定义，并且成功注册到服务目录。&lt;/p>
&lt;p>如果想注册多个服务，就可以在Consul配置目录创建多个服务定义文件。&lt;/p>
&lt;h2 id="查询服务">查询服务&lt;/h2>
&lt;p>一旦Agent启动并且服务同步了，我们可就以通过DNS或者HTTP API来查询服务。&lt;/p>
&lt;h3 id="dns-api">DNS API&lt;/h3>
&lt;p>我们首先使用DNS API来查询。在DNS API中，服务的DNS名字是 &lt;code>NAME.service.consul&lt;/code>。虽然是可配置的，但默认的所有DNS名字会都在consul命名空间下，这个子域告诉Consul，我们在查询服务，&lt;code>NAME&lt;/code>则是服务的名称.&lt;/p>
&lt;p>对于我们上面注册的Web服务.它的域名是 &lt;code>web.service.consul&lt;/code>:&lt;/p>
&lt;pre tabindex="0">&lt;code>$ dig @127.0.0.1 -p 8600 web.service.consul
; &amp;lt;&amp;lt;&amp;gt;&amp;gt; DiG 9.10.6 &amp;lt;&amp;lt;&amp;gt;&amp;gt; @127.0.0.1 -p 8600 web.service.consul
; (1 server found)
;; global options: +cmd
;; Got answer:
;; -&amp;gt;&amp;gt;HEADER&amp;lt;&amp;lt;- opcode: QUERY, status: NOERROR, id: 27222
;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 2
;; WARNING: recursion requested but not available
;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 4096
;; QUESTION SECTION:
;web.service.consul. IN A
;; ANSWER SECTION:
web.service.consul. 0 IN A 127.0.0.1
;; ADDITIONAL SECTION:
web.service.consul. 0 IN TXT &amp;#34;consul-network-segment=&amp;#34;
;; Query time: 8 msec
;; SERVER: 127.0.0.1#8600(127.0.0.1)
;; WHEN: Wed Nov 20 22:26:14 CST 2019
;; MSG SIZE rcvd: 99
&lt;/code>&lt;/pre>&lt;p>如你所见,一个A记录返回了一个可用的服务所在的节点的IP地址。A记录只能设置为IP地址，有也可用使用 DNS API 来接收包含地址和端口的 &lt;code>SRV&lt;/code> 记录：&lt;/p>
&lt;pre tabindex="0">&lt;code>$ dig @127.0.0.1 -p 8600 web.service.consul SRV
; &amp;lt;&amp;lt;&amp;gt;&amp;gt; DiG 9.10.6 &amp;lt;&amp;lt;&amp;gt;&amp;gt; @127.0.0.1 -p 8600 web.service.consul SRV
; (1 server found)
;; global options: +cmd
;; Got answer:
;; -&amp;gt;&amp;gt;HEADER&amp;lt;&amp;lt;- opcode: QUERY, status: NOERROR, id: 49043
;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 3
;; WARNING: recursion requested but not available
;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 4096
;; QUESTION SECTION:
;web.service.consul. IN SRV
;; ANSWER SECTION:
web.service.consul. 0 IN SRV 1 1 80 C02Z35N9LVCF.node.dc1.consul.
;; ADDITIONAL SECTION:
C02Z35N9LVCF.node.dc1.consul. 0 IN A 127.0.0.1
C02Z35N9LVCF.node.dc1.consul. 0 IN TXT &amp;#34;consul-network-segment=&amp;#34;
;; Query time: 1 msec
;; SERVER: 127.0.0.1#8600(127.0.0.1)
;; WHEN: Wed Nov 20 22:28:14 CST 2019
;; MSG SIZE rcvd: 147
&lt;/code>&lt;/pre>&lt;p>&lt;code>SRV&lt;/code>记录告诉我们 web 这个服务运行于节点&lt;code>C02Z35N9LVCF.node.dc1.consul&lt;/code> 的80端口，DNS额外返回了节点的A记录。&lt;/p>
&lt;p>最后，我们也可以用 DNS API 通过标签来过滤服务，基于标签的服务查询格式为&lt;code>TAG.NAME.service.consul&lt;/code>。在下面的例子中，我们请求Consul返回有 rails标签的 web服务：&lt;/p>
&lt;pre tabindex="0">&lt;code>$ dig @127.0.0.1 -p 8600 rails.web.service.consul SRV
# 输出信息略
&lt;/code>&lt;/pre>&lt;h3 id="http-api">HTTP API&lt;/h3>
&lt;p>除了DNS API之外，也可以使用HTTP API查询所有服务实例：&lt;/p>
&lt;pre tabindex="0">&lt;code>$ curl http://localhost:8500/v1/catalog/service/web
[
{
&amp;#34;ID&amp;#34;: &amp;#34;feba8d74-4a3a-9b42-305f-eea7da207c9c&amp;#34;,
&amp;#34;Node&amp;#34;: &amp;#34;C02Z35N9LVCF&amp;#34;,
&amp;#34;Address&amp;#34;: &amp;#34;127.0.0.1&amp;#34;,
&amp;#34;Datacenter&amp;#34;: &amp;#34;dc1&amp;#34;,
&amp;#34;TaggedAddresses&amp;#34;: {
&amp;#34;lan&amp;#34;: &amp;#34;127.0.0.1&amp;#34;,
&amp;#34;wan&amp;#34;: &amp;#34;127.0.0.1&amp;#34;
},
&amp;#34;NodeMeta&amp;#34;: {
&amp;#34;consul-network-segment&amp;#34;: &amp;#34;&amp;#34;
},
&amp;#34;ServiceKind&amp;#34;: &amp;#34;&amp;#34;,
&amp;#34;ServiceID&amp;#34;: &amp;#34;web&amp;#34;,
&amp;#34;ServiceName&amp;#34;: &amp;#34;web&amp;#34;,
&amp;#34;ServiceTags&amp;#34;: [
&amp;#34;rails&amp;#34;
],
&amp;#34;ServiceAddress&amp;#34;: &amp;#34;&amp;#34;,
&amp;#34;ServiceWeights&amp;#34;: {
&amp;#34;Passing&amp;#34;: 1,
&amp;#34;Warning&amp;#34;: 1
},
&amp;#34;ServiceMeta&amp;#34;: {},
&amp;#34;ServicePort&amp;#34;: 80,
&amp;#34;ServiceEnableTagOverride&amp;#34;: false,
&amp;#34;ServiceProxy&amp;#34;: {
&amp;#34;MeshGateway&amp;#34;: {}
},
&amp;#34;ServiceConnect&amp;#34;: {},
&amp;#34;CreateIndex&amp;#34;: 10,
&amp;#34;ModifyIndex&amp;#34;: 10
}
]
&lt;/code>&lt;/pre>&lt;p>只查看健康服务实例的方法：&lt;/p>
&lt;pre tabindex="0">&lt;code>$ curl http://localhost:8500/v1/catalog/service/web?passing
# 输出信息略
&lt;/code>&lt;/pre>&lt;h2 id="更新服务">更新服务&lt;/h2>
&lt;p>服务定义可以通过修改配置文件并发送&lt;code>SIGHUP&lt;/code>给Agent来进行更新，这样可以在不关闭服务或者保持服务请求可用的情况下进行更新。&lt;/p>
&lt;p>参考来源：&lt;/p>
&lt;ol>
&lt;li>&lt;a href="https://github.com/hashicorp/consul">https://github.com/hashicorp/consul&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.consul.io/intro/getting-started.html">https://www.consul.io/intro/getting-started.html&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://book-consul-guide.vnzmi.com/01_what_is_consul.html">https://book-consul-guide.vnzmi.com/01_what_is_consul.html&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>JSON Web Token入门手册</title><link>https://xzygis.github.io/2020/01/30/json-web-token%E5%85%A5%E9%97%A8%E6%89%8B%E5%86%8C/</link><pubDate>Thu, 30 Jan 2020 13:10:39 +0000</pubDate><guid>https://xzygis.github.io/2020/01/30/json-web-token%E5%85%A5%E9%97%A8%E6%89%8B%E5%86%8C/</guid><description>&lt;h1 id="跨域认证问题">跨域认证问题&lt;/h1>
&lt;p>互联网服务离不开用户认证。一般流程是下面这样：&lt;/p>
&lt;ol>
&lt;li>用户向服务器发送用户名和密码。&lt;/li>
&lt;li>服务器验证通过后，在当前对话（session）里面保存相关数据，比如用户角色、登录时间等等。&lt;/li>
&lt;li>服务器向用户返回一个 session_id，写入用户的 Cookie。&lt;/li>
&lt;li>用户随后的每一次请求，都会通过 Cookie，将 session_id 传回服务器。&lt;/li>
&lt;li>服务器收到 session_id，找到前期保存的数据，由此得知用户的身份。&lt;/li>
&lt;/ol>
&lt;p>这种模式的问题在于，扩展性（scaling）不好。单机当然没有问题，如果是服务器集群，或者是跨域的服务导向架构，就要求 session 数据共享，每台服务器都能够读取 session。&lt;/p>
&lt;p>举例来说，A 网站和 B 网站是同一家公司的关联服务。现在要求，用户只要在其中一个网站登录，再访问另一个网站就会自动登录，请问怎么实现？&lt;/p>
&lt;ul>
&lt;li>一种解决方案是 session 数据持久化，写入数据库或别的持久层。各种服务收到请求后，都向持久层请求数据。这种方案的优点是架构清晰，缺点是工程量比较大。另外，持久层万一挂了，就会单点失败。&lt;/li>
&lt;li>另一种方案是服务器索性不保存 session 数据了，所有数据都保存在客户端，每次请求都发回服务器。JWT 就是这种方案的一个代表。&lt;/li>
&lt;/ul>
&lt;!-- raw HTML omitted -->
&lt;h1 id="什么是jwt">什么是JWT？&lt;/h1>
&lt;p>Json web token (JWT)，是为了在网络应用环境间传递声明而执行的一种基于JSON的开放标准（(RFC 7519)。该token被设计为紧凑且安全的，特别适用于分布式站点的单点登录（SSO）场景。JWT的声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源，也可以增加一些额外的其它业务逻辑所必须的声明信息，该token可直接被用于认证，也可被加密。&lt;/p>
&lt;h1 id="jwt-的原理">JWT 的原理&lt;/h1>
&lt;p>服务器认证以后，生成一个经过签名的 JSON 对象，发回给用户，服务器则不用保存任何 session 数据了。从而把服务器变成无状态的，易于实现扩展。&lt;/p>
&lt;h1 id="jwt-的使用场景">JWT 的使用场景&lt;/h1>
&lt;p>以下是两个JWT的应用场景：&lt;/p>
&lt;ol>
&lt;li>鉴权：这是JWT最常见的应用场景。当用户登录成功后，随后的每个请求都将带上JWT，从而允许用户访问被授权的服务和资源。由于它开销小切易于使用，当前被广泛应用于单点登录（Single Sign On）。&lt;/li>
&lt;li>信息交换：JWT是不同组织间交换信息的一种很好的方式。因为JWT可以被签名（例如，通过公钥/私钥对），你可以确信信息发送者就是它们说声明的身份。此外，签名是用Header和Payload计算出来的，你可以验证内容是否被篡改。&lt;/li>
&lt;/ol>
&lt;h1 id="jwt-的数据结构">JWT 的数据结构&lt;/h1>
&lt;p>扁平化形式的JWT是由通过 &lt;code>.&lt;/code> 分隔的三部分组成，他们分别是：&lt;/p>
&lt;ul>
&lt;li>&lt;code>Header&lt;/code>&lt;/li>
&lt;li>&lt;code>Payload&lt;/code>&lt;/li>
&lt;li>&lt;code>Signature&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>所以，一个JWT看起来通常是如下的形式：&lt;/p>
&lt;pre tabindex="0">&lt;code>xxxxx.yyyyy.zzzzz
&lt;/code>&lt;/pre>&lt;h2 id="header">Header&lt;/h2>
&lt;p>头部由两部分组成：&lt;/p>
&lt;ul>
&lt;li>token类型，即JWT；&lt;/li>
&lt;li>签名算法，例如HMAC SHA256或RSA。&lt;/li>
&lt;/ul>
&lt;p>一个Header的例子：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;alg&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;HS256&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;typ&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;JWT&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>随后，以上JSON对象会通过 &lt;code>Base64Url&lt;/code> 编码为JWT的第一部分。&lt;/p>
&lt;h2 id="payload">Payload&lt;/h2>
&lt;p>载荷就是存放有效信息的地方。这个名字像是特指飞机上承载的货品，这些有效信息包含三个部分&lt;/p>
&lt;ul>
&lt;li>标准中注册的声明&lt;/li>
&lt;li>公共的声明&lt;/li>
&lt;li>私有的声明&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>标准中注册的声明：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>iss: jwt签发者&lt;/li>
&lt;li>sub: jwt所面向的用户&lt;/li>
&lt;li>aud: 接收jwt的一方&lt;/li>
&lt;li>exp: jwt的过期时间，这个过期时间必须要大于签发时间&lt;/li>
&lt;li>nbf: 定义在什么时间之前，该jwt都是不可用的.&lt;/li>
&lt;li>iat: jwt的签发时间&lt;/li>
&lt;li>jti: jwt的唯一身份标识，主要用来作为一次性token,从而回避重放攻击。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>公共的声明 ：&lt;/strong>
公共的声明可以添加任何的信息，一般添加用户的相关信息或其他业务需要的必要信息.但不建议添加敏感信息，因为该部分在客户端可解密。&lt;/p>
&lt;p>&lt;strong>私有的声明 ：&lt;/strong>
私有声明是提供者和消费者所共同定义的声明，一般不建议存放敏感信息，因为base64是对称解密的，意味着该部分信息可以归类为明文信息。&lt;/p>
&lt;p>一个Payload的例子：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;sub&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;1234567890&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;name&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;John Doe&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;admin&amp;#34;&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>随后，Payload会通过 &lt;code>Base64Url&lt;/code> 编码为JWT的第二部分。&lt;/p>
&lt;h2 id="signature">Signature&lt;/h2>
&lt;p>创建签名需要用到编码后的 Header、编码后的 Payload、秘钥、Header中指定的算法。&lt;/p>
&lt;p>如果你想使用HMAC SHA256算法，签名将通过如下方式生成：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-go" data-lang="go">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">HMACSHA256&lt;/span>(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">base64UrlEncode&lt;/span>(&lt;span style="color:#a6e22e">header&lt;/span>) &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#34;.&amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">base64UrlEncode&lt;/span>(&lt;span style="color:#a6e22e">payload&lt;/span>),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">secret&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>如果你想把以上概念付诸实践，可以通过 &lt;a href="https://jwt.io/">https://jwt.io/&lt;/a> 提供的工具来玩一玩 JWT 。如下图所示：&lt;img src="jwt-example.png" alt="jwt.io">&lt;/p>
&lt;h1 id="jwt-的使用方式">JWT 的使用方式&lt;/h1>
&lt;p>客户端收到服务器返回的 JWT，可以储存在 Cookie 里面，也可以储存在 localStorage。
此后，客户端每次与服务器通信，都要带上这个 JWT。你可以把它放在 Cookie 里面自动发送，但是这样不能跨域，所以更好的做法是放在 HTTP 请求的头信息Authorization字段里面。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-js" data-lang="js">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">Authorization&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">Bearer&lt;/span> &lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#a6e22e">token&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>另一种做法是，跨域的时候，JWT 就放在 POST 请求的数据体里面。&lt;/p>
&lt;h1 id="jwt-的几个特点">JWT 的几个特点&lt;/h1>
&lt;ul>
&lt;li>JWT 默认是不加密，但也是可以加密的。生成原始 Token 以后，可以用密钥再加密一次。&lt;/li>
&lt;li>JWT 不加密的情况下，不能将秘密数据写入 JWT。&lt;/li>
&lt;li>JWT 不仅可以用于认证，也可以用于交换信息。有效使用 JWT，可以降低服务器查询数据库的次数。&lt;/li>
&lt;li>JWT 的最大缺点是，由于服务器不保存 session 状态，因此无法在使用过程中废止某个 token，或者更改 token 的权限。也就是说，一旦 JWT 签发了，在到期之前就会始终有效，除非服务器部署额外的逻辑。&lt;/li>
&lt;li>JWT 本身包含了认证信息，一旦泄露，任何人都可以获得该令牌的所有权限。为了减少盗用，JWT 的有效期应该设置得比较短。对于一些比较重要的权限，使用时应该再次对用户进行认证。&lt;/li>
&lt;li>为了减少盗用，JWT 不应该使用 HTTP 协议明码传输，要使用 HTTPS 协议传输。&lt;/li>
&lt;/ul>
&lt;h1 id="示例代码">示例代码&lt;/h1>
&lt;p>Go语言版本：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-go" data-lang="go">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">package&lt;/span> &lt;span style="color:#a6e22e">util&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> (
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;crypto/rsa&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;crypto/x509&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;encoding/pem&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;errors&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;fmt&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;github.com/dgrijalva/jwt-go&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">ErrVerifyFailed&lt;/span> = &lt;span style="color:#a6e22e">fmt&lt;/span>.&lt;span style="color:#a6e22e">Errorf&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;verify failed&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">//https://godoc.org/github.com/dgrijalva/jwt-go#example-New--Hmac
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">func&lt;/span> &lt;span style="color:#a6e22e">CreateToken&lt;/span>(&lt;span style="color:#a6e22e">claims&lt;/span> &lt;span style="color:#a6e22e">jwt&lt;/span>.&lt;span style="color:#a6e22e">MapClaims&lt;/span>, &lt;span style="color:#a6e22e">privateKey&lt;/span> []&lt;span style="color:#66d9ef">byte&lt;/span>) (&lt;span style="color:#66d9ef">string&lt;/span>, &lt;span style="color:#66d9ef">error&lt;/span>) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">token&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">jwt&lt;/span>.&lt;span style="color:#a6e22e">NewWithClaims&lt;/span>(&lt;span style="color:#a6e22e">jwt&lt;/span>.&lt;span style="color:#a6e22e">SigningMethodRS512&lt;/span>, &lt;span style="color:#a6e22e">claims&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">block&lt;/span>, &lt;span style="color:#a6e22e">_&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">pem&lt;/span>.&lt;span style="color:#a6e22e">Decode&lt;/span>(&lt;span style="color:#a6e22e">privateKey&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#a6e22e">block&lt;/span> &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#66d9ef">nil&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>, &lt;span style="color:#a6e22e">errors&lt;/span>.&lt;span style="color:#a6e22e">New&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;private key error&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">priv&lt;/span>, &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">x509&lt;/span>.&lt;span style="color:#a6e22e">ParsePKCS8PrivateKey&lt;/span>(&lt;span style="color:#a6e22e">block&lt;/span>.&lt;span style="color:#a6e22e">Bytes&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">!=&lt;/span> &lt;span style="color:#66d9ef">nil&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>, &lt;span style="color:#a6e22e">err&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">token&lt;/span>.&lt;span style="color:#a6e22e">SignedString&lt;/span>(&lt;span style="color:#a6e22e">priv&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">//https://godoc.org/github.com/dgrijalva/jwt-go#example-Parse--Hmac
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">func&lt;/span> &lt;span style="color:#a6e22e">VerifyToken&lt;/span>(&lt;span style="color:#a6e22e">tokenString&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span>, &lt;span style="color:#a6e22e">publicKey&lt;/span> []&lt;span style="color:#66d9ef">byte&lt;/span>) (&lt;span style="color:#a6e22e">jwt&lt;/span>.&lt;span style="color:#a6e22e">MapClaims&lt;/span>, &lt;span style="color:#66d9ef">error&lt;/span>) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">token&lt;/span>, &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">jwt&lt;/span>.&lt;span style="color:#a6e22e">Parse&lt;/span>(&lt;span style="color:#a6e22e">tokenString&lt;/span>, &lt;span style="color:#66d9ef">func&lt;/span>(&lt;span style="color:#a6e22e">token&lt;/span> &lt;span style="color:#f92672">*&lt;/span>&lt;span style="color:#a6e22e">jwt&lt;/span>.&lt;span style="color:#a6e22e">Token&lt;/span>) (&lt;span style="color:#66d9ef">interface&lt;/span>{}, &lt;span style="color:#66d9ef">error&lt;/span>) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#a6e22e">_&lt;/span>, &lt;span style="color:#a6e22e">ok&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">token&lt;/span>.&lt;span style="color:#a6e22e">Method&lt;/span>.(&lt;span style="color:#f92672">*&lt;/span>&lt;span style="color:#a6e22e">jwt&lt;/span>.&lt;span style="color:#a6e22e">SigningMethodRSA&lt;/span>); !&lt;span style="color:#a6e22e">ok&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">nil&lt;/span>, &lt;span style="color:#a6e22e">fmt&lt;/span>.&lt;span style="color:#a6e22e">Errorf&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;unexpected signing method: %v&amp;#34;&lt;/span>, &lt;span style="color:#a6e22e">token&lt;/span>.&lt;span style="color:#a6e22e">Header&lt;/span>[&lt;span style="color:#e6db74">&amp;#34;alg&amp;#34;&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#a6e22e">token&lt;/span>.&lt;span style="color:#a6e22e">Header&lt;/span>[&lt;span style="color:#e6db74">&amp;#34;alg&amp;#34;&lt;/span>] &lt;span style="color:#f92672">!=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;RS512&amp;#34;&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">nil&lt;/span>, &lt;span style="color:#a6e22e">fmt&lt;/span>.&lt;span style="color:#a6e22e">Errorf&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;unexpected siging alg: %v&amp;#34;&lt;/span>, &lt;span style="color:#a6e22e">token&lt;/span>.&lt;span style="color:#a6e22e">Header&lt;/span>[&lt;span style="color:#e6db74">&amp;#34;alg&amp;#34;&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">block&lt;/span>, &lt;span style="color:#a6e22e">_&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">pem&lt;/span>.&lt;span style="color:#a6e22e">Decode&lt;/span>(&lt;span style="color:#a6e22e">publicKey&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#a6e22e">block&lt;/span> &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#66d9ef">nil&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">nil&lt;/span>, &lt;span style="color:#a6e22e">ErrVerifyFailed&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">pubInterface&lt;/span>, &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">x509&lt;/span>.&lt;span style="color:#a6e22e">ParsePKIXPublicKey&lt;/span>(&lt;span style="color:#a6e22e">block&lt;/span>.&lt;span style="color:#a6e22e">Bytes&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">!=&lt;/span> &lt;span style="color:#66d9ef">nil&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">nil&lt;/span>, &lt;span style="color:#a6e22e">ErrVerifyFailed&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">pub&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">pubInterface&lt;/span>.(&lt;span style="color:#f92672">*&lt;/span>&lt;span style="color:#a6e22e">rsa&lt;/span>.&lt;span style="color:#a6e22e">PublicKey&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">pub&lt;/span>, &lt;span style="color:#66d9ef">nil&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> })
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">!=&lt;/span> &lt;span style="color:#66d9ef">nil&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">nil&lt;/span>, &lt;span style="color:#a6e22e">ErrVerifyFailed&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#a6e22e">claims&lt;/span>, &lt;span style="color:#a6e22e">ok&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">token&lt;/span>.&lt;span style="color:#a6e22e">Claims&lt;/span>.(&lt;span style="color:#a6e22e">jwt&lt;/span>.&lt;span style="color:#a6e22e">MapClaims&lt;/span>); &lt;span style="color:#a6e22e">ok&lt;/span> &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> &lt;span style="color:#a6e22e">token&lt;/span>.&lt;span style="color:#a6e22e">Valid&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">claims&lt;/span>, &lt;span style="color:#66d9ef">nil&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">nil&lt;/span>, &lt;span style="color:#a6e22e">ErrVerifyFailed&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>参考来源：&lt;/p>
&lt;ol>
&lt;li>&lt;a href="https://jwt.io/introduction/">https://jwt.io/introduction/&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.jianshu.com/p/576dbf44b2ae">https://www.jianshu.com/p/576dbf44b2ae&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.ruanyifeng.com/blog/2018/07/json_web_token-tutorial.html">https://www.ruanyifeng.com/blog/2018/07/json_web_token-tutorial.html&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>Docker之容器使用</title><link>https://xzygis.github.io/2020/01/30/docker%E4%B9%8B%E5%AE%B9%E5%99%A8%E4%BD%BF%E7%94%A8/</link><pubDate>Thu, 30 Jan 2020 13:01:19 +0000</pubDate><guid>https://xzygis.github.io/2020/01/30/docker%E4%B9%8B%E5%AE%B9%E5%99%A8%E4%BD%BF%E7%94%A8/</guid><description>&lt;h2 id="获取镜像">获取镜像&lt;/h2>
&lt;pre tabindex="0">&lt;code>$ docker pull ubuntu
&lt;/code>&lt;/pre>&lt;h2 id="启动容器">启动容器：&lt;/h2>
&lt;pre tabindex="0">&lt;code>$ docker run -it ubuntu /bin/bash
# 要退出终端，直接输入 exit
&lt;/code>&lt;/pre>&lt;!-- raw HTML omitted -->
&lt;h2 id="启动已停止运行的容器">启动已停止运行的容器&lt;/h2>
&lt;pre tabindex="0">&lt;code>$ docker ps -a
&lt;/code>&lt;/pre>&lt;h2 id="启动已停止运行的容器-1">启动已停止运行的容器&lt;/h2>
&lt;pre tabindex="0">&lt;code>$ docker start b750bbbcfd88
&lt;/code>&lt;/pre>&lt;h2 id="后台运行">后台运行&lt;/h2>
&lt;pre tabindex="0">&lt;code>$ docker run -itd --name ubuntu-test ubuntu /bin/bash
&lt;/code>&lt;/pre>&lt;h2 id="停止一个容器">停止一个容器&lt;/h2>
&lt;pre tabindex="0">&lt;code>$ docker stop &amp;lt;容器 ID&amp;gt;
&lt;/code>&lt;/pre>&lt;p>停止的容器可以通过 docker restart 重启：&lt;/p>
&lt;pre tabindex="0">&lt;code>$ docker restart &amp;lt;容器 ID&amp;gt;
&lt;/code>&lt;/pre>&lt;h2 id="进入容器">进入容器&lt;/h2>
&lt;p>在使用 &lt;code>-d&lt;/code> 参数时，容器启动后会进入后台。此时想要进入容器，可以通过以下指令进入：&lt;/p>
&lt;ul>
&lt;li>&lt;code>docker attach&lt;/code>： 如果从这个容器退出（&lt;code>exit&lt;/code>），会导致容器的停止。&lt;/li>
&lt;li>&lt;code>docker exec&lt;/code>：推荐大家使用 &lt;code>docker exec&lt;/code> 命令，因为此退出容器终端，不会导致容器的停止。&lt;/li>
&lt;/ul>
&lt;p>exec命令使用：&lt;/p>
&lt;pre tabindex="0">&lt;code>$ docker exec -it 243c32535da7 /bin/bash
&lt;/code>&lt;/pre>&lt;h2 id="导出和导入容器">导出和导入容器&lt;/h2>
&lt;h3 id="导出容器">导出容器&lt;/h3>
&lt;pre tabindex="0">&lt;code>$ docker export 1e560fca3906 &amp;gt; ubuntu.tar
&lt;/code>&lt;/pre>&lt;h3 id="导入容器">导入容器&lt;/h3>
&lt;pre tabindex="0">&lt;code>$ cat docker/ubuntu.tar | docker import - test/ubuntu:v1
&lt;/code>&lt;/pre>&lt;p>或&lt;/p>
&lt;pre tabindex="0">&lt;code>$ docker import docker/ubuntu.tar test/ubuntu:v1
&lt;/code>&lt;/pre>&lt;p>也可以通过指定 URL 或者某个目录来导入，例如：&lt;/p>
&lt;pre tabindex="0">&lt;code>$ docker import http://example.com/exampleimage.tgz example/imagerepo
&lt;/code>&lt;/pre>&lt;p>参考来源：&lt;/p>
&lt;p>[1] &lt;a href="https://www.runoob.com/docker/docker-container-usage.html">https://www.runoob.com/docker/docker-container-usage.html&lt;/a>&lt;/p></description></item><item><title>Docker之镜像使用</title><link>https://xzygis.github.io/2020/01/30/docker%E4%B9%8B%E9%95%9C%E5%83%8F%E4%BD%BF%E7%94%A8/</link><pubDate>Thu, 30 Jan 2020 12:58:32 +0000</pubDate><guid>https://xzygis.github.io/2020/01/30/docker%E4%B9%8B%E9%95%9C%E5%83%8F%E4%BD%BF%E7%94%A8/</guid><description>&lt;h2 id="获取镜像">获取镜像&lt;/h2>
&lt;p>用法：&lt;/p>
&lt;pre tabindex="0">&lt;code>$ docker pull [OPTIONS] NAME[:TAG|@DIGEST]
&lt;/code>&lt;/pre>&lt;p>例如：&lt;code>docker pull ubuntu:18.04&lt;/code>&lt;/p>
&lt;h2 id="启动容器">启动容器&lt;/h2>
&lt;pre tabindex="0">&lt;code>$ docker run -it --rm ubuntu:18.04 bash
&lt;/code>&lt;/pre>&lt;p>简要的说明一下上面用到的参数:&lt;/p>
&lt;ul>
&lt;li>&lt;code>-it&lt;/code>：这是两个参数，一个是 &lt;code>-i&lt;/code>表示交互式操作，一个是&lt;code>-t&lt;/code>表示终端。我们这里打算进入 bash 执行一些命令并查看返回结果，因此我们需要交互式终端。&lt;/li>
&lt;li>&lt;code>--rm&lt;/code>：这个参数是说容器退出后随之将其删除。默认情况下，为了排障需求，退出的容器并不会立即删除，除非手动 docker rm。我们这里只是随便执行个命令，看看结果，不需要排障和保留结果，因此使用&lt;code>--rm&lt;/code> 可以避免浪费空间。&lt;/li>
&lt;li>&lt;code>ubuntu:18.04&lt;/code>：这是指用 ubuntu:18.04 镜像为基础来启动容器。&lt;/li>
&lt;li>&lt;code>bash&lt;/code>：放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是 bash。&lt;/li>
&lt;/ul>
&lt;!-- raw HTML omitted -->
&lt;h2 id="查看镜像列表">查看镜像列表&lt;/h2>
&lt;p>使用&lt;code>docker image ls&lt;/code>或者&lt;code>docker images&lt;/code>:&lt;/p>
&lt;pre tabindex="0">&lt;code>$ docker image ls
REPOSITORY TAG IMAGE ID CREATED SIZE
ubuntu 18.04 93fd78260bd1 5 weeks ago 86.2MB
ubuntu latest 93fd78260bd1 5 weeks ago 86.2MB
hello-world latest 4ab4c602aa5e 3 months ago 1.84kB
$ docker images
REPOSITORY TAG IMAGE ID CREATED SIZE
ubuntu 18.04 93fd78260bd1 5 weeks ago 86.2MB
ubuntu latest 93fd78260bd1 5 weeks ago 86.2MB
hello-world latest 4ab4c602aa5e 3 months ago 1.84kB
&lt;/code>&lt;/pre>&lt;p>列表包含了 仓库名、标签、镜像 ID、创建时间 以及 所占用的空间。&lt;/p>
&lt;h2 id="镜像体积">镜像体积&lt;/h2>
&lt;p>这里标识的所占用空间和在 Docker Hub 上看到的镜像大小不同。比如，&lt;code>ubuntu:18.04&lt;/code> 镜像大小，在这里是 127 MB，但是在 Docker Hub 显示的却是 50 MB。这是因为 Docker Hub 中显示的体积是压缩后的体积。在镜像下载和上传过程中镜像是保持着压缩状态的，因此 Docker Hub 所显示的大小是网络传输中更关心的流量大小。而 &lt;code>docker image ls&lt;/code> 显示的是镜像下载到本地后展开的大小，准确说，是展开后的各层所占空间的总和，因为镜像到本地后，查看空间的时候，更关心的是本地磁盘空间占用的大小。&lt;/p>
&lt;p>另外一个需要注意的问题是，&lt;code>docker image ls&lt;/code> 列表中的镜像体积总和并非是所有镜像实际硬盘消耗。由于 Docker 镜像是多层存储结构，并且可以继承、复用，因此不同镜像可能会因为使用相同的基础镜像，从而拥有共同的层。由于 Docker 使用 Union FS，相同的层只需要保存一份即可，因此实际镜像硬盘占用空间很可能要比这个列表镜像大小的总和要小的多。&lt;/p>
&lt;p>你可以通过以下命令来便捷的查看镜像、容器、数据卷所占用的空间。&lt;/p>
&lt;pre tabindex="0">&lt;code>$ docker system df
TYPE TOTAL ACTIVE SIZE RECLAIMABLE
Images 2 2 86.18MB 0B (0%)
Containers 14 2 148B 25B (16%)
Local Volumes 0 0 0B 0B
Build Cache 0 0 0B 0B
&lt;/code>&lt;/pre>&lt;h2 id="虚悬镜像">虚悬镜像&lt;/h2>
&lt;p>由于新旧镜像同名，旧镜像名称被取消，从而出现仓库名、标签均为&lt;code>&amp;lt;none&amp;gt;&lt;/code>的镜像。这类无标签镜像也被称为 虚悬镜像(dangling image) 。&lt;/p>
&lt;h2 id="中间层镜像">中间层镜像&lt;/h2>
&lt;p>为了加速镜像构建、重复利用资源，Docker 会利用 中间层镜像。所以在使用一段时间后，可能会看到一些依赖的中间层镜像。默认的 docker image ls 列表中只会显示顶层镜像，如果希望显示包括中间层镜像在内的所有镜像的话，需要加 -a 参数。&lt;/p>
&lt;pre tabindex="0">&lt;code>$ docker image ls -a
&lt;/code>&lt;/pre>&lt;p>这样会看到很多无标签的镜像，与之前的虚悬镜像不同，这些无标签的镜像很多都是中间层镜像，是其它镜像所依赖的镜像。这些无标签镜像不应该删除，否则会导致上层镜像因为依赖丢失而出错。实际上，这些镜像也没必要删除，因为之前说过，相同的层只会存一遍，而这些镜像是别的镜像的依赖，因此并不会因为它们被列出来而多存了一份，无论如何你也会需要它们。只要删除那些依赖它们的镜像后，这些依赖的中间层镜像也会被连带删除。&lt;/p>
&lt;p>以特定格式显示：&lt;/p>
&lt;pre tabindex="0">&lt;code>$ docker image ls --format &amp;#34;{{.ID}}: {{.Repository}}&amp;#34;
93fd78260bd1: ubuntu
93fd78260bd1: ubuntu
4ab4c602aa5e: hello-world
$ docker image ls --format &amp;#34;table {{.ID}}\t{{.Repository}}\t{{.Tag}}&amp;#34;
IMAGE ID REPOSITORY TAG
93fd78260bd1 ubuntu 18.04
93fd78260bd1 ubuntu latest
4ab4c602aa5e hello-world latest
&lt;/code>&lt;/pre>&lt;h2 id="删除本地镜像">删除本地镜像&lt;/h2>
&lt;p>如果要删除本地的镜像，可以使用 &lt;code>docker image rm&lt;/code> 命令，其格式为：&lt;/p>
&lt;pre tabindex="0">&lt;code>$ docker image rm [选项] &amp;lt;镜像1&amp;gt; [&amp;lt;镜像2&amp;gt; ...]
&lt;/code>&lt;/pre>&lt;p>其中，&lt;code>&amp;lt;镜像&amp;gt;&lt;/code> 可以是 &lt;code>镜像短 ID&lt;/code>、&lt;code>镜像长 ID&lt;/code>、&lt;code>镜像名&lt;/code> 或者 &lt;code>镜像摘要&lt;/code>。&lt;/p>
&lt;h2 id="untagged-和-deleted">Untagged 和 Deleted&lt;/h2>
&lt;p>如果观察上面这几个命令的运行输出信息的话，你会注意到删除行为分为两类，一类是&lt;code>Untagged&lt;/code>，另一类是 &lt;code>Deleted&lt;/code>。我们之前介绍过，镜像的唯一标识是其 ID 和摘要，而一个镜像可以有多个标签。&lt;/p>
&lt;p>因此当我们使用上面命令删除镜像的时候，实际上是在要求删除某个标签的镜像。所以首先需要做的是将满足我们要求的所有镜像标签都取消，这就是我们看到的 Untagged 的信息。因为一个镜像可以对应多个标签，因此当我们删除了所指定的标签后，可能还有别的标签指向了这个镜像，如果是这种情况，那么 Delete 行为就不会发生。所以并非所有的 &lt;code>docker image rm&lt;/code> 都会产生删除镜像的行为，有可能仅仅是取消了某个标签而已。&lt;/p>
&lt;p>当该镜像所有的标签都被取消了，该镜像很可能会失去了存在的意义，因此会触发删除行为。镜像是多层存储结构，因此在删除的时候也是从上层向基础层方向依次进行判断删除。镜像的多层结构让镜像复用变动非常容易，因此很有可能某个其它镜像正依赖于当前镜像的某一层。这种情况，依旧不会触发删除该层的行为。直到没有任何层依赖当前层时，才会真实的删除当前层。&lt;/p>
&lt;p>除了镜像依赖以外，还需要注意的是&lt;strong>容器对镜像的依赖&lt;/strong>。&lt;strong>如果有用这个镜像启动的容器存在（即使容器没有运行），那么同样不可以删除这个镜像&lt;/strong>。之前讲过，容器是以镜像为基础，再加一层容器存储层，组成这样的多层存储结构去运行的。因此该镜像如果被这个容器所依赖的，那么删除必然会导致故障。如果这些容器是不需要的，应该先将它们删除，然后再来删除镜像。&lt;/p>
&lt;h2 id="利用-commit-理解镜像构成">利用 commit 理解镜像构成&lt;/h2>
&lt;p>注意： &lt;code>docker commit&lt;/code> 命令除了学习之外，还有一些特殊的应用场合，比如被入侵后保存现场等。但是，不要使用 &lt;code>docker commit&lt;/code> 定制镜像，定制镜像应该使用 &lt;code>Dockerfile&lt;/code> 来完成。&lt;/p>
&lt;p>镜像是多层存储，每一层是在前一层的基础上进行的修改；而容器同样也是多层存储，是在以镜像为基础层，在其基础上加一层作为容器运行时的存储层。&lt;/p>
&lt;p>现在让我们以定制一个 Web 服务器为例子，来讲解镜像是如何构建的。&lt;/p>
&lt;pre tabindex="0">&lt;code>$ docker run --name webserver -d -p 80:80 nginx
&lt;/code>&lt;/pre>&lt;p>这条命令会用 &lt;code>nginx&lt;/code> 镜像启动一个容器，命名为 webserver，并且映射了 &lt;code>80&lt;/code> 端口，这样我们可以用浏览器去访问这个 &lt;code>nginx&lt;/code> 服务器。&lt;/p>
&lt;p>用浏览器访问的话，我们会看到默认的 &lt;code>Nginx&lt;/code> 欢迎页面内容：&lt;/p>
&lt;pre tabindex="0">&lt;code>Welcome to nginx!
If you see this page, the nginx web server is successfully installed and working. Further configuration is required.
For online documentation and support please refer to nginx.org.
Commercial support is available at nginx.com.
Thank you for using nginx.
&lt;/code>&lt;/pre>&lt;p>如果我们想要修改欢迎页面的内容，可以使用 &lt;code>docker exec&lt;/code> 命令进入容器，修改其内容。&lt;/p>
&lt;pre tabindex="0">&lt;code>$ docker exec -it webserver bash
root@3729b97e8226:/# echo &amp;#39;&amp;lt;h1&amp;gt;Hello, Docker!&amp;lt;/h1&amp;gt;&amp;#39; &amp;gt; /usr/share/nginx/html/index.html
root@3729b97e8226:/# exit
exit
&lt;/code>&lt;/pre>&lt;p>我们以交互式终端方式进入 &lt;code>webserver&lt;/code> 容器，并执行了 &lt;code>bash&lt;/code> 命令，也就是获得一个可操作的 Shell。&lt;/p>
&lt;p>然后，我们用 &lt;code>&amp;lt;h1&amp;gt;Hello, Docker!&amp;lt;/h1&amp;gt;&lt;/code> 覆盖了 /usr/share/nginx/html/index.html 的内容。现在我们再刷新浏览器的话，会发现内容被改变了。&lt;/p>
&lt;p>我们修改了容器的文件，也就是改动了容器的存储层。我们可以通过 &lt;code>docker diff&lt;/code> 命令看到具体的改动。&lt;/p>
&lt;pre tabindex="0">&lt;code>$ docker diff webserver
C /usr
C /usr/share
C /usr/share/nginx
C /usr/share/nginx/html
C /usr/share/nginx/html/index.html
C /root
A /root/.bash_history
C /var
C /var/cache
C /var/cache/nginx
A /var/cache/nginx/scgi_temp
A /var/cache/nginx/uwsgi_temp
A /var/cache/nginx/client_temp
A /var/cache/nginx/fastcgi_temp
A /var/cache/nginx/proxy_temp
C /run
A /run/nginx.pid
&lt;/code>&lt;/pre>&lt;p>当我们运行一个容器的时候（如果不使用卷的话），我们做的任何文件修改都会被记录于容器存储层里。Docker 提供了一个 &lt;code>docker commit&lt;/code> 命令，可以将容器的存储层保存下来成为镜像。换句话说，就是在原有镜像的基础上，再叠加上容器的存储层，并构成新的镜像。&lt;/p>
&lt;p>docker commit 的语法格式为：&lt;/p>
&lt;pre tabindex="0">&lt;code>docker commit [选项] &amp;lt;容器ID或容器名&amp;gt; [&amp;lt;仓库名&amp;gt;[:&amp;lt;标签&amp;gt;]]
&lt;/code>&lt;/pre>&lt;p>我们可以用下面的命令将容器保存为镜像：&lt;/p>
&lt;pre tabindex="0">&lt;code>$ docker commit --author &amp;#34;chuxing&amp;#34; --message &amp;#34;update page&amp;#34; webserver nginx:v2
sha256:8aaa0b63a1b842fb301d5d691cae92d9fdb52c73f37858eefada4325a36474f0
&lt;/code>&lt;/pre>&lt;p>我们可以在 &lt;code>docker image ls&lt;/code> 中看到这个新定制的镜像：&lt;/p>
&lt;pre tabindex="0">&lt;code>$ docker image ls nginx
REPOSITORY TAG IMAGE ID CREATED SIZE
nginx v2 8aaa0b63a1b8 About a minute ago 109MB
nginx latest 568c4670fa80 4 weeks ago 109MB
&lt;/code>&lt;/pre>&lt;p>新的镜像定制好后，我们可以运行这个镜像:&lt;/p>
&lt;pre tabindex="0">&lt;code>docker run --name web2 -d -p 81:80 nginx:v2
&lt;/code>&lt;/pre>&lt;h2 id="慎用-docker-commit">慎用 docker commit&lt;/h2>
&lt;p>使用 &lt;code>docker commit&lt;/code> 命令虽然可以比较直观的帮助理解镜像分层存储的概念，但是实际环境中并不会这样使用。&lt;/p>
&lt;ol>
&lt;li>如果仔细观察之前的 &lt;code>docker diff webserver&lt;/code> 的结果，你会发现除了真正想要修改的 &lt;code>/usr/share/nginx/html/index.html&lt;/code> 文件外，还有很多文件被改动或添加了。这还仅仅是最简单的操作，如果是安装软件包、编译构建，那会有大量的无关内容被添加进来，如果不小心清理，将会导致镜像极为臃肿。&lt;/li>
&lt;li>使用 &lt;code>docker commit&lt;/code> 意味着所有对镜像的操作都是黑箱操作，生成的镜像也被称为黑箱镜像，换句话说，就是除了制作镜像的人知道执行过什么命令、怎么生成的镜像，别人根本无从得知。&lt;/li>
&lt;li>回顾之前提及的镜像所使用的分层存储的概念，任何修改的结果仅仅是在当前层进行标记、添加、修改，而不会改动上一层。如果使用 &lt;code>docker commit&lt;/code> 制作镜像，每一次修改都会让镜像更加臃肿一次，这会让镜像更加臃肿。&lt;/li>
&lt;/ol>
&lt;h2 id="镜像导入和导出">镜像导入和导出&lt;/h2>
&lt;h3 id="导出镜像">导出镜像&lt;/h3>
&lt;pre tabindex="0">&lt;code>$ docker save -o nginx.tar nginx:latest
&lt;/code>&lt;/pre>&lt;p>或&lt;/p>
&lt;pre tabindex="0">&lt;code>$ docker save &amp;gt; nginx.tar nginx:latest
&lt;/code>&lt;/pre>&lt;h3 id="导入镜像">导入镜像&lt;/h3>
&lt;pre tabindex="0">&lt;code>$ docker load -i nginx.tar
&lt;/code>&lt;/pre>&lt;p>或&lt;/p>
&lt;pre tabindex="0">&lt;code>$ docker load &amp;lt; nginx.tar
&lt;/code>&lt;/pre></description></item><item><title>CentOS安装docker</title><link>https://xzygis.github.io/2020/01/30/centos%E5%AE%89%E8%A3%85docker/</link><pubDate>Thu, 30 Jan 2020 12:56:35 +0000</pubDate><guid>https://xzygis.github.io/2020/01/30/centos%E5%AE%89%E8%A3%85docker/</guid><description>&lt;h3 id="1-移除旧的版本">1. 移除旧的版本&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>sudo yum remove docker &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> docker-client &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> docker-client-latest &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> docker-common &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> docker-latest &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> docker-latest-logrotate &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> docker-logrotate &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> docker-selinux &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> docker-engine-selinux &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> docker-engine
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="2-安装一些必要的系统工具">2. 安装一些必要的系统工具&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>sudo yum install -y yum-utils device-mapper-persistent-data lvm2
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="3-添加软件源信息">3. 添加软件源信息&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="4-更新-yum-缓存">4. 更新 yum 缓存&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>sudo yum makecache fast
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="5-安装-docker-ce">5. 安装 Docker-ce&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>sudo yum -y install docker-ce
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;!-- raw HTML omitted -->
&lt;h3 id="6-启动-docker-后台服务">6. 启动 Docker 后台服务&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>sudo systemctl start docker
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="7-测试运行-hello-world">7. 测试运行 hello-world&lt;/h3>
&lt;p>初次运行可能会报如下的错误信息：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@VM_0_6_centos ~&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># docker run hello-world&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Unable to find image &lt;span style="color:#e6db74">&amp;#39;hello-world:latest&amp;#39;&lt;/span> locally
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docker: Error response from daemon: Get https://registry-1.docker.io/v2/library/hello-world/manifests/latest: Get https://auth.docker.io/token?scope&lt;span style="color:#f92672">=&lt;/span>repository%3Alibrary%2Fhello-world%3Apull&amp;amp;service&lt;span style="color:#f92672">=&lt;/span>registry.docker.io: net/http: TLS handshake timeout.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>See &lt;span style="color:#e6db74">&amp;#39;docker run --help&amp;#39;&lt;/span>.
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>解决方式是使用国内的镜像地址，新建&lt;code>/etc/docker/daemon.json&lt;/code>文件，填写如下配置信息：&lt;/p>
&lt;pre tabindex="0">&lt;code>{
&amp;#34;registry-mirrors&amp;#34;: [&amp;#34;http://hub-mirror.c.163.com&amp;#34;]
}
&lt;/code>&lt;/pre>&lt;p>之后运行正常，如下：&lt;/p>
&lt;pre tabindex="0">&lt;code>[root@VM_0_6_centos docker]# docker run hello-world
Unable to find image &amp;#39;hello-world:latest&amp;#39; locally
latest: Pulling from library/hello-world
d1725b59e92d: Pull complete
Digest: sha256:0add3ace90ecb4adbf7777e9aacf18357296e799f81cabc9fde470971e499788
Status: Downloaded newer image for hello-world:latest
Hello from Docker!
This message shows that your installation appears to be working correctly.
To generate this message, Docker took the following steps:
1. The Docker client contacted the Docker daemon.
2. The Docker daemon pulled the &amp;#34;hello-world&amp;#34; image from the Docker Hub.
(amd64)
3. The Docker daemon created a new container from that image which runs the
executable that produces the output you are currently reading.
4. The Docker daemon streamed that output to the Docker client, which sent it
to your terminal.
To try something more ambitious, you can run an Ubuntu container with:
$ docker run -it ubuntu bash
Share images, automate workflows, and more with a free Docker ID:
https://hub.docker.com/
For more examples and ideas, visit:
https://docs.docker.com/get-started/
&lt;/code>&lt;/pre></description></item><item><title>SO_REUSEADDR &amp; SO_REUSEPORT</title><link>https://xzygis.github.io/2020/01/30/so_reuseaddr-so_reuseport/</link><pubDate>Thu, 30 Jan 2020 12:50:51 +0000</pubDate><guid>https://xzygis.github.io/2020/01/30/so_reuseaddr-so_reuseport/</guid><description>&lt;p>&lt;strong>SO_REUSEADDR&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>当有一个有相同本地地址和端口的socket1处于TIME_WAIT状态时，而你启动的程序的socket2要占用该地址和端口，你的程序就要用到该选项。&lt;/li>
&lt;li>SO_REUSEADDR允许同一port上启动同一服务器的多个实例(多个进程)。但每个实例绑定的IP地址是不能相同的。在有多块网卡或用IP Alias技术的机器可
以测试这种情况。&lt;/li>
&lt;li>SO_REUSEADDR允许单个进程绑定相同的端口到多个socket上，但每个socket绑定的ip地址不同。这和2很相似，区别请看UNPv1。&lt;/li>
&lt;li>SO_REUSEADDR允许完全相同的地址和端口的重复绑定。但这只用于UDP的多播，不用于TCP。&lt;/li>
&lt;/ol>
&lt;!-- raw HTML omitted -->
&lt;p>&lt;strong>SO_REUSEPORT&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>The new socket option allows multiple sockets on the same host to bind to the same port, and is intended to improve the performance of multithreaded network server applications running on top of multicore systems.&lt;/p>
&lt;/blockquote>
&lt;p>linux kernel 3.9引入了最新的SO_REUSEPORT选项，使得多进程或者多线程可以创建多个绑定同一个ip:port的监听socket，提高服务器的接收连接的并发能力,程序的扩展性更好；此时需要设置SO_REUSEPORT（注意所有进程都要设置才生效）。&lt;/p>
&lt;p>目的：每一个进程有一个独立的监听socket，并且bind相同的ip:port，独立的listen()和accept()；提高接收连接的能力。（例如nginx多进程同时监听同一个ip:port）&lt;/p>
&lt;p>解决的问题：&lt;/p>
&lt;ul>
&lt;li>避免了应用层多线程或者进程监听同一ip:port的“惊群效应”。&lt;/li>
&lt;li>内核层面实现负载均衡，保证每个进程或者线程接收均衡的连接数。&lt;/li>
&lt;li>只有effective-user-id相同的服务器进程才能监听同一ip:port （安全性考虑）&lt;/li>
&lt;/ul>
&lt;p>golang开源实现：https://github.com/kavu/go_reuseport&lt;/p>
&lt;p>注意：SO_REUSEPORT只支持TCP和UDP。对unix domain socket不生效。&lt;/p></description></item><item><title>Kubernetes概述</title><link>https://xzygis.github.io/2020/01/29/kubernetes%E6%A6%82%E8%BF%B0/</link><pubDate>Wed, 29 Jan 2020 23:53:11 +0000</pubDate><guid>https://xzygis.github.io/2020/01/29/kubernetes%E6%A6%82%E8%BF%B0/</guid><description>&lt;h1 id="kubernetes-简介">Kubernetes 简介&lt;/h1>
&lt;p>Kubernetes 是谷歌开源的容器集群管理系统，是 Google 多年大规模容器管理技术 Borg 的开源版本，主要功能包括：&lt;/p>
&lt;ul>
&lt;li>基于容器的应用部署、维护和滚动升级&lt;/li>
&lt;li>负载均衡和服务发现&lt;/li>
&lt;li>跨机器和跨地区的集群调度&lt;/li>
&lt;li>自动伸缩&lt;/li>
&lt;li>无状态服务和有状态服务&lt;/li>
&lt;li>广泛的 Volume 支持&lt;/li>
&lt;li>插件机制保证扩展性&lt;/li>
&lt;/ul>
&lt;!-- raw HTML omitted -->
&lt;h2 id="kubernetes-是一个平台">Kubernetes 是一个平台&lt;/h2>
&lt;p>Kubernetes 提供了很多的功能，它可以简化应用程序的工作流，加快开发速度。&lt;/p>
&lt;ul>
&lt;li>用户可以使用 Label 以自己的方式组织管理资源，还可以使用 Annotation 来自定义资源的描述信息，比如为管理工具提供状态检查等。&lt;/li>
&lt;li>Kubernetes 控制器也是构建在跟开发人员和用户使用的相同的 API 之上。用户还可以编写自己的控制器和调度器，也可以通过各种插件机制扩展系统的功能。&lt;/li>
&lt;/ul>
&lt;h2 id="kubernetes-不是什么">Kubernetes 不是什么&lt;/h2>
&lt;p>Kubernetes 不是一个传统意义上，包罗万象的 PaaS (平台即服务) 系统，它给用户保留了选择的自由和灵活性。&lt;/p>
&lt;ul>
&lt;li>不限制支持的应用程序类型。Kubernetes 旨在支持极其多样化的工作负载，包括无状态、有状态和数据处理工作负载。只要应用可以在容器中运行，那么它就可以很好的在 Kubernetes 上运行。&lt;/li>
&lt;li>不提供内置的中间件 (如消息中间件)、数据处理框架 (如 Spark)、数据库 (如 mysql) 或集群存储系统 (如 Ceph) 等。&lt;/li>
&lt;li>不直接部署代码，也不会构建您的应用程序。&lt;/li>
&lt;li>允许用户选择自己的日志、监控和告警系统。&lt;/li>
&lt;li>不提供应用程序配置语言或系统 (如 jsonnet)。&lt;/li>
&lt;li>不提供机器配置、维护、管理或自愈系统。&lt;/li>
&lt;/ul>
&lt;h2 id="核心组件">核心组件&lt;/h2>
&lt;p>Kubernetes 主要由以下几个核心组件组成：&lt;/p>
&lt;ul>
&lt;li>etcd 保存了整个集群的状态；&lt;/li>
&lt;li>apiserver 提供了资源操作的唯一入口，并提供认证、授权、访问控制、API 注册和发现等机制；&lt;/li>
&lt;li>controller manager 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等；&lt;/li>
&lt;li>scheduler 负责资源的调度，按照预定的调度策略将 Pod 调度到相应的机器上；&lt;/li>
&lt;li>kubelet 负责维护容器的生命周期，同时也负责 Volume（CVI）和网络（CNI）的管理；&lt;/li>
&lt;li>Container runtime 负责镜像管理以及 Pod 和容器的真正运行（CRI）；&lt;/li>
&lt;li>kube-proxy 负责为 Service 提供 cluster 内部的服务发现和负载均衡
&lt;img src="https://img-blog.csdnimg.cn/20191118230100546.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9jaHV4aW5nLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="k8s核心组件">&lt;/li>
&lt;/ul>
&lt;h1 id="kubernetes-基本概念">Kubernetes 基本概念&lt;/h1>
&lt;h2 id="container">Container&lt;/h2>
&lt;p>Container（容器）是一种便携式、轻量级的操作系统级虚拟化技术。它使用 namespace 隔离不同的软件运行环境，并通过镜像自包含软件的运行环境，从而使得容器可以很方便的在任何地方运行。&lt;/p>
&lt;p>使用容器，不需要与外部的基础架构环境绑定，因为每一个应用程序都不需要外部依赖，更不需要与外部的基础架构环境依赖。完美解决了从开发到生产环境的一致性问题。&lt;/p>
&lt;p>容器同样比虚拟机更加透明，这有助于监测和管理。尤其是容器进程的生命周期由基础设施管理，而不是被进程管理器隐藏在容器内部。最后，每个应用程序用容器封装，管理容器部署就等同于管理应用程序部署。&lt;/p>
&lt;p>容器的其他优点：&lt;/p>
&lt;ul>
&lt;li>敏捷的应用程序创建和部署：与虚拟机镜像相比，容器镜像更易用、更高效。&lt;/li>
&lt;li>持续开发、集成和部署：提供可靠与频繁的容器镜像构建、部署和快速简便的回滚（镜像是不可变的）。&lt;/li>
&lt;li>开发与运维的关注分离：在构建/发布时即创建容器镜像，从而将应用与基础架构分离。&lt;/li>
&lt;li>开发、测试与生产环境的一致性：在笔记本电脑上运行和云中一样。&lt;/li>
&lt;li>可观测：不仅显示操作系统的信息和度量，还显示应用自身的信息和度量。&lt;/li>
&lt;li>云和操作系统的分发可移植性：可运行在 Ubuntu, RHEL, CoreOS, 物理机, GKE 以及其他任何地方。&lt;/li>
&lt;li>以应用为中心的管理：从传统的硬件上部署操作系统提升到操作系统中部署应用程序。&lt;/li>
&lt;li>松耦合、分布式、弹性伸缩、微服务：应用程序被分成更小，更独立的模块，并可以动态管理和部署。&lt;/li>
&lt;li>资源隔离：可预测的应用程序性能。&lt;/li>
&lt;li>资源利用：高效率和高密度。&lt;/li>
&lt;/ul>
&lt;h2 id="pod">Pod&lt;/h2>
&lt;p>Kubernetes 使用 Pod 来管理容器，每个 Pod 可以包含一个或多个紧密关联的容器。&lt;/p>
&lt;p>Pod 是一组紧密关联的容器集合，它们共享 PID、IPC、Network 和 UTS namespace，是 Kubernetes 调度的基本单位。Pod 内的多个容器共享网络和文件系统，可以通过进程间通信和文件共享这种简单高效的方式组合完成服务。&lt;/p>
&lt;p>在 Kubernetes 中，所有对象都使用 manifest（yaml 或 json）来定义，比如一个简单的 nginx 服务可以定义为 nginx.yaml，它包含一个镜像为 nginx 的容器：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">Pod&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">nginx&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">labels&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">app&lt;/span>: &lt;span style="color:#ae81ff">nginx&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">containers&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">nginx&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">image&lt;/span>: &lt;span style="color:#ae81ff">nginx&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ports&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">containerPort&lt;/span>: &lt;span style="color:#ae81ff">80&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="node">Node&lt;/h2>
&lt;p>Node 是 Pod 真正运行的主机，可以是物理机，也可以是虚拟机。为了管理 Pod，每个 Node 节点上至少要运行 container runtime（比如 docker 或者 rkt）、kubelet 和 kube-proxy 服务。&lt;/p>
&lt;h2 id="namespace">Namespace&lt;/h2>
&lt;p>Namespace 是对一组资源和对象的抽象集合，比如可以用来将系统内部的对象划分为不同的项目组或用户组。常见的 pods, services, replication controllers 和 deployments 等都是属于某一个 namespace 的（默认是 default），而 node, persistentVolumes 等则不属于任何 namespace。&lt;/p>
&lt;h2 id="service">Service&lt;/h2>
&lt;p>Service 是应用服务的抽象，通过 labels 为应用提供负载均衡和服务发现。匹配 labels 的 Pod IP 和端口列表组成 endpoints，由 kube-proxy 负责将服务 IP 负载均衡到这些 endpoints 上。
每个 Service 都会自动分配一个 cluster IP（仅在集群内部可访问的虚拟地址）和 DNS 名，其他容器可以通过该地址或 DNS 来访问服务，而不需要了解后端容器的运行。
&lt;img src="https://img-blog.csdnimg.cn/20191118230137955.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9jaHV4aW5nLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="k8s-service">&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">Service&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">nginx&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ports&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">port&lt;/span>: &lt;span style="color:#ae81ff">8078&lt;/span> &lt;span style="color:#75715e"># the port that this service should serve on&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">http&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># the container on each pod to connect to, can be a name&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># (e.g. &amp;#39;www&amp;#39;) or a number (e.g. 80)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">targetPort&lt;/span>: &lt;span style="color:#ae81ff">80&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">protocol&lt;/span>: &lt;span style="color:#ae81ff">TCP&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">selector&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">app&lt;/span>: &lt;span style="color:#ae81ff">nginx&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="label">Label&lt;/h2>
&lt;p>Label 是识别 Kubernetes 对象的标签，以 key/value 的方式附加到对象上（key 最长不能超过 63 字节，value 可以为空，也可以是不超过 253 字节的字符串）。&lt;/p>
&lt;p>Label 不提供唯一性，并且实际上经常是很多对象（如 Pods）都使用相同的 label 来标志具体的应用。
Label 定义好后其他对象可以使用 Label Selector 来选择一组相同 label 的对象（比如 ReplicaSet 和 Service 用 label 来选择一组 Pod）。Label Selector 支持以下几种方式：&lt;/p>
&lt;ul>
&lt;li>等式，如 app=nginx 和 env!=production&lt;/li>
&lt;li>集合，如 env in (production, qa)&lt;/li>
&lt;li>多个 label（它们之间是 AND 关系），如 app=nginx,env=test&lt;/li>
&lt;/ul>
&lt;h2 id="annotations">Annotations&lt;/h2>
&lt;p>Annotations 是 key/value 形式附加于对象的注解。不同于 Labels 用于标志和选择对象，Annotations 则是用来记录一些附加信息，用来辅助应用部署、安全策略以及调度策略等。比如 deployment 使用 annotations 来记录 rolling update 的状态。&lt;/p>
&lt;p>参考来源：&lt;/p>
&lt;ol>
&lt;li>&lt;a href="https://feisky.gitbooks.io/kubernetes/introduction/">https://feisky.gitbooks.io/kubernetes/introduction/&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/">https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>云原生概述</title><link>https://xzygis.github.io/2020/01/28/%E4%BA%91%E5%8E%9F%E7%94%9F%E6%A6%82%E8%BF%B0/</link><pubDate>Tue, 28 Jan 2020 15:05:10 +0000</pubDate><guid>https://xzygis.github.io/2020/01/28/%E4%BA%91%E5%8E%9F%E7%94%9F%E6%A6%82%E8%BF%B0/</guid><description>&lt;h1 id="云原生的定义">云原生的定义&lt;/h1>
&lt;p>云原生技术有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展的应用。云原生的代表技术包括容器、服务网格、微服务、不可变基础设施和声明式API。&lt;/p>
&lt;p>这些技术能够构建容错性好、易于管理和便于观察的松耦合系统。结合可靠的自动化手段，云原生技术使工程师能够轻松地对系统作出频繁和可预测的重大变更。&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;h1 id="云原生的设计哲学">云原生的设计哲学&lt;/h1>
&lt;p>云原生本身甚至不能称为是一种架构，它首先是一种基础设施，运行在其上的应用称作云原生应用，只有符合云原生设计哲学的应用架构才叫云原生应用架构。&lt;/p>
&lt;h2 id="云原生的设计理念">云原生的设计理念&lt;/h2>
&lt;p>云原生系统的设计理念如下:&lt;/p>
&lt;ul>
&lt;li>面向分布式设计（Distribution）：容器、微服务、API 驱动的开发；&lt;/li>
&lt;li>面向配置设计（Configuration）：一个镜像，多个环境配置；&lt;/li>
&lt;li>面向韧性设计（Resistancy）：故障容忍和自愈；&lt;/li>
&lt;li>面向弹性设计（Elasticity）：弹性扩展和对环境变化（负载）做出响应；&lt;/li>
&lt;li>面向交付设计（Delivery）：自动拉起，缩短交付时间；&lt;/li>
&lt;li>面向性能设计（Performance）：响应式，并发和资源高效利用；&lt;/li>
&lt;li>面向自动化设计（Automation）：自动化的 DevOps；&lt;/li>
&lt;li>面向诊断性设计（Diagnosability）：集群级别的日志、metric 和追踪；&lt;/li>
&lt;li>面向安全性设计（Security）：安全端点、API Gateway、端到端加密；&lt;/li>
&lt;/ul>
&lt;h2 id="云原生应用程序">云原生应用程序&lt;/h2>
&lt;p>云原生应用程序被设计为在平台上运行，并设计用于弹性，敏捷性，可操作性和可观察性。弹性包含失败而不是试图阻止它们；它利用了在平台上运行的动态特性。敏捷性允许快速部署和快速迭代。可操作性从应用程序内部控制应用程序生命周期，而不是依赖外部进程和监视器。可观察性提供信息来回答有关应用程序状态的问题。&lt;/p>
&lt;p>实现云原生应用程序所需特性的常用方法：&lt;/p>
&lt;ul>
&lt;li>微服务&lt;/li>
&lt;li>健康报告&lt;/li>
&lt;li>遥测数据&lt;/li>
&lt;li>弹性&lt;/li>
&lt;li>声明式的，而不是命令式的&lt;/li>
&lt;/ul>
&lt;h3 id="微服务">微服务&lt;/h3>
&lt;p>微服务 (Microservices) 是一种软件架构风格，它是以专注于单一责任与功能的小型功能区块 (Small Building Blocks) 为基础，利用模块化的方式组合出复杂的大型应用程序，各功能区块使用与语言无关 (Language-Independent/Language agnostic) 的 API 集相互通信。&lt;/p>
&lt;p>微服务是一种以业务功能为主的服务设计概念，每一个服务都具有自主运行的业务功能，对外开放不受语言限制的 API (最常用的是 HTTP)，应用程序则是由一个或多个微服务组成。&lt;/p>
&lt;h3 id="健康报告">健康报告&lt;/h3>
&lt;p>为了提高云原生应用程序的可操作性，应用程序应该暴露健康检查。开发人员可以将其实施为命令或过程信号，以便应用程序在执行自我检查之后响应，或者更常见的是：通过应用程序提供Web服务，返回HTTP状态码来检查健康状态。&lt;/p>
&lt;p>一个很好的例子就是当平台需要知道应用程序何时可以接收流量。在应用程序启动时，如果它不能正确处理流量，它就应该表现为未准备好。&lt;/p>
&lt;h3 id="遥测数据">遥测数据&lt;/h3>
&lt;p>遥测数据是进行决策所需的信息。确实，遥测数据可能与健康报告重叠，但它们有不同的用途。健康报告通知我们应用程序生命周期状态，而遥测数据通知我们应用程序业务目标。&lt;/p>
&lt;p>测量的指标有时称为服务级指标（SLI）或关键性能指标（KPI）。这些是特定于应用程序的数据，可以确保应用程序的性能处于服务级别目标（SLO）内。&lt;/p>
&lt;h3 id="弹性">弹性&lt;/h3>
&lt;p>一旦你有遥测和监测数据，你需要确保你的应用程序对故障有适应能力。弹性是基础设施的责任，但云原生应用程序也需要承担部分工作。在云原生应用程序中考虑弹性的两个主要方面：为失败设计和优雅降级。&lt;/p>
&lt;h4 id="为失败设计">为失败设计&lt;/h4>
&lt;p>设计一个以失败期望为目标的应用程序将比假定可用性的应用程序更具防御性。当故障不可避免时，将会有额外的检查，故障模式和日志内置到应用程序中。&lt;/p>
&lt;h4 id="优雅降级">优雅降级&lt;/h4>
&lt;p>云原生应用程序处理过载的一种方式。&lt;/p>
&lt;h3 id="声明式非命令式">声明式，非命令式&lt;/h3>
&lt;p>声明式编程是一种编程范式，与命令式编程相对立。它描述目标的性质，让电脑明白目标，而非流程。声明式编程不用告诉电脑问题领域，从而避免随之而来的副作用。而命令式编程则需要用算法来明确的指出每一步该怎么做。&lt;/p>
&lt;p>声明式通信模型规范了通信模型，并且它将功能实现从应用程序转移到远程API或服务端点，从而实现某种状态到达期望状态。这有助于简化应用程序，并使它们彼此的行为更具可预测性。&lt;/p>
&lt;p>例子：SQL数据库
其实你很早就接触过声明式编程语言， SQL语言就是很典型的例子：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sql" data-lang="sql">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">SELECT&lt;/span> &lt;span style="color:#f92672">*&lt;/span> &lt;span style="color:#66d9ef">from&lt;/span> &lt;span style="color:#66d9ef">user&lt;/span> &lt;span style="color:#66d9ef">WHERE&lt;/span> user_name &lt;span style="color:#f92672">=&lt;/span> Ben
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>上面是一个很普通的SQL查询语句，我只只声明我想要找一个叫Ben的用户（What) , 就是不说SQL该怎么（How）去寻找怎么做。接下来我们看看如果用命令式语言写会是什么样的：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-js" data-lang="js">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">//user=[{user_name:&amp;#39;ou&amp;#39;,user_id=1},.....]
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">user&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span>(&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">i&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>; &lt;span style="color:#a6e22e">i&lt;/span> &lt;span style="color:#f92672">&amp;lt;&lt;/span> &lt;span style="color:#a6e22e">user&lt;/span>.&lt;span style="color:#a6e22e">length&lt;/span>; &lt;span style="color:#a6e22e">i&lt;/span>&lt;span style="color:#f92672">++&lt;/span>){
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#a6e22e">user&lt;/span>.&lt;span style="color:#a6e22e">user_name&lt;/span> &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Ben&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">print&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;find&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">break&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>通过上面的对比你可以看出声明式语言的优势-短小精悍，你并不会知道程序的控制流（control flow）我们不需要告诉程序如何去寻找（How），而是只告诉程序我们想要的结果（What），让程序自己来解决过程（How）。当然SQL具体的细节还是用命令式的编程风格来实现的。&lt;/p>
&lt;h1 id="play-with-kubernetes">Play with Kubernetes&lt;/h1>
&lt;h2 id="创建kubernetes集群">创建Kubernetes集群&lt;/h2>
&lt;p>登陆Play with Kubernetes，启动第一个实例作为Master节点，在web终端上执行：&lt;/p>
&lt;ol>
&lt;li>初始化master节点：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>kubeadm init --apiserver-advertise-address &lt;span style="color:#66d9ef">$(&lt;/span>hostname -i&lt;span style="color:#66d9ef">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>输出如下：&lt;/p>
&lt;pre tabindex="0">&lt;code>[node1 ~]$ kubeadm init --apiserver-advertise-address $(hostname -i)
Initializing machine ID from random generator.
[init] using Kubernetes version: v1.11.10
[preflight] running pre-flight checks
[WARNING Service-Docker]: docker service is not active, please run &amp;#39;systemctl start docker.service&amp;#39;
[WARNING FileContent--proc-sys-net-bridge-bridge-nf-call-iptables]: /proc/sys/net/bridge/bridge-nf-call-iptables does not exist
I1117 13:53:18.409493 885 kernel_validator.go:81] Validating kernel version
I1117 13:53:18.409685 885 kernel_validator.go:96] Validating kernel config
[preflight] The system verification failed. Printing the output from the verification:
KERNEL_VERSION: 4.4.0-148-generic
DOCKER_VERSION: 18.06.1-ce
OS: Linux
CGROUPS_CPU: enabled
CGROUPS_CPUACCT: enabled
CGROUPS_CPUSET: enabled
CGROUPS_DEVICES: enabled
CGROUPS_FREEZER: enabled
CGROUPS_MEMORY: enabled
[WARNING SystemVerification]: docker version is greater than the most recently validated version. Docker version: 18.06.1-ce. Max validated version: 17.03
[WARNING SystemVerification]: failed to parse kernel config: unable to load kernel module &amp;#34;configs&amp;#34;: output - &amp;#34;&amp;#34;, err - exit status 1
[preflight/images] Pulling images required for setting up a Kubernetes cluster
[preflight/images] This might take a minute or two, depending on the speed of your internet connection
[preflight/images] You can also perform this action in beforehand using &amp;#39;kubeadm config images pull&amp;#39;
[kubelet] Writing kubelet environment file with flags to file &amp;#34;/var/lib/kubelet/kubeadm-flags.env&amp;#34;
[kubelet] Writing kubelet configuration to file &amp;#34;/var/lib/kubelet/config.yaml&amp;#34;
[preflight] Activating the kubelet service
[certificates] Generated ca certificate and key.
[certificates] Generated apiserver certificate and key.
[certificates] apiserver serving cert is signed for DNS names [node1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.0.18]
[certificates] Generated apiserver-kubelet-client certificate and key.
[certificates] Generated sa key and public key.
[certificates] Generated front-proxy-ca certificate and key.
[certificates] Generated front-proxy-client certificate and key.
[certificates] Generated etcd/ca certificate and key.
[certificates] Generated etcd/server certificate and key.
[certificates] etcd/server serving cert is signed for DNS names [node1 localhost] and IPs [127.0.0.1 ::1]
[certificates] Generated etcd/peer certificate and key.
[certificates] etcd/peer serving cert is signed for DNS names [node1 localhost] and IPs [192.168.0.18 127.0.0.1 ::1]
[certificates] Generated etcd/healthcheck-client certificate and key.
[certificates] Generated apiserver-etcd-client certificate and key.
[certificates] valid certificates and keys now exist in &amp;#34;/etc/kubernetes/pki&amp;#34;
[kubeconfig] Wrote KubeConfig file to disk: &amp;#34;/etc/kubernetes/admin.conf&amp;#34;
[kubeconfig] Wrote KubeConfig file to disk: &amp;#34;/etc/kubernetes/kubelet.conf&amp;#34;
[kubeconfig] Wrote KubeConfig file to disk: &amp;#34;/etc/kubernetes/controller-manager.conf&amp;#34;
[kubeconfig] Wrote KubeConfig file to disk: &amp;#34;/etc/kubernetes/scheduler.conf&amp;#34;
[controlplane] wrote Static Pod manifest for component kube-apiserver to &amp;#34;/etc/kubernetes/manifests/kube-apiserver.yaml&amp;#34;
[controlplane] wrote Static Pod manifest for component kube-controller-manager to &amp;#34;/etc/kubernetes/manifests/kube-controller-manager.yaml&amp;#34;
[controlplane] wrote Static Pod manifest for component kube-scheduler to &amp;#34;/etc/kubernetes/manifests/kube-scheduler.yaml&amp;#34;
[etcd] Wrote Static Pod manifest for a local etcd instance to &amp;#34;/etc/kubernetes/manifests/etcd.yaml&amp;#34;
[init] waiting for the kubelet to boot up the control plane as Static Pods from directory &amp;#34;/etc/kubernetes/manifests&amp;#34;
[init] this might take a minute or longer if the control plane images have to be pulled
[apiclient] All control plane components are healthy after 51.503514 seconds
[uploadconfig] storing the configuration used in ConfigMap &amp;#34;kubeadm-config&amp;#34; in the &amp;#34;kube-system&amp;#34; Namespace
[kubelet] Creating a ConfigMap &amp;#34;kubelet-config-1.11&amp;#34; in namespace kube-system with the configuration for the kubelets in the cluster
[markmaster] Marking the node node1 as master by adding the label &amp;#34;node-role.kubernetes.io/master=&amp;#39;&amp;#39;&amp;#34;
[markmaster] Marking the node node1 as master by adding the taints [node-role.kubernetes.io/master:NoSchedule]
[patchnode] Uploading the CRI Socket information &amp;#34;/var/run/dockershim.sock&amp;#34; to the Node API object &amp;#34;node1&amp;#34; as an annotation
[bootstraptoken] using token: 5f1nyz.351cet8vt4g2ix78
[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstraptoken] creating the &amp;#34;cluster-info&amp;#34; ConfigMap in the &amp;#34;kube-public&amp;#34; namespace
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy
Your Kubernetes master has initialized successfully!
To start using your cluster, you need to run the following as a regular user:
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
You should now deploy a pod network to the cluster.
Run &amp;#34;kubectl apply -f [podnetwork].yaml&amp;#34; with one of the options listed at:
https://kubernetes.io/docs/concepts/cluster-administration/addons/
You can now join any number of machines by running the following on each node
as root:
kubeadm join 192.168.0.18:6443 --token 5f1nyz.351cet8vt4g2ix78 --discovery-token-ca-cert-hash sha256:d105d049cf090f7814473e5554b79e09cd13e4acfd8a56b09754ba9181d08fd8
Waiting for api server to startup
Warning: kubectl apply should be used on resource created by either kubectl create --save-config or kubectl apply
daemonset.extensions/kube-proxy configured
No resources found
&lt;/code>&lt;/pre>&lt;ol start="2">
&lt;li>初始化集群网络：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>kubectl apply -n kube-system -f &lt;span style="color:#e6db74">&amp;#34;https://cloud.weave.works/k8s/net?k8s-version=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>kubectl version | base64 | tr -d &lt;span style="color:#e6db74">&amp;#39;\n&amp;#39;&lt;/span>&lt;span style="color:#66d9ef">)&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>输出如下：&lt;/p>
&lt;pre tabindex="0">&lt;code>serviceaccount/weave-net created
clusterrole.rbac.authorization.k8s.io/weave-net created
clusterrolebinding.rbac.authorization.k8s.io/weave-net created
role.rbac.authorization.k8s.io/weave-net created
rolebinding.rbac.authorization.k8s.io/weave-net created
daemonset.apps/weave-net created
&lt;/code>&lt;/pre>&lt;ol start="3">
&lt;li>执行下列初始化命令：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>mkdir -p $HOME/.kube
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>chown &lt;span style="color:#66d9ef">$(&lt;/span>id -u&lt;span style="color:#66d9ef">)&lt;/span>:&lt;span style="color:#66d9ef">$(&lt;/span>id -g&lt;span style="color:#66d9ef">)&lt;/span> $HOME/.kube/config
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="4">
&lt;li>根据master节点上的提示，在新的web终端上执行：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>kubeadm join 192.168.0.18:6443 --token 5f1nyz.351cet8vt4g2ix78 --discovery-token-ca-cert-hash sha256:d105d049cf090f7814473e5554b79e09cd13e4acfd8a56b09754ba9181d08fd8
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>输出如下：&lt;/p>
&lt;pre tabindex="0">&lt;code>[preflight] running pre-flight checks
[WARNING DirAvailable--etc-kubernetes-manifests]: /etc/kubernetes/manifests is not empty
[WARNING FileAvailable--etc-kubernetes-pki-ca.crt]: /etc/kubernetes/pki/ca.crt already exists
[WARNING FileAvailable--etc-kubernetes-kubelet.conf]: /etc/kubernetes/kubelet.conf already exists
[WARNING RequiredIPVSKernelModulesAvailable]: error getting required builtin kernel modules: exit status 1(cut: /lib/modules/4.4.0-166-generic/modules.builtin: No such file or directory
)
[WARNING Service-Docker]: docker service is not active, please run &amp;#39;systemctl start docker.service&amp;#39;
[WARNING FileContent--proc-sys-net-bridge-bridge-nf-call-iptables]: /proc/sys/net/bridge/bridge-nf-call-iptables does not exist
I1117 14:09:02.416363 7243 kernel_validator.go:81] Validating kernel version
I1117 14:09:02.419283 7243 kernel_validator.go:96] Validating kernel config
[preflight] The system verification failed. Printing the output from the verification:
KERNEL_VERSION: 4.4.0-166-generic
DOCKER_VERSION: 18.06.1-ce
OS: Linux
CGROUPS_CPU: enabled
CGROUPS_CPUACCT: enabled
CGROUPS_CPUSET: enabled
CGROUPS_DEVICES: enabled
CGROUPS_FREEZER: enabled
CGROUPS_MEMORY: enabled
[WARNING SystemVerification]: docker version is greater than the most recently validated version. Docker version: 18.06.1-ce. Max validated version: 17.03
[WARNING SystemVerification]: failed to parse kernel config: unable to load kernel module &amp;#34;configs&amp;#34;: output - &amp;#34;&amp;#34;, err - exit status 1
[WARNING Port-10250]: Port 10250 is in use
[discovery] Trying to connect to API Server &amp;#34;192.168.0.28:6443&amp;#34;
[discovery] Created cluster-info discovery client, requesting info from &amp;#34;https://192.168.0.28:6443&amp;#34;
[discovery] Requesting info from &amp;#34;https://192.168.0.28:6443&amp;#34; again to validate TLS against the pinned public key
[discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server &amp;#34;192.168.0.28:6443&amp;#34;
[discovery] Successfully established connection with API Server &amp;#34;192.168.0.28:6443&amp;#34;
[kubelet] Downloading configuration for the kubelet from the &amp;#34;kubelet-config-1.11&amp;#34; ConfigMap in the kube-system namespace
[kubelet] Writing kubelet configuration to file &amp;#34;/var/lib/kubelet/config.yaml&amp;#34;
[kubelet] Writing kubelet environment file with flags to file &amp;#34;/var/lib/kubelet/kubeadm-flags.env&amp;#34;
[preflight] Activating the kubelet service
[tlsbootstrap] Waiting for the kubelet to perform the TLS Bootstrap...
[patchnode] Uploading the CRI Socket information &amp;#34;/var/run/dockershim.sock&amp;#34; to the Node API object &amp;#34;node1&amp;#34; as an annotation
This node has joined the cluster:
* Certificate signing request was sent to master and a response
was received.
* The Kubelet was informed of the new secure connection details.
Run &amp;#39;kubectl get nodes&amp;#39; on the master to see this node join the cluster.
&lt;/code>&lt;/pre>&lt;p>多开几个实例，重复执行第四步，即可向Kubernetes集群中增加节点。&lt;/p>
&lt;p>此时在master节点上执行&lt;code>kubectl get nodes&lt;/code>查看节点所有节点状态：&lt;/p>
&lt;pre tabindex="0">&lt;code>[node1 ~]$ kubectl get nodes
NAME STATUS ROLES AGE VERSION
node1 Ready master 19m v1.11.3
node2 Ready &amp;lt;none&amp;gt; 2m v1.11.3
node3 Ready &amp;lt;none&amp;gt; 1m v1.11.3
&lt;/code>&lt;/pre>&lt;h2 id="创建nginx-deployment">创建nginx deployment&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>node1 ~&lt;span style="color:#f92672">]&lt;/span>$ curl https://raw.githubusercontent.com/kubernetes/website/master/content/en/examples/application/nginx-app.yaml &amp;gt; nginx-app.yaml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> % Total % Received % Xferd Average Speed Time Time Time Current
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Dload Upload Total Spent Left Speed
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">100&lt;/span> &lt;span style="color:#ae81ff">497&lt;/span> &lt;span style="color:#ae81ff">100&lt;/span> &lt;span style="color:#ae81ff">497&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span> &lt;span style="color:#ae81ff">1252&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span> --:--:-- --:--:-- --:--:-- &lt;span style="color:#ae81ff">1255&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>node1 ~&lt;span style="color:#f92672">]&lt;/span>$
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>node1 ~&lt;span style="color:#f92672">]&lt;/span>$ kubectl apply -f nginx-app.yaml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>service/my-nginx-svc created
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>deployment.apps/my-nginx created
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>此时查看nodes和pods：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>node1 ~&lt;span style="color:#f92672">]&lt;/span>$ kubectl get nodes
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME STATUS ROLES AGE VERSION
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>node1 Ready master 29m v1.11.3
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>node2 Ready &amp;lt;none&amp;gt; 11m v1.11.3
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>node3 Ready &amp;lt;none&amp;gt; 11m v1.11.3
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>node1 ~&lt;span style="color:#f92672">]&lt;/span>$
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>node1 ~&lt;span style="color:#f92672">]&lt;/span>$ kubectl get pods
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME READY STATUS RESTARTS AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>my-nginx-67594d6bf6-2cbbz 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 1m
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>my-nginx-67594d6bf6-r2p6w 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 1m
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>my-nginx-67594d6bf6-vjqn4 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 1m
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>参考来源：&lt;/p>
&lt;ol>
&lt;li>&lt;a href="https://github.com/cncf/toc/blob/master/DEFINITION.md">https://github.com/cncf/toc/blob/master/DEFINITION.md&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://zh.wikipedia.org/wiki/%E5%BE%AE%E6%9C%8D%E5%8B%99">https://zh.wikipedia.org/wiki/%E5%BE%AE%E6%9C%8D%E5%8B%99&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://zh.wikipedia.org/zh-cn/%E5%AE%A3%E5%91%8A%E5%BC%8F%E7%B7%A8%E7%A8%8B">https://zh.wikipedia.org/zh-cn/%E5%AE%A3%E5%91%8A%E5%BC%8F%E7%B7%A8%E7%A8%8B&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/34445114">https://zhuanlan.zhihu.com/p/34445114&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://labs.play-with-k8s.com/">https://labs.play-with-k8s.com/&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>Service Mesh概述</title><link>https://xzygis.github.io/2020/01/28/service-mesh%E6%A6%82%E8%BF%B0/</link><pubDate>Tue, 28 Jan 2020 14:48:01 +0000</pubDate><guid>https://xzygis.github.io/2020/01/28/service-mesh%E6%A6%82%E8%BF%B0/</guid><description>&lt;h1 id="什么是服务网格">什么是服务网格？&lt;/h1>
&lt;p>服务网格是用于处理服务间通信的专用基础设施层。它负责通过包含现代云原生应用程序的复杂服务拓扑来可靠地传递请求。实际上，服务网格通常通过一组轻量级网络代理来实现，这些代理与应用程序代码一起部署，而不需要感知应用程序本身。&lt;/p>
&lt;h2 id="服务网格的特点">服务网格的特点&lt;/h2>
&lt;p>服务网格有如下几个特点：&lt;/p>
&lt;ul>
&lt;li>应用程序间通讯的中间层&lt;/li>
&lt;li>轻量级网络代理&lt;/li>
&lt;li>应用程序无感知&lt;/li>
&lt;li>解耦应用程序的重试/超时、监控、追踪和服务发现&lt;/li>
&lt;/ul>
&lt;!-- raw HTML omitted -->
&lt;h2 id="理解服务网格">理解服务网格&lt;/h2>
&lt;p>如果用一句话来解释什么是服务网格，可以将它比作是应用程序或者说微服务间的 TCP/IP，负责服务之间的网络调用、限流、熔断和监控。&lt;/p>
&lt;p>服务网格的架构如下图所示：
&lt;img src="https://img-blog.csdnimg.cn/20191116230107526.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9jaHV4aW5nLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="Service Mesh架构图">&lt;/p>
&lt;h2 id="为何使用服务网格">为何使用服务网格？&lt;/h2>
&lt;p>服务网格并没有给我们带来新功能，它是用于解决其他工具已经解决过的问题，只不过这次是在云原生的 Kubernetes 环境下的实现。&lt;/p>
&lt;p>在传统的 MVC 三层 Web 应用程序架构下，服务之间的通讯并不复杂，在应用程序内部自己管理即可，但是在现今的复杂的大型网站情况下，单体应用被分解为众多的微服务，服务之间的依赖和通讯十分复杂，出现了 twitter 开发的 Finagle、Netflix 开发的 Hystrix 和 Google 的 Stubby 这样的 “胖客户端” 库，这些就是早期的服务网格，但是它们都仅适用于特定的环境和特定的开发语言，并不能作为平台级的服务网格支持。&lt;/p>
&lt;p>在云原生架构下，容器的使用给予了异构应用程序的更多可行性，Kubernetes 增强的应用的横向扩容能力，用户可以快速的编排出复杂环境、复杂依赖关系的应用程序，同时开发者又无须过多关心应用程序的监控、扩展性、服务发现和分布式追踪这些繁琐的事情而专注于程序开发，赋予开发者更多的创造性。&lt;/p>
&lt;h1 id="服务网格架构">服务网格架构&lt;/h1>
&lt;p>服务网格中分为控制平面和数据平面，当前流行的两款开源的服务网格 Istio 和 Linkerd 实际上都是这种架构，只不过 Istio 的划分更清晰，而且部署更零散，很多组件都被拆分，控制平面中包括 Mixer、Pilot、Citadel，数据平面默认是用 Envoy；而 Linkerd 中只分为 Linkerd 做数据平面，namerd 作为控制平面。&lt;/p>
&lt;p>&lt;strong>控制平面的特点&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>不直接解析数据包&lt;/li>
&lt;li>与数据平面中的代理通信，下发策略和配置&lt;/li>
&lt;li>负责网络行为的可视化&lt;/li>
&lt;li>通常提供 API 或者命令行工具可用于配置版本化管理，便于持续集成和部署&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>数据平面的特点&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>通常是按照无状态目标设计的，但实际上为了提高流量转发性能，需要缓存一些数据，因此无状态也是有争议的&lt;/li>
&lt;li>直接处理入站和出站数据包，转发、路由、健康检查、负载均衡、认证、鉴权、产生监控数据等&lt;/li>
&lt;li>对应用来说透明，即可以做到无感知部署&lt;/li>
&lt;/ul>
&lt;h2 id="服务网格的实现模式">服务网格的实现模式&lt;/h2>
&lt;p>Service Mesh 架构示意图：
&lt;img src="https://img-blog.csdnimg.cn/20191116231047738.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9jaHV4aW5nLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="Service Mesh架构示意图">&lt;/p>
&lt;h2 id="istio-架构解析">Istio 架构解析&lt;/h2>
&lt;p>&lt;img src="https://img-blog.csdnimg.cn/20191116231618741.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9jaHV4aW5nLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">&lt;/p>
&lt;ul>
&lt;li>Istio 是独立于平台的，可以在 Kubernetes 、 Consul 、虚拟机上部署的服务&lt;/li>
&lt;li>Istio 的组成
&lt;ul>
&lt;li>Envoy：智能代理、流量控制&lt;/li>
&lt;li>Pilot：服务发现、流量管理&lt;/li>
&lt;li>Mixer：访问控制、遥测&lt;/li>
&lt;li>Citadel：终端用户认证、流量加密&lt;/li>
&lt;li>Galley（1.1新增）：验证、处理和分配配置&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Service mesh 关注的方面
&lt;ul>
&lt;li>可观察性&lt;/li>
&lt;li>安全性&lt;/li>
&lt;li>可运维性&lt;/li>
&lt;li>可拓展性&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Istio 的策略执行组件可以扩展和定制，同时也是可拔插的&lt;/li>
&lt;li>Istio 在数据平面为每个服务中注入一个 Envoy 代理以 Sidecar 形式运行来劫持所有进出服务的流量，同时对流量加以控制，通俗的讲就是应用程序你只管处理你的业务逻辑，其他的事情 Sidecar 会汇报给 Istio 控制平面处理&lt;/li>
&lt;li>应用程序只需关注于业务逻辑（这才能生钱）即可，非功能性需求交给 Istio&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>设计目标&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>最大化透明度&lt;/li>
&lt;li>可扩展性&lt;/li>
&lt;li>可移植性&lt;/li>
&lt;li>策略一致性&lt;/li>
&lt;/ul>
&lt;h2 id="从边车模式到-service-mesh">从边车模式到 Service Mesh&lt;/h2>
&lt;h3 id="什么是边车模式">什么是边车模式&lt;/h3>
&lt;blockquote>
&lt;p>Deploy components of an application into a separate process or container to provide isolation and encapsulation.
&amp;mdash; Sidecar pattern&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://img-blog.csdnimg.cn/2019111623235962.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9jaHV4aW5nLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="SideCar">&lt;/p>
&lt;h3 id="边车模式设计">边车模式设计&lt;/h3>
&lt;p>有两种方法来实现边车模式：&lt;/p>
&lt;ul>
&lt;li>通过 SDK、Lib 等软件包的形式，在开发时引入该软件包依赖，使其与业务服务集成起来。&lt;/li>
&lt;li>以 Sidecar 的形式，在运维的时候与应用服务集成在一起。&lt;/li>
&lt;/ul>
&lt;h3 id="边车模式解决了什么问题">边车模式解决了什么问题&lt;/h3>
&lt;ul>
&lt;li>控制与逻辑分离的问题
&lt;ul>
&lt;li>业务代码只需要关心其复杂的业务逻辑&lt;/li>
&lt;li>日志记录、监控、流量控制、服务注册、服务发现、服务限流、服务熔断、鉴权、访问控制等交给边车&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>解决服务之间调用越来越复杂的问题
&lt;ul>
&lt;li>随着分布式架构越来越复杂和微服务越拆越细，我们越来越迫切的希望有一个统一的控制面来管理我们的微服务，来帮助我们维护和管理所有微服务&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="从边车模式到-service-mesh-1">从边车模式到 Service Mesh&lt;/h3>
&lt;p>遵循边车模式进行实践从很早以前就开始了，开发人员一直试图将服务治理等通用功能提取成一个标准化的 Sidecar ，通过 Sidecar 代理来与其他系统进行交互，这样可以大大简化业务开发和运维。而随着分布式架构和微服务被越来越多的公司和开发者接受并使用，这一需求日益凸显。这就是 Service Mesh 服务网格诞生的契机，它是 CNCF（Cloud Native Computing Foundation，云原生基金会）目前主推的新一代微服务架构。&lt;/p>
&lt;p>Service Mesh 将底层那些难以控制的网络通讯统一管理，诸如：流量管控，丢包重试，访问控制等。而上层的应用层协议只需关心业务逻辑即可。Service Mesh 是一个用于处理服务间通信的基础设施层，它负责为构建复杂的云原生应用传递可靠的网络请求。&lt;/p>
&lt;h1 id="kubernetes-vs-service-mesh">Kubernetes vs Service Mesh&lt;/h1>
&lt;blockquote>
&lt;p>Kubernetes 管理的对象是 Pod，Service Mesh 中管理的对象是 Service。&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>Kubernetes 的本质是应用的生命周期管理，具体来说就是部署和管理（扩缩容、自动恢复、发布）。&lt;/li>
&lt;li>Kubernetes 为微服务提供了可扩展、高弹性的部署和管理平台。&lt;/li>
&lt;li>Service Mesh 的基础是透明代理，通过 sidecar proxy 拦截到微服务间流量后再通过控制平面配置管理微服务的行为。&lt;/li>
&lt;li>Service Mesh 将流量管理从 Kubernetes 中解耦，Service Mesh 内部的流量无需 kube-proxy 组件的支持，通过为更接近微服务应用层的抽象，管理服务间的流量、安全性和可观察性。&lt;/li>
&lt;li>Service Mesh 是对 Kubernetes 中的 service 更上层的抽象，它的下一步是 serverless。&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>本文是针对ServiceMesher社区系列文章而整理的学习笔记，文章地址：https://www.servicemesher.com/istio-handbook/intro/service-mesh-the-microservices-in-post-kubernetes-era.html&lt;/p></description></item><item><title>API网关概述</title><link>https://xzygis.github.io/2020/01/27/api%E7%BD%91%E5%85%B3%E6%A6%82%E8%BF%B0/</link><pubDate>Mon, 27 Jan 2020 22:51:43 +0000</pubDate><guid>https://xzygis.github.io/2020/01/27/api%E7%BD%91%E5%85%B3%E6%A6%82%E8%BF%B0/</guid><description>&lt;h1 id="1-背景">1 背景&lt;/h1>
&lt;ul>
&lt;li>由于后端的微服务拆分，客户端通常需要请求多个服务获取所需数据。&lt;/li>
&lt;li>不同客户端所需要的数据不一样。例如，PC需要的数据通常比移动端更加详细。&lt;/li>
&lt;li>不同客户端网络环境差异大。例如，WAN vs LAN，移动网络 vs 非移动网络。&lt;/li>
&lt;li>服务端实例的地址信息（IP + port）会动态更新。&lt;/li>
&lt;li>微服务的拆分逻辑会变化，这种变化应该应该对客户端透明。&lt;/li>
&lt;li>不同的服务可能采用不同的协议，有些协议是非web的。&lt;/li>
&lt;/ul>
&lt;h1 id="2-什么是api网关">2 什么是API网关？&lt;/h1>
&lt;p>API网关接收客户端的所有请求，并将请求路由到相应的后端服务，并提供接口聚合和协议转换。通常来说，API网关通过调用多个后端服务，并聚合结果的方式处理请求。它可将web协议转化为非web的内部后台协议。&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>核心功能：&lt;/p>
&lt;ul>
&lt;li>服务发现：&lt;/li>
&lt;li>负载均衡：以某种算法分摊系统压力。&lt;/li>
&lt;li>服务熔断：直接返回失败或者执行降价逻辑，防止雪崩。&lt;/li>
&lt;li>流量控制：防止短时间内大量请求转发到后台压垮服务器。&lt;/li>
&lt;li>认证鉴权：验证客户端的请求是否被授权。&lt;/li>
&lt;li>灰度发布：&lt;/li>
&lt;/ul>
&lt;p>其他功能：&lt;/p>
&lt;ul>
&lt;li>协议转换：web协议转非Web协议。&lt;/li>
&lt;li>参数校验：对入参设置校验规则，由网关根据规则对无效请求进行过滤。&lt;/li>
&lt;li>API管理：包括 API 的创建、测试、发布、下线、版本切换等。&lt;/li>
&lt;li>监控告警：监控API请求次数、API调用延迟和API错误信息。&lt;/li>
&lt;li>SDK生成：&lt;/li>
&lt;/ul>
&lt;h1 id="3-实现方式">3 实现方式&lt;/h1>
&lt;p>将API网关作为客户端的唯一接入点。API网关主要有两种类型：&lt;/p>
&lt;ul>
&lt;li>one-size-fits-all网关&lt;/li>
&lt;li>Backends for frontends网关&lt;/li>
&lt;/ul>
&lt;h2 id="31-one-size-fits-all网关">3.1 One-size-fits-all网关&lt;/h2>
&lt;p>简单地将请求路由到相应服务。将请求扇出到多个后端服务。
&lt;img src="https://img-blog.csdnimg.cn/20191013124932708.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9jaHV4aW5nLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="OSFA API Gateway">&lt;/p>
&lt;h2 id="32-backends-for-fronts网关">3.2 Backends for fronts网关&lt;/h2>
&lt;p>为每种客户端暴露不同的API。为每种客户端设计一个API网关，每个API网关为其客户端提供一种API。
&lt;img src="https://img-blog.csdnimg.cn/20191013125314703.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9jaHV4aW5nLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="Backends fro frontends API Gateway">&lt;/p>
&lt;h1 id="4-优点">4 优点&lt;/h1>
&lt;ul>
&lt;li>使后端的微服务拆分对客户端透明。&lt;/li>
&lt;li>客户端无需关心后端服务的实例地址（IP + port）。&lt;/li>
&lt;li>可为每个客户端提供最优API。&lt;/li>
&lt;li>减少请求次数。&lt;/li>
&lt;li>简化客户端的逻辑（由调用多个后台服务变为只调用API网关）。&lt;/li>
&lt;li>可将标准的Web API协议转化为任意的后端协议。&lt;/li>
&lt;/ul>
&lt;h1 id="5-缺点">5 缺点&lt;/h1>
&lt;ul>
&lt;li>增加复杂性。增加了API网关模块，带来了额外的开发、部署、管理成本。&lt;/li>
&lt;li>增加响应时间。调用链路多了一跳（API网关）。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Issues:&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>How implement the API gateway?
event-driven/reactive approach is the best if it must scale to handle high loads.&lt;/p>
&lt;/blockquote>
&lt;p>参考来源：
[1] &lt;a href="https://microservices.io/patterns/apigateway.html">https://microservices.io/patterns/apigateway.html&lt;/a>
[2] &lt;a href="https://www.nginx.com/learn/api-gateway/">https://www.nginx.com/learn/api-gateway/&lt;/a>
[3] &lt;a href="https://aws.amazon.com/cn/api-gateway/features/">https://aws.amazon.com/cn/api-gateway/features/&lt;/a>
[4] &lt;a href="https://cloud.tencent.com/document/product/628/11755">https://cloud.tencent.com/document/product/628/11755&lt;/a>&lt;/p></description></item><item><title>如何通过GitHub+Hexo搭建博客</title><link>https://xzygis.github.io/2020/01/27/%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87github-hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/</link><pubDate>Mon, 27 Jan 2020 21:52:50 +0000</pubDate><guid>https://xzygis.github.io/2020/01/27/%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87github-hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/</guid><description>&lt;h2 id="安装node">安装Node&lt;/h2>
&lt;pre tabindex="0">&lt;code>$ brew install node
&lt;/code>&lt;/pre>&lt;h2 id="安装hexo">安装Hexo&lt;/h2>
&lt;pre tabindex="0">&lt;code>$ npm install -g hexo
&lt;/code>&lt;/pre>&lt;h2 id="初始化hexo">初始化Hexo&lt;/h2>
&lt;pre tabindex="0">&lt;code>$ hexo init
&lt;/code>&lt;/pre>&lt;h2 id="生成网页文件和开启服务器">生成网页文件和开启服务器&lt;/h2>
&lt;pre tabindex="0">&lt;code>$ hexo g
$ hexo s
&lt;/code>&lt;/pre>&lt;!-- raw HTML omitted -->
&lt;h2 id="关联github">关联Github&lt;/h2>
&lt;ol>
&lt;li>修改&lt;code>_config.yml&lt;/code>，修改deploy为：&lt;/li>
&lt;/ol>
&lt;pre tabindex="0">&lt;code>deploy:
type: &amp;#39;git&amp;#39;
repository: https://github.com/xzygis/xzygis.github.io.git
branch: master
&lt;/code>&lt;/pre>&lt;ol start="2">
&lt;li>生成静态文件并上传Github&lt;/li>
&lt;/ol>
&lt;pre tabindex="0">&lt;code>$ hexo g
$ hexo d
&lt;/code>&lt;/pre>&lt;p>若执行&lt;code>hexo d&lt;/code>出错则执行&lt;code>npm install hexo-deployer-git --save&lt;/code>。&lt;/p>
&lt;p>执行&lt;code>hexo d&lt;/code>会提示输入用户名密码。&lt;/p>
&lt;h2 id="配置next主题">配置next主题&lt;/h2>
&lt;p>在blog目录下执行&lt;/p>
&lt;pre tabindex="0">&lt;code>git clone --branch v5.1.4 https://github.com/iissnan/hexo-theme-next themes/next
&lt;/code>&lt;/pre>&lt;p>修改&lt;code>_config.yml&lt;/code>，设置theme为next。&lt;/p></description></item></channel></rss>