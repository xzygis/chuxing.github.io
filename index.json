[{"categories":null,"content":"个人经历 多年大厂经验：先后工作于美团、腾讯、字节，目前在字节工作。 有比较丰富的高并发、高可用服务开发经验：做过承载数百万QPS的中台服务，也开发过公司级的基础组件（承载数千万的QPS）。 个人爱好 读书 跑步 人生格言 问题的根源通常是认知不足 学而不思则罔，思而不学则殆 知行合一 如果您有任何的问题，欢迎与我联系~ ","date":"2020-12-03","objectID":"/about/:0:0","tags":null,"title":"About","uri":"/about/"},{"categories":["后台开发"],"content":"Redis是一个键值对数据库服务器，服务器中通常包含着任意个非空数据库，而每个非空数据库中又可以包含任意个键值对，为了方便起见，我们将服务器中的非空数据库以及它们的键值对统称为数据库状态。 因为Redis是内存数据库，它将自己的数据库状态储存在内存里面，所以如果不想办法将储存在内存中的数据库状态保存到磁盘里面，那么一旦服务器进程退出，服务器中的数据库状态也会消失不见。为了解决这个问题，Redis提供了RDB持久化功能，这个功能可以将Redis在内存中的数据库状态保存到磁盘里面，避免数据意外丢失。 RDB持久化既可以手动执行，也可以根据服务器配置选项定期执行，该功能可以将某个时间点上的数据库状态保存到一个RDB文件中。 RDB持久化功能所生成的RDB文件是一个经过压缩的二进制文件，通过该文件可以还原生成RDB文件时的数据库状态。 因为RDB文件是保存在硬盘里面的，所以即使Redis服务器进程退出，甚至运行Redis服务器的计算机停机，但只要RDB文件仍然存在，Redis服务器就可以用它来还原数据库状态。 ","date":"2022-12-09","objectID":"/posts/introduction-to-redis-rdb-persistence/:0:0","tags":["Redis"],"title":"Redis RDB持久化","uri":"/posts/introduction-to-redis-rdb-persistence/"},{"categories":["后台开发"],"content":"RDB文件的创建与载入 有两个Redis命令可以用于生成RDB文件，一个是SAVE，另一个是BGSAVE。SAVE命令会阻塞Redis服务器进程，直到RDB文件创建完毕为止，在服务器进程阻塞期间，服务器不能处理任何命令请求；BGSAVE命令会派生出一个子进程，然后由子进程负责创建RDB文件，服务器进程（父进程）继续处理命令请求。 创建RDB文件的实际工作由rdb.c/rdbSave函数完成，SAVE命令和BGSAVE命令会以不同的方式调用这个函数，通过以下伪代码可以明显地看出这两个命令之间的区别： def SAVE(): #创建RDB文件 rdbSave() def BGSAVE(): #创建子进程 pid = fork() if pid == 0: #子进程负责创建RDB文件 rdbSave() #完成之后向父进程发送信号 signal_parent() elif pid ＞ 0: #父进程继续处理命令请求，并通过轮询等待子进程的信号 handle_request_and_wait_signal() else: #处理出错情况 handle_fork_error() RDB文件的载入工作是在服务器启动时自动执行的，所以Redis并没有专门用于载入RDB文件的命令，只要Redis服务器在启动时检测到RDB文件存在，它就会自动载入RDB文件。 另外值得一提的是，因为AOF文件的更新频率通常比RDB文件的更新频率高，所以： 如果服务器开启了AOF持久化功能，那么服务器会优先使用AOF文件来还原数据库状态。 只有在AOF持久化功能处于关闭状态时，服务器才会使用RDB文件来还原数据库状态。 ","date":"2022-12-09","objectID":"/posts/introduction-to-redis-rdb-persistence/:1:0","tags":["Redis"],"title":"Redis RDB持久化","uri":"/posts/introduction-to-redis-rdb-persistence/"},{"categories":["后台开发"],"content":"SAVE命令执行时的服务器状态 当SAVE命令执行时，Redis服务器会被阻塞，所以当SAVE命令正在执行时，客户端发送的所有命令请求都会被拒绝。只有在服务器执行完SAVE命令、重新开始接受命令请求之后，客户端发送的命令才会被处理。 ","date":"2022-12-09","objectID":"/posts/introduction-to-redis-rdb-persistence/:1:1","tags":["Redis"],"title":"Redis RDB持久化","uri":"/posts/introduction-to-redis-rdb-persistence/"},{"categories":["后台开发"],"content":"BGSAVE命令执行时的服务器状态 因为BGSAVE命令的保存工作是由子进程执行的，所以在子进程创建RDB文件的过程中，Redis服务器仍然可以继续处理客户端的命令请求，但是，在BGSAVE命令执行期间，服务器处理SAVE、BGSAVE、BGREWRITEAOF三个命令的方式会和平时有所不同。 首先，在BGSAVE命令执行期间，客户端发送的SAVE命令会被服务器拒绝，服务器禁止SAVE命令和BGSAVE命令同时执行是为了避免父进程（服务器进程）和子进程同时执行两个rdbSave调用，防止产生竞争条件。 其次，在BGSAVE命令执行期间，客户端发送的BGSAVE命令会被服务器拒绝，因为同时执行两个BGSAVE命令也会产生竞争条件。 最后，BGREWRITEAOF和BGSAVE两个命令不能同时执行： 如果BGSAVE命令正在执行，那么客户端发送的BGREWRITEAOF命令会被延迟到BGSAVE命令执行完毕之后执行。 如果BGREWRITEAOF命令正在执行，那么客户端发送的BGSAVE命令会被服务器拒绝。 因为BGREWRITEAOF和BGSAVE两个命令的实际工作都由子进程执行，所以这两个命令在操作方面并没有什么冲突的地方，不能同时执行它们只是一个性能方面的考虑——并发出两个子进程，并且这两个子进程都同时执行大量的磁盘写入操作，这怎么想都不会是一个好主意。 ","date":"2022-12-09","objectID":"/posts/introduction-to-redis-rdb-persistence/:1:2","tags":["Redis"],"title":"Redis RDB持久化","uri":"/posts/introduction-to-redis-rdb-persistence/"},{"categories":["后台开发"],"content":"RDB文件载入时的服务器状态 服务器在载入RDB文件期间，会一直处于阻塞状态，直到载入工作完成为止。 ","date":"2022-12-09","objectID":"/posts/introduction-to-redis-rdb-persistence/:1:3","tags":["Redis"],"title":"Redis RDB持久化","uri":"/posts/introduction-to-redis-rdb-persistence/"},{"categories":["后台开发"],"content":"自动间隔性保存 因为BGSAVE命令可以在不阻塞服务器进程的情况下执行，所以Redis允许用户通过设置服务器配置的save选项，让服务器每隔一段时间自动执行一次BGSAVE命令。用户可以通过save选项设置多个保存条件，但只要其中任意一个条件被满足，服务器就会执行BGSAVE命令。 举个例子，如果我们向服务器提供以下配置： save 900 1 save 300 10 save 60 10000 那么只要满足以下三个条件中的任意一个，BGSAVE命令就会被执行： 服务器在900秒之内，对数据库进行了至少1次修改。 服务器在300秒之内，对数据库进行了至少10次修改。 服务器在60秒之内，对数据库进行了至少10000次修改。 ","date":"2022-12-09","objectID":"/posts/introduction-to-redis-rdb-persistence/:2:0","tags":["Redis"],"title":"Redis RDB持久化","uri":"/posts/introduction-to-redis-rdb-persistence/"},{"categories":["后台开发"],"content":"设置保存条件 当Redis服务器启动时，用户可以通过指定配置文件或者传入启动参数的方式设置save选项，如果用户没有主动设置save选项，那么服务器会为save选项设置默认条件。服务器程序会根据save选项所设置的保存条件，设置服务器状态redisServer结构的saveparams属性： struct redisServer { // ... //记录了保存条件的数组 struct saveparam *saveparams; // ... }; ","date":"2022-12-09","objectID":"/posts/introduction-to-redis-rdb-persistence/:2:1","tags":["Redis"],"title":"Redis RDB持久化","uri":"/posts/introduction-to-redis-rdb-persistence/"},{"categories":["后台开发"],"content":"dirty计数器和lastsave属性 除了saveparams数组之外，服务器状态还维持着一个dirty计数器，以及一个lastsave属性： dirty计数器记录距离上一次成功执行SAVE命令或者BGSAVE命令之后，服务器对数据库状态（服务器中的所有数据库）进行了多少次修改（包括写入、删除、更新等操作）。 lastsave属性是一个UNIX时间戳，记录了服务器上一次成功执行SAVE命令或者BGSAVE命令的时间。 struct redisServer { // ... //修改计数器 long long dirty; //上一次执行保存的时间 time_t lastsave; // ... }; ","date":"2022-12-09","objectID":"/posts/introduction-to-redis-rdb-persistence/:2:2","tags":["Redis"],"title":"Redis RDB持久化","uri":"/posts/introduction-to-redis-rdb-persistence/"},{"categories":["后台开发"],"content":"检查保存条件是否满足 Redis的服务器周期性操作函数serverCron默认每隔100毫秒就会执行一次，该函数用于对正在运行的服务器进行维护，它的其中一项工作就是检查save选项所设置的保存条件是否已经满足，如果满足的话，就执行BGSAVE命令。 def serverCron(): # ... #遍历所有保存条件 for saveparam in server.saveparams: #计算距离上次执行保存操作有多少秒 save_interval = unixtime_now()-server.lastsave #如果数据库状态的修改次数超过条件所设置的次数 #并且距离上次保存的时间超过条件所设置的时间 #那么执行保存操作 if server.dirty ＞= saveparam.changes and \\ save_interval ＞ saveparam.seconds: BGSAVE() # ... 程序会遍历并检查saveparams数组中的所有保存条件，只要有任意一个条件被满足，那么服务器就会执行BGSAVE命令。 ","date":"2022-12-09","objectID":"/posts/introduction-to-redis-rdb-persistence/:2:3","tags":["Redis"],"title":"Redis RDB持久化","uri":"/posts/introduction-to-redis-rdb-persistence/"},{"categories":["后台开发"],"content":"RDB文件结构 一个完整的RDB文件包含以下几个部分： | REDIS | db_version | databases | EOF | check_sum | 其中： RDB文件的最开头是REDIS部分，这个部分的长度为5字节，保存着“REDIS”五个字符。通过这五个字符，程序可以在载入文件时，快速检查所载入的文件是否RDB文件。 db_version长度为4字节，它的值是一个字符串表示的整数，这个整数记录了RDB文件的版本号，比如\"0006\"就代表RDB文件的版本为第六版 databases部分包含着零个或任意多个数据库，以及各个数据库中的键值对数据。 EOF常量的长度为1字节，这个常量标志着RDB文件正文内容的结束，当读入程序遇到这个值的时候，它知道所有数据库的所有键值对都已经载入完毕了。 check_sum是一个8字节长的无符号整数，保存着一个校验和，这个校验和是程序通过对REDIS、db_version、databases、EOF四个部分的内容进行计算得出的。 ","date":"2022-12-09","objectID":"/posts/introduction-to-redis-rdb-persistence/:3:0","tags":["Redis"],"title":"Redis RDB持久化","uri":"/posts/introduction-to-redis-rdb-persistence/"},{"categories":["后台开发"],"content":"databases部分 一个RDB文件的databases部分可以保存任意多个非空数据库。每个非空数据库在RDB文件中都可以保存为SELECTDB、db_number、key_value_pairs三个部分： | SELECTDB | db_number | key_value_pairs | ","date":"2022-12-09","objectID":"/posts/introduction-to-redis-rdb-persistence/:3:1","tags":["Redis"],"title":"Redis RDB持久化","uri":"/posts/introduction-to-redis-rdb-persistence/"},{"categories":["后台开发"],"content":"key_value_pairs部分 RDB文件中的每个key_value_pairs部分都保存了一个或以上数量的键值对，如果键值对带有过期时间的话，那么键值对的过期时间也会被保存在内。不带过期时间的键值对在RDB文件中由TYPE、key、value三部分组成： | TYPE | key | value | TYPE记录了value的类型，长度为1字节，每个TYPE常量都代表了一种对象类型或者底层编码，当服务器读入RDB文件中的键值对数据时，程序会根据TYPE的值来决定如何读入和解释value的数据。Type的值可以是以下常量的其中一个： REDIS_RDB_TYPE_STRING REDIS_RDB_TYPE_LIST REDIS_RDB_TYPE_SET REDIS_RDB_TYPE_ZSET REDIS_RDB_TYPE_HASH REDIS_RDB_TYPE_LIST_ZIPLIST REDIS_RDB_TYPE_SET_INTSET REDIS_RDB_TYPE_ZSET_ZIPLIST REDIS_RDB_TYPE_HASH_ZIPLIST 带有过期时间的键值对在RDB文件中的结构： | EXPIRETIME_MS | ms | TYPE | key | value | 其中， EXPIRETIME_MS常量的长度为1字节，它告知读入程序，接下来要读入的将是一个以毫秒为单位的过期时间。 ms是一个8字节长的带符号整数，记录着一个以毫秒为单位的UNIX时间戳，这个时间戳就是键值对的过期时间。 ","date":"2022-12-09","objectID":"/posts/introduction-to-redis-rdb-persistence/:3:2","tags":["Redis"],"title":"Redis RDB持久化","uri":"/posts/introduction-to-redis-rdb-persistence/"},{"categories":["后台开发"],"content":"value的编码 RDB文件中的每个value部分都保存了一个值对象，每个值对象的类型都由与之对应的TYPE记录，根据类型的不同，value部分的结构、长度也会有所不同。 ","date":"2022-12-09","objectID":"/posts/introduction-to-redis-rdb-persistence/:3:3","tags":["Redis"],"title":"Redis RDB持久化","uri":"/posts/introduction-to-redis-rdb-persistence/"},{"categories":["后台开发"],"content":"分析RDB文件 我们可以使用od命令来分析Redis服务器产生的RDB文件，该命令可以用给定的格式转存（dump）并打印输入文件。 ","date":"2022-12-09","objectID":"/posts/introduction-to-redis-rdb-persistence/:4:0","tags":["Redis"],"title":"Redis RDB持久化","uri":"/posts/introduction-to-redis-rdb-persistence/"},{"categories":["后台开发"],"content":"重点回顾 RDB文件用于保存和还原Redis服务器所有数据库中的所有键值对数据。 SAVE命令由服务器进程直接执行保存操作，所以该命令会阻塞服务器。 BGSAVE令由子进程执行保存操作，所以该命令不会阻塞服务器。 服务器状态中会保存所有用save选项设置的保存条件，当任意一个保存条件被满足时，服务器会自动执行BGSAVE命令。 RDB文件是一个经过压缩的二进制文件，由多个部分组成。 对于不同类型的键值对，RDB文件会使用不同的方式来保存它们。 ","date":"2022-12-09","objectID":"/posts/introduction-to-redis-rdb-persistence/:5:0","tags":["Redis"],"title":"Redis RDB持久化","uri":"/posts/introduction-to-redis-rdb-persistence/"},{"categories":["后台开发"],"content":"服务器中的数据库 Redis服务器将所有数据库都保存在服务器状态redis.h/redisServer结构的db数组中，db数组的每个项都是一个redis.h/redisDb结构，每个redisDb结构代表一个数据库： struct redisServer { // ... // 一个数组，保存着服务器中的所有数据库 redisDb *db; // ... }; 在初始化服务器时，程序会根据服务器状态的dbnum属性来决定应该创建多少个数据库： struct redisServer { // ... // 服务器的数据库数量 int dbnum; // ... }; dbnum属性的值由服务器配置的database选项决定，默认情况下，该选项的值为16，所以Redis服务器默认会创建16个数据库。 ","date":"2022-12-08","objectID":"/posts/redis-server-database-implementation-introduction/:1:0","tags":["Redis"],"title":"Redis服务器数据库实现介绍","uri":"/posts/redis-server-database-implementation-introduction/"},{"categories":["后台开发"],"content":"切换数据库 默认情况下，Redis客户端的目标数据库为0号数据库，但客户端可以通过执行SELECT命令来切换目标数据库。 在服务器内部，客户端状态redisClient结构的db属性记录了客户端当前的目标数据库，这个属性是一个指向redisDb结构的指针： typedef struct redisClient { // ... // 记录客户端当前正在使用的数据库 redisDb *db; // ... } redisClient; redisClient.db指针指向redisServer.db数组的其中一个元素，而被指向的元素就是客户端的目标数据库。 ","date":"2022-12-08","objectID":"/posts/redis-server-database-implementation-introduction/:2:0","tags":["Redis"],"title":"Redis服务器数据库实现介绍","uri":"/posts/redis-server-database-implementation-introduction/"},{"categories":["后台开发"],"content":"数据库键空间 Redis是一个键值对（key-value pair）数据库服务器，服务器中的每个数据库都由一个redis.h/redisDb结构表示，其中，redisDb结构的dict字典保存了数据库中的所有键值对，我们将这个字典称为键空间（key space）： typedef struct redisDb { // ... // 数据库键空间，保存着数据库中的所有键值对 dict *dict; // ... } redisDb; 键空间和用户所见的数据库是直接对应的： 键空间的键也就是数据库的键，每个键都是一个字符串对象。 键空间的值也就是数据库的值，每个值可以是字符串对象、列表对象、哈希表对象、集合对象和有序集合对象中的任意一种Redis对象。 因为数据库的键空间是一个字典，所以所有针对数据库的操作，比如添加一个键值对到数据库，或者从数据库中删除一个键值对，又或者在数据库中获取某个键值对等，实际上都是通过对键空间字典进行操作来实现的。 ","date":"2022-12-08","objectID":"/posts/redis-server-database-implementation-introduction/:3:0","tags":["Redis"],"title":"Redis服务器数据库实现介绍","uri":"/posts/redis-server-database-implementation-introduction/"},{"categories":["后台开发"],"content":"读写键空间时的维护操作 当使用Redis命令对数据库进行读写时，服务器不仅会对键空间执行指定的读写操作，还会执行一些额外的维护操作，其中包括： 在读取一个键之后（读操作和写操作都要对键进行读取），服务器会根据键是否存在来更新服务器的键空间命中（hit）次数或键空间不命中（miss）次数，这两个值可以在INFO stats命令的keyspace_hits属性和keyspace_misses属性中查看。 在读取一个键之后，服务器会更新键的LRU（最后一次使用）时间，这个值可以用于计算键的闲置时间，使用OBJECT idletime命令可以查看键key的闲置时间。 如果服务器在读取一个键时发现该键已经过期，那么服务器会先删除这个过期键，然后才执行余下的其他操作，本章稍后对过期键的讨论会详细说明这一点。 如果有客户端使用WATCH命令监视了某个键，那么服务器在对被监视的键进行修改之后，会将这个键标记为脏（dirty），从而让事务程序注意到这个键已经被修改过。 服务器每次修改一个键之后，都会对脏（dirty）键计数器的值增1，这个计数器会触发服务器的持久化以及复制操作。 如果服务器开启了数据库通知功能，那么在对键进行修改之后，服务器将按配置发送相应的数据库通知，本章稍后讨论数据库通知功能的实现时会详细说明这一点。 ","date":"2022-12-08","objectID":"/posts/redis-server-database-implementation-introduction/:3:1","tags":["Redis"],"title":"Redis服务器数据库实现介绍","uri":"/posts/redis-server-database-implementation-introduction/"},{"categories":["后台开发"],"content":"设置键的生存时间或过期时间 通过EXPIRE命令或者PEXPIRE命令，客户端可以以秒或者毫秒精度为数据库中的某个键设置生存时间（Time To Live，TTL），在经过指定的秒数或者毫秒数之后，服务器就会自动删除生存时间为0的键。 ","date":"2022-12-08","objectID":"/posts/redis-server-database-implementation-introduction/:4:0","tags":["Redis"],"title":"Redis服务器数据库实现介绍","uri":"/posts/redis-server-database-implementation-introduction/"},{"categories":["后台开发"],"content":"设置过期时间 Redis有四个不同的命令可以用于设置键的生存时间（键可以存在多久）或过期时间（键什么时候会被删除）： EXPIRE＜key＞＜ttl＞命令用于将键key的生存时间设置为ttl秒。 PEXPIRE＜key＞＜ttl＞命令用于将键key的生存时间设置为ttl毫秒。 EXPIREAT＜key＞＜timestamp＞命令用于将键key的过期时间设置为timestamp所指定的秒数时间戳。 PEXPIREAT＜key＞＜timestamp＞命令用于将键key的过期时间设置为timestamp所指定的毫秒数时间戳。 ","date":"2022-12-08","objectID":"/posts/redis-server-database-implementation-introduction/:4:1","tags":["Redis"],"title":"Redis服务器数据库实现介绍","uri":"/posts/redis-server-database-implementation-introduction/"},{"categories":["后台开发"],"content":"保存过期时间 redisDb结构的expires字典保存了数据库中所有键的过期时间，我们称这个字典为过期字典： 过期字典的键是一个指针，这个指针指向键空间中的某个键对象（也即是某个数据库键）。 过期字典的值是一个long long类型的整数，这个整数保存了键所指向的数据库键的过期时间——一个毫秒精度的UNIX时间戳。 ","date":"2022-12-08","objectID":"/posts/redis-server-database-implementation-introduction/:4:2","tags":["Redis"],"title":"Redis服务器数据库实现介绍","uri":"/posts/redis-server-database-implementation-introduction/"},{"categories":["后台开发"],"content":"移除过期时间 PERSIST命令就是PEXPIREAT命令的反操作：PERSIST命令在过期字典中查找给定的键，并解除键和值（过期时间）在过期字典中的关联。 ","date":"2022-12-08","objectID":"/posts/redis-server-database-implementation-introduction/:4:3","tags":["Redis"],"title":"Redis服务器数据库实现介绍","uri":"/posts/redis-server-database-implementation-introduction/"},{"categories":["后台开发"],"content":"过期键的判定 通过过期字典，程序可以用以下步骤检查一个给定键是否过期： 检查给定键是否存在于过期字典：如果存在，那么取得键的过期时间。 检查当前UNIX时间戳是否大于键的过期时间：如果是的话，那么键已经过期；否则的话，键未过期。 ","date":"2022-12-08","objectID":"/posts/redis-server-database-implementation-introduction/:4:4","tags":["Redis"],"title":"Redis服务器数据库实现介绍","uri":"/posts/redis-server-database-implementation-introduction/"},{"categories":["后台开发"],"content":"过期键删除策略 三种不同的删除策略： 定时删除：在设置键的过期时间的同时，创建一个定时器（timer），让定时器在键的过期时间来临时，立即执行对键的删除操作。 惰性删除：放任键过期不管，但是每次从键空间中获取键时，都检查取得的键是否过期，如果过期的话，就删除该键；如果没有过期，就返回该键。 定期删除：每隔一段时间，程序就对数据库进行一次检查，删除里面的过期键。至于要删除多少过期键，以及要检查多少个数据库，则由算法决定。 ","date":"2022-12-08","objectID":"/posts/redis-server-database-implementation-introduction/:5:0","tags":["Redis"],"title":"Redis服务器数据库实现介绍","uri":"/posts/redis-server-database-implementation-introduction/"},{"categories":["后台开发"],"content":"定时删除 定时删除策略对内存是最友好的：通过使用定时器，定时删除策略可以保证过期键会尽可能快地被删除，并释放过期键所占用的内存。 另一方面，定时删除策略的缺点是，它对CPU时间是最不友好的。 除此之外，创建一个定时器需要用到Redis服务器中的时间事件，而当前时间事件的实现方式——无序链表，查找一个事件的时间复杂度为O（N）——并不能高效地处理大量时间事件。 ","date":"2022-12-08","objectID":"/posts/redis-server-database-implementation-introduction/:5:1","tags":["Redis"],"title":"Redis服务器数据库实现介绍","uri":"/posts/redis-server-database-implementation-introduction/"},{"categories":["后台开发"],"content":"惰性删除 惰性删除策略对CPU时间来说是最友好的：程序只会在取出键时才对键进行过期检查，这可以保证删除过期键的操作只会在非做不可的情况下进行，并且删除的目标仅限于当前处理的键，这个策略不会在删除其他无关的过期键上花费任何CPU时间。 惰性删除策略的缺点是，它对内存是最不友好的：如果一个键已经过期，而这个键又仍然保留在数据库中，那么只要这个过期键不被删除，它所占用的内存就不会释放。 在使用惰性删除策略时，如果数据库中有非常多的过期键，而这些过期键又恰好没有被访问到的话，那么它们也许永远也不会被删除（除非用户手动执行FLUSHDB），我们甚至可以将这种情况看作是一种内存泄漏——无用的垃圾数据占用了大量的内存。 ","date":"2022-12-08","objectID":"/posts/redis-server-database-implementation-introduction/:5:2","tags":["Redis"],"title":"Redis服务器数据库实现介绍","uri":"/posts/redis-server-database-implementation-introduction/"},{"categories":["后台开发"],"content":"定期删除 从上面对定时删除和惰性删除的讨论来看，这两种删除方式在单一使用时都有明显的缺陷： 定时删除占用太多CPU时间，影响服务器的响应时间和吞吐量。 惰性删除浪费太多内存，有内存泄漏的危险。 定期删除策略是前两种策略的一种整合和折中： 定期删除策略每隔一段时间执行一次删除过期键操作，并通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响。 除此之外，通过定期删除过期键，定期删除策略有效地减少了因为过期键而带来的内存浪费。 定期删除策略的难点是确定删除操作执行的时长和频率： 如果删除操作执行得太频繁，或者执行的时间太长，定期删除策略就会退化成定时删除策略，以至于将CPU时间过多地消耗在删除过期键上面。 如果删除操作执行得太少，或者执行的时间太短，定期删除策略又会和惰性删除策略一样，出现浪费内存的情况。 因此，如果采用定期删除策略的话，服务器必须根据情况，合理地设置删除操作的执行时长和执行频率。 ","date":"2022-12-08","objectID":"/posts/redis-server-database-implementation-introduction/:5:3","tags":["Redis"],"title":"Redis服务器数据库实现介绍","uri":"/posts/redis-server-database-implementation-introduction/"},{"categories":["后台开发"],"content":"Redis的过期键删除策略 Redis服务器实际使用的是惰性删除和定期删除两种策略：通过配合使用这两种删除策略，服务器可以很好地在合理使用CPU时间和避免浪费内存空间之间取得平衡。 ","date":"2022-12-08","objectID":"/posts/redis-server-database-implementation-introduction/:6:0","tags":["Redis"],"title":"Redis服务器数据库实现介绍","uri":"/posts/redis-server-database-implementation-introduction/"},{"categories":["后台开发"],"content":"惰性删除策略的实现 过期键的惰性删除策略由db.c/expireIfNeeded函数实现，所有读写数据库的Redis命令在执行之前都会调用expireIfNeeded函数对输入键进行检查： 如果输入键已经过期，那么expireIfNeeded函数将输入键从数据库中删除。 如果输入键未过期，那么expireIfNeeded函数不做动作。 ","date":"2022-12-08","objectID":"/posts/redis-server-database-implementation-introduction/:6:1","tags":["Redis"],"title":"Redis服务器数据库实现介绍","uri":"/posts/redis-server-database-implementation-introduction/"},{"categories":["后台开发"],"content":"定期删除策略的实现 过期键的定期删除策略由redis.c/activeExpireCycle函数实现，每当Redis的服务器周期性操作redis.c/serverCron函数执行时，activeExpireCycle函数就会被调用，它在规定的时间内，分多次遍历服务器中的各个数据库，从数据库的expires字典中随机检查一部分键的过期时间，并删除其中的过期键。 整个过程可以用伪代码描述如下： #默认每次检查的数据库数量 DEFAULT_DB_NUMBERS = 16 #默认每个数据库检查的键数量 DEFAULT_KEY_NUMBERS = 20 #全局变量，记录检查进度 current_db = 0 def activeExpireCycle(): #初始化要检查的数据库数量 #如果服务器的数据库数量比 DEFAULT_DB_NUMBERS要小 #那么以服务器的数据库数量为准 if server.dbnum ＜ DEFAULT_DB_NUMBERS: db_numbers = server.dbnum else: db_numbers = DEFAULT_DB_NUMBERS #遍历各个数据库 for i in range(db_numbers): #如果current_db的值等于服务器的数据库数量 #这表示检查程序已经遍历了服务器的所有数据库一次 #将current_db重置为0，开始新的一轮遍历 if current_db == server.dbnum: current_db = 0 #获取当前要处理的数据库 redisDb = server.db[current_db] #将数据库索引增1，指向下一个要处理的数据库 current_db += 1 #检查数据库键 for j in range(DEFAULT_KEY_NUMBERS): #如果数据库中没有一个键带有过期时间，那么跳过这个数据库 if redisDb.expires.size() == 0: break #随机获取一个带有过期时间的键 key_with_ttl = redisDb.expires.get_random_key() #检查键是否过期，如果过期就删除它 if is_expired(key_with_ttl): delete_key(key_with_ttl) #已达到时间上限，停止处理 if reach_time_limit(): return activeExpireCycle函数的工作模式可以总结如下： 函数每次运行时，都从一定数量的数据库中取出一定数量的随机键进行检查，并删除其中的过期键。 全局变量current_db会记录当前activeExpireCycle函数检查的进度，并在下一次activeExpireCycle函数调用时，接着上一次的进度进行处理。 随着activeExpireCycle函数的不断执行，服务器中的所有数据库都会被检查一遍，这时函数将current_db变量重置为0，然后再次开始新一轮的检查工作。 ","date":"2022-12-08","objectID":"/posts/redis-server-database-implementation-introduction/:6:2","tags":["Redis"],"title":"Redis服务器数据库实现介绍","uri":"/posts/redis-server-database-implementation-introduction/"},{"categories":["后台开发"],"content":"AOF、RDB和复制功能对过期键的处理 ","date":"2022-12-08","objectID":"/posts/redis-server-database-implementation-introduction/:7:0","tags":["Redis"],"title":"Redis服务器数据库实现介绍","uri":"/posts/redis-server-database-implementation-introduction/"},{"categories":["后台开发"],"content":"生成RDB文件 在执行SAVE命令或者BGSAVE命令创建一个新的RDB文件时，程序会对数据库中的键进行检查，已过期的键不会被保存到新创建的RDB文件中。 ","date":"2022-12-08","objectID":"/posts/redis-server-database-implementation-introduction/:7:1","tags":["Redis"],"title":"Redis服务器数据库实现介绍","uri":"/posts/redis-server-database-implementation-introduction/"},{"categories":["后台开发"],"content":"载入RDB文件 在启动Redis服务器时，如果服务器开启了RDB功能，那么服务器将对RDB文件进行载入： 如果服务器以主服务器模式运行，那么在载入RDB文件时，程序会对文件中保存的键进行检查，未过期的键会被载入到数据库中，而过期键则会被忽略，所以过期键对载入RDB文件的主服务器不会造成影响。 如果服务器以从服务器模式运行，那么在载入RDB文件时，文件中保存的所有键，不论是否过期，都会被载入到数据库中。不过，因为主从服务器在进行数据同步的时候，从服务器的数据库就会被清空，所以一般来讲，过期键对载入RDB文件的从服务器也不会造成影响。 ","date":"2022-12-08","objectID":"/posts/redis-server-database-implementation-introduction/:7:2","tags":["Redis"],"title":"Redis服务器数据库实现介绍","uri":"/posts/redis-server-database-implementation-introduction/"},{"categories":["后台开发"],"content":"AOF文件写入 当服务器以AOF持久化模式运行时，如果数据库中的某个键已经过期，但它还没有被惰性删除或者定期删除，那么AOF文件不会因为这个过期键而产生任何影响。当过期键被惰性删除或者定期删除之后，程序会向AOF文件追加（append）一条DEL命令，来显式地记录该键已被删除。 ","date":"2022-12-08","objectID":"/posts/redis-server-database-implementation-introduction/:7:3","tags":["Redis"],"title":"Redis服务器数据库实现介绍","uri":"/posts/redis-server-database-implementation-introduction/"},{"categories":["后台开发"],"content":"AOF重写 和生成RDB文件时类似，在执行AOF重写的过程中，程序会对数据库中的键进行检查，已过期的键不会被保存到重写后的AOF文件中。 ","date":"2022-12-08","objectID":"/posts/redis-server-database-implementation-introduction/:7:4","tags":["Redis"],"title":"Redis服务器数据库实现介绍","uri":"/posts/redis-server-database-implementation-introduction/"},{"categories":["后台开发"],"content":"复制 当服务器运行在复制模式下时，从服务器的过期键删除动作由主服务器控制： 主服务器在删除一个过期键之后，会显式地向所有从服务器发送一个DEL命令，告知从服务器删除这个过期键。 从服务器在执行客户端发送的读命令时，即使碰到过期键也不会将过期键删除，而是继续像处理未过期的键一样来处理过期键。❑从服务器只有在接到主服务器发来的DEL命令之后，才会删除过期键。 通过由主服务器来控制从服务器统一地删除过期键，可以保证主从服务器数据的一致性，也正是因为这个原因，当一个过期键仍然存在于主服务器的数据库时，这个过期键在从服务器里的复制品也会继续存在。 ","date":"2022-12-08","objectID":"/posts/redis-server-database-implementation-introduction/:7:5","tags":["Redis"],"title":"Redis服务器数据库实现介绍","uri":"/posts/redis-server-database-implementation-introduction/"},{"categories":["后台开发"],"content":"重点回顾 Redis服务器的所有数据库都保存在redisServer.db数组中，而数据库的数量则由redisServer.dbnum属性保存。 客户端通过修改目标数据库指针，让它指向redisServer.db数组中的不同元素来切换不同的数据库。 数据库主要由dict和expires两个字典构成，其中dict字典负责保存键值对，而expires字典则负责保存键的过期时间。 因为数据库由字典构成，所以对数据库的操作都是建立在字典操作之上的。 数据库的键总是一个字符串对象，而值则可以是任意一种Redis对象类型，包括字符串对象、哈希表对象、集合对象、列表对象和有序集合对象，分别对应字符串键、哈希表键、集合键、列表键和有序集合键。❑expires字典的键指向数据库中的某个键，而值则记录了数据库键的过期时间，过期时间是一个以毫秒为单位的UNIX时间戳。 Redis使用惰性删除和定期删除两种策略来删除过期的键：惰性删除策略只在碰到过期键时才进行删除操作，定期删除策略则每隔一段时间主动查找并删除过期键。 执行SAVE命令或者BGSAVE命令所产生的新RDB文件不会包含已经过期的键。 执行BGREWRITEAOF命令所产生的重写AOF文件不会包含已经过期的键。 当一个过期键被删除之后，服务器会追加一条DEL命令到现有AOF文件的末尾，显式地删除过期键。 当主服务器删除一个过期键之后，它会向所有从服务器发送一条DEL命令，显式地删除过期键。 从服务器即使发现过期键也不会自作主张地删除它，而是等待主节点发来DEL命令，这种统一、中心化的过期键删除策略可以保证主从服务器数据的一致性。 当Redis命令对数据库进行修改之后，服务器会根据配置向客户端发送数据库通知。 ","date":"2022-12-08","objectID":"/posts/redis-server-database-implementation-introduction/:8:0","tags":["Redis"],"title":"Redis服务器数据库实现介绍","uri":"/posts/redis-server-database-implementation-introduction/"},{"categories":["后台开发"],"content":"在 Redis底层数据结构介绍1 中我们介绍了Redis用到的所有主要数据结构，比如简单动态字符串（SDS）、双端链表、字典、压缩列表、整数集合等等。Redis并没有直接使用这些数据结构来实现键值对数据库，而是基于这些数据结构创建了一个对象系统，这个系统包含字符串对象、列表对象、哈希对象、集合对象和有序集合对象这五种类型的对象，每种对象都用到了至少一种我们前面所介绍的数据结构。 通过这五种不同类型的对象，Redis可以在执行命令之前，根据对象的类型来判断一个对象是否可以执行给定的命令。使用对象的另一个好处是，我们可以针对不同的使用场景，为对象设置多种不同的数据结构实现，从而优化对象在不同场景下的使用效率。 除此之外，Redis的对象系统还实现了基于引用计数技术的内存回收机制，当程序不再使用某个对象的时候，这个对象所占用的内存就会被自动释放；另外，Redis还通过引用计数技术实现了对象共享机制，这一机制可以在适当的条件下，通过让多个数据库键共享同一个对象来节约内存。 最后，Redis的对象带有访问时间记录信息，该信息可以用于计算数据库键的空转时长，在服务器启用了maxmemory功能的情况下，空转时长较大的那些键可能会优先被服务器删除。 ","date":"2022-12-07","objectID":"/posts/introduction-to-redis-object/:0:0","tags":["Redis"],"title":"Redis对象介绍","uri":"/posts/introduction-to-redis-object/"},{"categories":["后台开发"],"content":"对象的类型与编码2 Redis使用对象来表示数据库中的键和值，每次当我们在Redis的数据库中新创建一个键值对时，我们至少会创建两个对象，一个对象用作键值对的键（键对象），另一个对象用作键值对的值（值对象）。 Redis中的每个对象都由一个redisObject结构表示，该结构中和保存数据有关的三个属性分别是type属性、encoding属性和ptr属性： typedef struct redisObject { //类型 unsigned type:4; //编码 unsigned encoding:4; //指向底层实现数据结构的指针 void *ptr; // ... } robj; ","date":"2022-12-07","objectID":"/posts/introduction-to-redis-object/:1:0","tags":["Redis"],"title":"Redis对象介绍","uri":"/posts/introduction-to-redis-object/"},{"categories":["后台开发"],"content":"类型 对象的type属性记录了对象的类型，这个属性的下表列出的常量的其中一个。 对于Redis数据库保存的键值对来说，键总是一个字符串对象，而值则可以是字符串对象、列表对象、哈希对象、集合对象或者有序集合对象的其中一种，因此： 当我们称呼一个数据库键为“字符串键”时，我们指的是“这个数据库键所对应的值为字符串对象”； 当我们称呼一个键为“列表键”时，我们指的是“这个数据库键所对应的值为列表对象”。 ","date":"2022-12-07","objectID":"/posts/introduction-to-redis-object/:1:1","tags":["Redis"],"title":"Redis对象介绍","uri":"/posts/introduction-to-redis-object/"},{"categories":["后台开发"],"content":"编码和底层实现 对象的ptr指针指向对象的底层实现数据结构，而这些数据结构由对象的encoding属性决定。encoding属性记录了对象所使用的编码，也即是说这个对象使用了什么数据结构作为对象的底层实现。 通过encoding属性来设定对象所使用的编码，而不是为特定类型的对象关联一种固定的编码，极大地提升了Redis的灵活性和效率，因为Redis可以根据不同的使用场景来为一个对象设置不同的编码，从而优化对象在某一场景下的效率。 ","date":"2022-12-07","objectID":"/posts/introduction-to-redis-object/:1:2","tags":["Redis"],"title":"Redis对象介绍","uri":"/posts/introduction-to-redis-object/"},{"categories":["后台开发"],"content":"字符串对象 字符串对象的编码可以是int、raw或者embstr。 如果一个字符串对象保存的是整数值，并且这个整数值可以用long类型来表示，那么字符串对象会将整数值保存在字符串对象结构的ptr属性里面（将void*转换成long），并将字符串对象的编码设置为int。 如果字符串对象保存的是一个字符串值，并且这个字符串值的长度大于32字节，那么字符串对象将使用一个简单动态字符串（SDS）来保存这个字符串值，并将对象的编码设置为raw。 如果字符串对象保存的是一个字符串值，并且这个字符串值的长度小于等于32字节，那么字符串对象将使用embstr编码的方式来保存这个字符串值。 embstr编码是专门用于保存短字符串的一种优化编码方式，这种编码和raw编码一样，都使用redisObject结构和sdshdr结构来表示字符串对象，但raw编码会调用两次内存分配函数来分别创建redisObject结构和sdshdr结构，而embstr编码则通过调用一次内存分配函数来分配一块连续的空间，空间中依次包含redisObject和sdshdr两个结构。 embstr编码的字符串对象在执行命令时，产生的效果和raw编码的字符串对象执行命令时产生的效果是相同的，但使用embstr编码的字符串对象来保存短字符串值有以下好处： embstr编码将创建字符串对象所需的内存分配次数从raw编码的两次降低为一次。 释放embstr编码的字符串对象只需要调用一次内存释放函数，而释放raw编码的字符串对象需要调用两次内存释放函数。 因为embstr编码的字符串对象的所有数据都保存在一块连续的内存里面，所以这种编码的字符串对象比起raw编码的字符串对象能够更好地利用缓存带来的优势。 ","date":"2022-12-07","objectID":"/posts/introduction-to-redis-object/:2:0","tags":["Redis"],"title":"Redis对象介绍","uri":"/posts/introduction-to-redis-object/"},{"categories":["后台开发"],"content":"编码转换 int编码的字符串对象和embstr编码的字符串对象在条件满足的情况下，会被转换为raw编码的字符串对象。对于int编码的字符串对象来说，如果我们向对象执行了一些命令，使得这个对象保存的不再是整数值，而是一个字符串值，那么字符串对象的编码将从int变为raw。 因为Redis没有为embstr编码的字符串对象编写任何相应的修改程序（只有int编码的字符串对象和raw编码的字符串对象有这些程序），所以embstr编码的字符串对象实际上是只读的。当我们对embstr编码的字符串对象执行任何修改命令时，程序会先将对象的编码从embstr转换成raw，然后再执行修改命令。 ","date":"2022-12-07","objectID":"/posts/introduction-to-redis-object/:2:1","tags":["Redis"],"title":"Redis对象介绍","uri":"/posts/introduction-to-redis-object/"},{"categories":["后台开发"],"content":"列表对象 列表对象的编码可以是ziplist或者linkedlist。 ziplist编码的列表对象使用压缩列表作为底层实现，每个压缩列表节点（entry）保存了一个列表元素。 linkedlist编码的列表对象使用双端链表作为底层实现，每个双端链表节点（node）都保存了一个字符串对象，而每个字符串对象都保存了一个列表元素。 ","date":"2022-12-07","objectID":"/posts/introduction-to-redis-object/:3:0","tags":["Redis"],"title":"Redis对象介绍","uri":"/posts/introduction-to-redis-object/"},{"categories":["后台开发"],"content":"编码转换 当列表对象可以同时满足以下两个条件时，列表对象使用ziplist编码： 列表对象保存的所有字符串元素的长度都小于64字节； 列表对象保存的元素数量小于512个；不能满足这两个条件的列表对象需要使用linkedlist编码。 ","date":"2022-12-07","objectID":"/posts/introduction-to-redis-object/:3:1","tags":["Redis"],"title":"Redis对象介绍","uri":"/posts/introduction-to-redis-object/"},{"categories":["后台开发"],"content":"哈希对象 哈希对象的编码可以是ziplist或者hashtable。 ziplist编码的哈希对象使用压缩列表作为底层实现，每当有新的键值对要加入到哈希对象时，程序会先将保存了键的压缩列表节点推入到压缩列表表尾，然后再将保存了值的压缩列表节点推入到压缩列表表尾。 hashtable编码的哈希对象使用字典作为底层实现，哈希对象中的每个键值对都使用一个字典键值对来保存： 字典的每个键都是一个字符串对象，对象中保存了键值对的键； 字典的每个值都是一个字符串对象，对象中保存了键值对的值。 ","date":"2022-12-07","objectID":"/posts/introduction-to-redis-object/:4:0","tags":["Redis"],"title":"Redis对象介绍","uri":"/posts/introduction-to-redis-object/"},{"categories":["后台开发"],"content":"编码转换 当哈希对象可以同时满足以下两个条件时，哈希对象使用ziplist编码： 哈希对象保存的所有键值对的键和值的字符串长度都小于64字节； 哈希对象保存的键值对数量小于512个；不能满足这两个条件的哈希对象需要使用hashtable编码。 这两个条件的上限值是可以修改的，具体请看配置文件中关于hash-max-ziplist-value选项和hash-max-ziplist-entries选项的说明。 ","date":"2022-12-07","objectID":"/posts/introduction-to-redis-object/:4:1","tags":["Redis"],"title":"Redis对象介绍","uri":"/posts/introduction-to-redis-object/"},{"categories":["后台开发"],"content":"集合对象 集合对象的编码可以是intset或者hashtable。 intset编码的集合对象使用整数集合作为底层实现，集合对象包含的所有元素都被保存在整数集合里面。 hashtable编码的集合对象使用字典作为底层实现，字典的每个键都是一个字符串对象，每个字符串对象包含了一个集合元素，而字典的值则全部被设置为NULL。 ","date":"2022-12-07","objectID":"/posts/introduction-to-redis-object/:5:0","tags":["Redis"],"title":"Redis对象介绍","uri":"/posts/introduction-to-redis-object/"},{"categories":["后台开发"],"content":"编码转换 当集合对象可以同时满足以下两个条件时，对象使用intset编码： 集合对象保存的所有元素都是整数值； 集合对象保存的元素数量不超过512个。 不能满足这两个条件的集合对象需要使用hashtable编码。 ","date":"2022-12-07","objectID":"/posts/introduction-to-redis-object/:5:1","tags":["Redis"],"title":"Redis对象介绍","uri":"/posts/introduction-to-redis-object/"},{"categories":["后台开发"],"content":"有序集合对象 有序集合的编码可以是ziplist或者skiplist。 ziplist编码的压缩列表对象使用压缩列表作为底层实现，每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员（member），而第二个元素则保存元素的分值（score）。压缩列表内的集合元素按分值从小到大进行排序，分值较小的元素被放置在靠近表头的方向，而分值较大的元素则被放置在靠近表尾的方向。 skiplist编码的有序集合对象使用zset结构作为底层实现，一个zset结构同时包含一个字典和一个跳跃表。 zset结构定义： typedef struct zset { zskiplist *zsl; dict *dict; } zset; zset结构中的zsl跳跃表按分值从小到大保存了所有集合元素，每个跳跃表节点都保存了一个集合元素：跳跃表节点的object属性保存了元素的成员，而跳跃表节点的score属性则保存了元素的分值。通过这个跳跃表，程序可以对有序集合进行范围型操作，比如ZRANK、ZRANGE等命令就是基于跳跃表API来实现的。 除此之外，zset结构中的dict字典为有序集合创建了一个从成员到分值的映射，字典中的每个键值对都保存了一个集合元素：字典的键保存了元素的成员，而字典的值则保存了元素的分值。通过这个字典，程序可以用O（1）复杂度查找给定成员的分值，ZSCORE命令就是根据这一特性实现的，而很多其他有序集合命令都在实现的内部用到了这一特性。 有序集合每个元素的成员都是一个字符串对象，而每个元素的分值都是一个double类型的浮点数。值得一提的是，虽然zset结构同时使用跳跃表和字典来保存有序集合元素，但这两种数据结构都会通过指针来共享相同元素的成员和分值，所以同时使用跳跃表和字典来保存集合元素不会产生任何重复成员或者分值，也不会因此而浪费额外的内存。 为什么有序集合需要同时使用跳跃表和字典来实现？ 在理论上，有序集合可以单独使用字典或者跳跃表的其中一种数据结构来实现，但无论单独使用字典还是跳跃表，在性能上对比起同时使用字典和跳跃表都会有所降低。举个例子，如果我们只使用字典来实现有序集合，那么虽然以O（1）复杂度查找成员的分值这一特性会被保留，但是，因为字典以无序的方式来保存集合元素，所以每次在执行范围型操作——比如ZRANK、ZRANGE等命令时，程序都需要对字典保存的所有元素进行排序，完成这种排序需要至少O（NlogN）时间复杂度，以及额外的O（N）内存空间（因为要创建一个数组来保存排序后的元素）。 另一方面，如果我们只使用跳跃表来实现有序集合，那么跳跃表执行范围型操作的所有优点都会被保留，但因为没有了字典，所以根据成员查找分值这一操作的复杂度将从O（1）上升为O（logN）。因为以上原因，为了让有序集合的查找和范围型操作都尽可能快地执行，Redis选择了同时使用字典和跳跃表两种数据结构来实现有序集合。 ","date":"2022-12-07","objectID":"/posts/introduction-to-redis-object/:6:0","tags":["Redis"],"title":"Redis对象介绍","uri":"/posts/introduction-to-redis-object/"},{"categories":["后台开发"],"content":"编码转换 当有序集合对象可以同时满足以下两个条件时，对象使用ziplist编码： 有序集合保存的元素数量小于128个； 有序集合保存的所有元素成员的长度都小于64字节； 不能满足以上两个条件的有序集合对象将使用skiplist编码。 ","date":"2022-12-07","objectID":"/posts/introduction-to-redis-object/:6:1","tags":["Redis"],"title":"Redis对象介绍","uri":"/posts/introduction-to-redis-object/"},{"categories":["后台开发"],"content":"类型检查与多态 Redis除了会根据值对象的类型来判断键是否能够执行指定命令之外，还会根据值对象的编码方式，选择正确的命令实现代码来执行命令。 ","date":"2022-12-07","objectID":"/posts/introduction-to-redis-object/:7:0","tags":["Redis"],"title":"Redis对象介绍","uri":"/posts/introduction-to-redis-object/"},{"categories":["后台开发"],"content":"内存回收 因为C语言并不具备自动内存回收功能，所以Redis在自己的对象系统中构建了一个引用计数（reference counting）技术实现的内存回收机制，通过这一机制，程序可以通过跟踪对象的引用计数信息，在适当的时候自动释放对象并进行内存回收。 每个对象的引用计数信息由redisObject结构的refcount属性记录： typedef struct redisObject { // ... //引用计数 int refcount; // ... } robj; 对象的引用计数信息会随着对象的使用状态而不断变化： 在创建一个新对象时，引用计数的值会被初始化为1； 当对象被一个新程序使用时，它的引用计数值会被增一； 当对象不再被一个程序使用时，它的引用计数值会被减一； 当对象的引用计数值变为0时，对象所占用的内存会被释放。 ","date":"2022-12-07","objectID":"/posts/introduction-to-redis-object/:8:0","tags":["Redis"],"title":"Redis对象介绍","uri":"/posts/introduction-to-redis-object/"},{"categories":["后台开发"],"content":"对象共享 Redis会在初始化服务器时，创建一万个字符串对象，这些对象包含了从0到9999的所有整数值，当服务器需要用到值为0到9999的字符串对象时，服务器就会使用这些共享对象，而不是新创建对象。 在Redis中，让多个键共享同一个值对象需要执行以下两个步骤： 将数据库键的值指针指向一个现有的值对象； 将被共享的值对象的引用计数增一。 共享对象机制对于节约内存非常有帮助，数据库中保存的相同值对象越多，对象共享机制就能节约越多的内存。 尽管共享更复杂的对象可以节约更多的内存，但受到CPU时间的限制，Redis只对包含整数值的字符串对象进行共享。 ","date":"2022-12-07","objectID":"/posts/introduction-to-redis-object/:9:0","tags":["Redis"],"title":"Redis对象介绍","uri":"/posts/introduction-to-redis-object/"},{"categories":["后台开发"],"content":"对象的空转时长 除了前面介绍过的type、encoding、ptr和refcount四个属性之外，redisObject结构包含的最后一个属性为lru属性，该属性记录了对象最后一次被命令程序访问的时间： typedef struct redisObject { // ... unsigned lru:22; // ... } robj; 如果服务器打开了maxmemory选项，并且服务器用于回收内存的算法为volatile-lru或者allkeys-lru，那么当服务器占用的内存数超过了maxmemory选项所设置的上限值时，空转时长较高的那部分键会优先被服务器释放，从而回收内存。 ","date":"2022-12-07","objectID":"/posts/introduction-to-redis-object/:10:0","tags":["Redis"],"title":"Redis对象介绍","uri":"/posts/introduction-to-redis-object/"},{"categories":["后台开发"],"content":"重点回顾 Redis数据库中的每个键值对的键和值都是一个对象。 Redis共有字符串、列表、哈希、集合、有序集合五种类型的对象，每种类型的对象至少都有两种或以上的编码方式，不同的编码可以在不同的使用场景上优化对象的使用效率。 服务器在执行某些命令之前，会先检查给定键的类型能否执行指定的命令，而检查一个键的类型就是检查键的值对象的类型。 Redis的对象系统带有引用计数实现的内存回收机制，当一个对象不再被使用时，该对象所占用的内存就会被自动释放。 Redis会共享值为0到9999的字符串对象。 对象会记录自己的最后一次被访问的时间，这个时间可以用于计算对象的空转时间。 参考来源： https://chuxing.club/posts/introduction-to-the-underlying-data-structure-of-redis/ ↩︎ 《Redis设计与实现》 ↩︎ ","date":"2022-12-07","objectID":"/posts/introduction-to-redis-object/:11:0","tags":["Redis"],"title":"Redis对象介绍","uri":"/posts/introduction-to-redis-object/"},{"categories":["hugo"],"content":"Hugo是由Go语言实现的静态网站生成器。简单、易用、高效、易扩展、快速部署。 ","date":"2022-12-03","objectID":"/posts/hugo-quick-start/:0:0","tags":["hugo"],"title":"Hugo Quick Start","uri":"/posts/hugo-quick-start/"},{"categories":["hugo"],"content":"Intall go install github.com/gohugoio/hugo@latest ","date":"2022-12-03","objectID":"/posts/hugo-quick-start/:1:0","tags":["hugo"],"title":"Hugo Quick Start","uri":"/posts/hugo-quick-start/"},{"categories":["hugo"],"content":"Quick Start https://gohugo.io/getting-started/quick-start/ 运行以下命令创建一个使用Ananke主题的网站： hugo new site quickstart cd quickstart git init git submodule add https://github.com/theNewDynamic/gohugo-theme-ananke themes/ananke echo \"theme = 'ananke'\" \u003e\u003e config.toml hugo server ","date":"2022-12-03","objectID":"/posts/hugo-quick-start/:2:0","tags":["hugo"],"title":"Hugo Quick Start","uri":"/posts/hugo-quick-start/"},{"categories":["hugo"],"content":"Add Content 给网站增加新的网页： hugo new posts/my-first-post.md Hugo在content/posts目录创建了my-first-post.md文件，文件内容如下： --- title: \"My First Post\" date: 2022-11-20T09:03:20-08:00 draft: true --- 修改并保存文件后启动Hugo服务器可以预览网站，可以使用以下的任一命令以包含draft内容： hugo server --buildDrafts hugo server -D ","date":"2022-12-03","objectID":"/posts/hugo-quick-start/:3:0","tags":["hugo"],"title":"Hugo Quick Start","uri":"/posts/hugo-quick-start/"},{"categories":["hugo"],"content":"Configure the site 可以通过根目录的config.toml文件配置网站相关信息： baseURL = 'http://example.org/' languageCode = 'en-us' title = 'My New Hugo Site' theme = 'ananke' ","date":"2022-12-03","objectID":"/posts/hugo-quick-start/:4:0","tags":["hugo"],"title":"Hugo Quick Start","uri":"/posts/hugo-quick-start/"},{"categories":["hugo"],"content":"Publish the site 生成站点的静态文件，文件将生成到根目录下的public目录 hugo ","date":"2022-12-03","objectID":"/posts/hugo-quick-start/:5:0","tags":["hugo"],"title":"Hugo Quick Start","uri":"/posts/hugo-quick-start/"},{"categories":["hugo"],"content":"Host on GitHub https://gohugo.io/hosting-and-deployment/hosting-on-github/ 创建名为\u003cUSERNAME\u003e.github.io 或 \u003cORGANIZATION\u003e.github.io的GitHub仓库 在仓库中新增文件.github/workflows/gh-pages.yml并填写以下内容： name: github pages on: push: branches: - main # Set a branch that will trigger a deployment pull_request: jobs: deploy: runs-on: ubuntu-22.04 steps: - uses: actions/checkout@v3 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: 'latest' # extended: true - name: Build run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 if: github.ref == 'refs/heads/main' with: github_token: ${{ secrets.GITHUB_TOKEN }} publish_dir: ./public 把config.toml中的baseURL修改为https://\u003cUSERNAME\u003e.github.io。 Ref： https://github.com/gohugoio/hugo https://www.xianmin.org/post/2022/07-familiar-one-keybinding-style/ ","date":"2022-12-03","objectID":"/posts/hugo-quick-start/:6:0","tags":["hugo"],"title":"Hugo Quick Start","uri":"/posts/hugo-quick-start/"},{"categories":["后台开发"],"content":"简单动态字符串 每个sds.h/sdshdr结构表示一个SDS值： struct sdshdr { //记录buf数组中已使用字节的数量 //等于SDS所保存字符串的长度 int len; //记录buf数组中未使用字节的数量 int free; //字节数组，用于保存字符串 char buf[]; }; ","date":"2022-11-30","objectID":"/posts/introduction-to-the-underlying-data-structure-of-redis/:1:0","tags":["Redis"],"title":"Redis底层数据结构介绍","uri":"/posts/introduction-to-the-underlying-data-structure-of-redis/"},{"categories":["后台开发"],"content":"SDS与C字符串的区别 常数时间复杂度获取字符串长度 杜绝缓冲区溢出 减少修改字符串带来的内存重分配次数（空间预分配、惰性空间释放） 二进制安全 兼容部分C字符串函数 ","date":"2022-11-30","objectID":"/posts/introduction-to-the-underlying-data-structure-of-redis/:1:1","tags":["Redis"],"title":"Redis底层数据结构介绍","uri":"/posts/introduction-to-the-underlying-data-structure-of-redis/"},{"categories":["后台开发"],"content":"链表 当一个列表键包含了数量比较多的元素，又或者列表中包含的元素都是比较长的字符串时，Redis就会使用链表作为列表键的底层实现。 每个链表节点使用一个adlist.h/listNode结构来表示： typedef struct listNode { // 前置节点 struct listNode * prev; // 后置节点 struct listNode * next; //节点的值 void * value; }listNode; 每个链表节点由一个listNode结构来表示，每个节点都有一个指向前置节点和后置节点的指针，所以Redis的链表实现是双端链表。 每个链表使用一个list结构来表示，这个结构带有表头节点指针、表尾节点指针，以及链表长度等信息。 因为链表表头节点的前置节点和表尾节点的后置节点都指向NULL，所以Redis的链表实现是无环链表。 虽然仅仅使用多个listNode结构就可以组成链表，但使用adlist.h/list来持有链表的话，操作起来会更方便： typedef struct list { // 表头节点 listNode * head; // 表尾节点 listNode * tail; // 链表所包含的节点数量 unsigned long len; // 节点值复制函数 void *(*dup)(void *ptr); // 节点值释放函数 void (*free)(void *ptr); // 节点值对比函数 int (*match)(void *ptr,void *key); } list; 通过为链表设置不同的类型特定函数，Redis的链表可以用于保存各种不同类型的值。 ","date":"2022-11-30","objectID":"/posts/introduction-to-the-underlying-data-structure-of-redis/:2:0","tags":["Redis"],"title":"Redis底层数据结构介绍","uri":"/posts/introduction-to-the-underlying-data-structure-of-redis/"},{"categories":["后台开发"],"content":"字典 字典，又称为符号表（symbol table）、关联数组（associative array）或映射（map），是一种用于保存键值对（key-value pair）的抽象数据结构。 当一个哈希键包含的键值对比较多，又或者键值对中的元素都是比较长的字符串时，Redis就会使用字典作为哈希键的底层实现。 Redis字典所使用的哈希表由dict.h/dictht结构定义： typedef struct dictht { //哈希表数组 dictEntry **table; //哈希表大小 unsigned long size; //哈希表大小掩码，用于计算索引值 //总是等于size-1 unsigned long sizemask; //该哈希表已有节点的数量 unsigned long used; } dictht; table属性是一个数组，数组中的每个元素都是一个指向dict.h/dictEntry结构的指针，每个dictEntry结构保存着一个键值对。size属性记录了哈希表的大小，也即是table数组的大小，而used属性则记录了哈希表目前已有节点（键值对）的数量。sizemask属性的值总是等于size-1，这个属性和哈希值一起决定一个键应该被放到table数组的哪个索引上面。 哈希表节点使用dictEntry结构表示，每个dictEntry结构都保存着一个键值对： typedef struct dictEntry { //键 void *key; //值 union{ void *val; uint64_tu64; int64_ts64; } v; //指向下个哈希表节点，形成链表 struct dictEntry *next; } dictEntry; key属性保存着键值对中的键，而v属性则保存着键值对中的值，其中键值对的值可以是一个指针，或者是一个uint64_t整数，又或者是一个int64_t整数。next属性是指向另一个哈希表节点的指针，这个指针可以将多个哈希值相同的键值对连接在一次，以此来解决键冲突（collision）的问题。 Redis中的字典由dict.h/dict结构表示： typedef struct dict { //类型特定函数 dictType *type; //私有数据 void *privdata; //哈希表 dictht ht[2]; // rehash索引 //当rehash不在进行时，值为-1 in trehashidx; /* rehashing not in progress if rehashidx == -1 */ } dict; type属性和privdata属性是针对不同类型的键值对，为创建多态字典而设置的： type属性是一个指向dictType结构的指针，每个dictType结构保存了一簇用于操作特定类型键值对的函数，Redis会为用途不同的字典设置不同的类型特定函数。 而privdata属性则保存了需要传给那些类型特定函数的可选参数。 typedef struct dictType { //计算哈希值的函数 unsigned int (*hashFunction)(const void *key); //复制键的函数 void *(*keyDup)(void *privdata, const void *key); //复制值的函数 void *(*valDup)(void *privdata, const void *obj); //对比键的函数 int (*keyCompare)(void *privdata, const void *key1, const void *key2); //销毁键的函数 void (*keyDestructor)(void *privdata, void *key); //销毁值的函数 void (*valDestructor)(void *privdata, void *obj); } dictType; ht属性是一个包含两个项的数组，数组中的每个项都是一个dictht哈希表，一般情况下，字典只使用ht[0]哈希表，ht[1]哈希表只会在对ht[0]哈希表进行rehash时使用。除了ht[1]之外，另一个和rehash有关的属性就是rehashidx，它记录了rehash目前的进度，如果目前没有在进行rehash，那么它的值为-1。 当要将一个新的键值对添加到字典里面时，程序需要先根据键值对的键计算出哈希值和索引值，然后再根据索引值，将包含新键值对的哈希表节点放到哈希表数组的指定索引上面。 Redis计算哈希值和索引值的方法如下： #使用字典设置的哈希函数，计算键key的哈希值 hash = dict-＞type-＞hashFunction(key); #使用哈希表的sizemask属性和哈希值，计算出索引值 #根据情况不同，ht[x]可以是ht[0]或者ht[1] index = hash \u0026 dict-＞ht[x].sizemask; Redis的哈希表使用链地址法（separate chaining）来解决键冲突，每个哈希表节点都有一个next指针，多个哈希表节点可以用next指针构成一个单向链表，被分配到同一个索引上的多个节点可以用这个单向链表连接起来，这就解决了键冲突的问题。 ","date":"2022-11-30","objectID":"/posts/introduction-to-the-underlying-data-structure-of-redis/:3:0","tags":["Redis"],"title":"Redis底层数据结构介绍","uri":"/posts/introduction-to-the-underlying-data-structure-of-redis/"},{"categories":["后台开发"],"content":"rehash 根据BGSAVE命令或BGREWRITEAOF命令是否正在执行，服务器执行扩展操作所需的负载因子并不相同，这是因为在执行BGSAVE命令或BGREWRITEAOF命令的过程中，Redis需要创建当前服务器进程的子进程，而大多数操作系统都采用写时复制（copy-on-write）技术来优化子进程的使用效率，所以在子进程存在期间，服务器会提高执行扩展操作所需的负载因子，从而尽可能地避免在子进程存在期间进行哈希表扩展操作，这可以避免不必要的内存写入操作，最大限度地节约内存。 为了避免rehash对服务器性能造成影响，服务器不是一次性将ht[0]里面的所有键值对全部rehash到ht[1]，而是分多次、渐进式地将ht[0]里面的键值对慢慢地rehash到ht[1]。 哈希表渐进式rehash的详细步骤： 为ht[1]分配空间，让字典同时持有ht[0]和ht[1]两个哈希表。 在字典中维持一个索引计数器变量rehashidx，并将它的值设置为0，表示rehash工作正式开始。 在rehash进行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作以外，还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]，当rehash工作完成之后，程序将rehashidx属性的值增一。 随着字典操作的不断执行，最终在某个时间点上，ht[0]的所有键值对都会被rehash至ht[1]，这时程序将rehashidx属性的值设为-1，表示rehash操作已完成。渐进式rehash的好处在于它采取分而治之的方式，将rehash键值对所需的计算工作均摊到对字典的每个添加、删除、查找和更新操作上，从而避免了集中式rehash而带来的庞大计算量。 因为在进行渐进式rehash的过程中，字典会同时使用ht[0]和ht[1]两个哈希表，所以在渐进式rehash进行期间，字典的删除（delete）、查找（find）、更新（update）等操作会在两个哈希表上进行。例如，要在字典里面查找一个键的话，程序会先在ht[0]里面进行查找，如果没找到的话，就会继续到ht[1]里面进行查找，诸如此类。 另外，在渐进式rehash执行期间，新添加到字典的键值对一律会被保存到ht[1]里面，而ht[0]则不再进行任何添加操作，这一措施保证了ht[0]包含的键值对数量会只减不增，并随着rehash操作的执行而最终变成空表。 ","date":"2022-11-30","objectID":"/posts/introduction-to-the-underlying-data-structure-of-redis/:3:1","tags":["Redis"],"title":"Redis底层数据结构介绍","uri":"/posts/introduction-to-the-underlying-data-structure-of-redis/"},{"categories":["后台开发"],"content":"跳跃表 跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。跳跃表支持平均O（logN）、最坏O（N）复杂度的节点查找，还可以通过顺序性操作来批量处理节点。在大部分情况下，跳跃表的效率可以和平衡树相媲美，并且因为跳跃表的实现比平衡树要来得更为简单，所以有不少程序都使用跳跃表来代替平衡树。Redis使用跳跃表作为有序集合键的底层实现之一，如果一个有序集合包含的元素数量比较多，又或者有序集合中元素的成员（member）是比较长的字符串时，Redis就会使用跳跃表来作为有序集合键的底层实现。 跳跃表节点的实现由redis.h/zskiplistNode结构定义： typedef struct zskiplistNode { //层 struct zskiplistLevel { //前进指针 struct zskiplistNode *forward; //跨度 unsigned int span; } level[]; //后退指针 struct zskiplistNode *backward; //分值 double score; //成员对象 robj *obj; } zskiplistNode; 每次创建一个新跳跃表节点的时候，程序都根据幂次定律（power law，越大的数出现的概率越小）随机生成一个介于1和32之间的值作为level数组的大小，这个大小就是层的“高度”。 跨度（span）实际上是用来计算排位（rank）的：在查找某个节点的过程中，将沿途访问过的所有层的跨度累计起来，得到的结果就是目标节点在跳跃表中的排位。 节点的后退指针（backward属性）用于从表尾向表头方向访问节点：跟可以一次跳过多个节点的前进指针不同，因为每个节点只有一个后退指针，所以每次只能后退至前一个节点。 zskiplist结构的定义如下： typedef struct zskiplist { //表头节点和表尾节点 structz skiplistNode *header, *tail; //表中节点的数量 unsigned long length; //表中层数最大的节点的层数 int level; } zskiplist; ","date":"2022-11-30","objectID":"/posts/introduction-to-the-underlying-data-structure-of-redis/:4:0","tags":["Redis"],"title":"Redis底层数据结构介绍","uri":"/posts/introduction-to-the-underlying-data-structure-of-redis/"},{"categories":["后台开发"],"content":"整数集合 整数集合（intset）是集合键的底层实现之一，当一个集合只包含整数值元素，并且这个集合的元素数量不多时，Redis就会使用整数集合作为集合键的底层实现。 每个intset.h/intset结构表示一个整数集合： typedef struct intset { //编码方式 uint32_t encoding; //集合包含的元素数量 uint32_t length; //保存元素的数组 int8_t contents[]; } intset; contents数组是整数集合的底层实现：整数集合的每个元素都是contents数组的一个数组项（item），各个项在数组中按值的大小从小到大有序地排列，并且数组中不包含任何重复项。 因为引发升级的新元素的长度总是比整数集合现有所有元素的长度都大，所以这个新元素的值要么就大于所有现有元素，要么就小于所有现有元素： 要让一个数组可以同时保存int16_t、int32_t、int64_t三种类型的值，最简单的做法就是直接使用int64_t类型的数组作为整数集合的底层实现。不过这样一来，即使添加到整数集合里面的都是int16_t类型或者int32_t类型的值，数组都需要使用int64_t类型的空间去保存它们，从而出现浪费内存的情况。而整数集合现在的做法既可以让集合能同时保存三种不同类型的值，又可以确保升级操作只会在有需要的时候进行，这可以尽量节省内存。 整数集合不支持降级操作，一旦对数组进行了升级，编码就会一直保持升级后的状态。 ","date":"2022-11-30","objectID":"/posts/introduction-to-the-underlying-data-structure-of-redis/:5:0","tags":["Redis"],"title":"Redis底层数据结构介绍","uri":"/posts/introduction-to-the-underlying-data-structure-of-redis/"},{"categories":["后台开发"],"content":"压缩列表 压缩列表（ziplist）是列表键和哈希键的底层实现之一。当一个列表键只包含少量列表项，并且每个列表项要么就是小整数值，要么就是长度比较短的字符串，那么Redis就会使用压缩列表来做列表键的底层实现。 压缩列表是Redis为了节约内存而开发的，是由一系列特殊编码的连续内存块组成的顺序型（sequential）数据结构。一个压缩列表可以包含任意多个节点（entry），每个节点可以保存一个字节数组或者一个整数值。 ziplist的组成部分： | zlbytes | ztail | zlen | entry1 | entry2 | ... | entryN | zlend | 每个压缩列表节点都由previous_entry_length、encoding、content三个部分组成: | previous_entry_length | encoding | content | 添加新节点到压缩列表，或者从压缩列表中删除节点，可能会引发连锁更新操作，但这种操作出现的几率并不高。 尽管连锁更新的复杂度较高，但它真正造成性能问题的几率是很低的： 首先，压缩列表里要恰好有多个连续的、长度介于250字节至253字节之间的节点，连锁更新才有可能被引发，在实际中，这种情况并不多见；- 其次，即使出现连锁更新，但只要被更新的节点数量不多，就不会对性能造成任何影响：比如说，对三五个节点进行连锁更新是绝对不会影响性能的； ","date":"2022-11-30","objectID":"/posts/introduction-to-the-underlying-data-structure-of-redis/:6:0","tags":["Redis"],"title":"Redis底层数据结构介绍","uri":"/posts/introduction-to-the-underlying-data-structure-of-redis/"},{"categories":["后台开发"],"content":"产品概览 Tair 是快速访问内存 (MDB)/持久性 (LDB) 存储服务。 Tair采用高性能、高可用的分布式集群架构，可以满足企业对读写性能和可扩展容量的高要求。 ","date":"2022-11-27","objectID":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/:1:0","tags":["cache"],"title":"Tair:分布式键/值存储系统","uri":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/"},{"categories":["后台开发"],"content":"系统架构 Tair 集群具有三个必要的模块：ConfigServer、DataServer 和客户端。 通常，一个 Tair 集群包括两个 ConfigServer 和多个 DataServer。 两个 ConfigServer 充当主服务器和备用服务器。 DataServer 和 ConfigServer 之间的心跳检查用于检查集群中活跃的和可用的 DataServer，以建立集群中数据的分布（比较表）。 DataServers 按照 ConfigServer 的指示存储、复制和迁移数据。当客户端启动时，它从 ConfigServer 获取数据分布信息。客户端根据这些数据分布信息，与对应的DataServer进行交互，执行用户的请求。 在架构上，ConfigServer 的作用类似于传统应用系统中的中心节点。整个集群服务依赖于ConfigServer。 事实上，Tair 的 ConfigServers 是非常轻量级的。当一个工作的 ConfigServer 遇到停机时间时，另一个 ConfigServer 会在几秒钟内自动接管。 即使两个 ConfigServer 同时停机，只要 DataServer 没有变化，Tair 也可以正常运行。 用户只需要将应用程序连接到 ConfigServers，不需要知道内部节点的详细信息。 ","date":"2022-11-27","objectID":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/:2:0","tags":["cache"],"title":"Tair:分布式键/值存储系统","uri":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/"},{"categories":["后台开发"],"content":"ConfigServer 两个 ConfigServers 作为主服务器和备用服务器。 集群的实时和可用 DataServer 节点信息是使用 ConfigServer 和 DataServer 之间的心跳检查确定的。 ConfigServer根据DataServer节点信息构建数据分布表，展示数据在集群中的分布情况。 ConfigServer 提供数据分发表查询服务。 ConfigServer 调度数据服务器之间的数据迁移和复制。 ","date":"2022-11-27","objectID":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/:2:1","tags":["cache"],"title":"Tair:分布式键/值存储系统","uri":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/"},{"categories":["后台开发"],"content":"DataServers 数据服务器 DataServers 提供存储引擎。 DataServers 接收客户端发起的操作，例如 put/get/remove。 DataServers 迁移和复制数据。 DataServers 提供访问统计信息。 ","date":"2022-11-27","objectID":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/:2:2","tags":["cache"],"title":"Tair:分布式键/值存储系统","uri":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/"},{"categories":["后台开发"],"content":"Clients 客户端 客户端提供用于访问 Tair 集群的 API。 客户端更新和缓存数据分发表。 客户端提供LocalCache，防止过热的数据访问影响Tair集群服务。 客户端控制流量。 ","date":"2022-11-27","objectID":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/:2:3","tags":["cache"],"title":"Tair:分布式键/值存储系统","uri":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/"},{"categories":["后台开发"],"content":"产品特点 ","date":"2022-11-27","objectID":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/:3:0","tags":["cache"],"title":"Tair:分布式键/值存储系统","uri":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/"},{"categories":["后台开发"],"content":"分布式架构 分布式集群架构用于提供自动灾难恢复和故障转移。 支持负载均衡，数据分布均匀。 系统存储空间和吞吐量性能可以弹性伸缩，解决数据量和QPS性能限制。 功能齐全且用户友好的访问 数据结构丰富。 支持单级键值结构和二级索引结构。 支持各种用途。 还支持计数器模式。 支持数据过期和版本控制。 ","date":"2022-11-27","objectID":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/:3:1","tags":["cache"],"title":"Tair:分布式键/值存储系统","uri":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/"},{"categories":["后台开发"],"content":"Version 支持 Tair 中的每个数据都包含版本号，版本号在每次更新后都会递增。这个特性有助于防止由于数据的并发更新导致的问题。 比如，系统有一个 value 为 “a,b,c”，A 和 B 同时 get 到这个 value。A 执行操作，在后面添加一个 d，value 为 “a,b,c,d”。B 执行操作添加一个 e，value 为”a,b,c,e”。如果不加控制，无论 A 和 B 谁先更新成功，它的更新都会被后到的更新覆盖。 Tair 无法解决这个问题，但是引入了 version 机制避免这样的问题。还是拿刚才的例子，A 和 B 取到数据，假设版本号为 10，A 先更新，更新成功后，value 为”a,b,c,d”，与此同时，版本号会变为 11。当 B 更新时，由于其基于的版本号是 10，服务器会拒绝更新，从而避免 A 的更新被覆盖。B 可以选择 get 新版本的 value，然后在其基础上修改，也可以选择强行更新。 ","date":"2022-11-27","objectID":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/:3:2","tags":["cache"],"title":"Tair:分布式键/值存储系统","uri":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/"},{"categories":["后台开发"],"content":"Item 支持 Tair 还支持将 value 视为一个 item 数组，对 value 中的部分 item 进行操作。比如有个 key 的 value 为 [1,2,3,4,5]，我们可以只获取前两个 item，返回 [1,2]，也可以删除第一个 item，还支持将数据删除，并返回被删除的数据，通过这个接口可以实现一个原子的分布式 FIFO 的队列。 ","date":"2022-11-27","objectID":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/:3:3","tags":["cache"],"title":"Tair:分布式键/值存储系统","uri":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/"},{"categories":["后台开发"],"content":"用途 ","date":"2022-11-27","objectID":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/:4:0","tags":["cache"],"title":"Tair:分布式键/值存储系统","uri":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/"},{"categories":["后台开发"],"content":"数据库缓存 随着业务量的增加，对数据库系统的并发请求越来越多，数据库系统的负载越来越重。当数据库系统过载时，响应速度会变慢，在极端情况下甚至会导致服务中断。 为了解决这个问题，Tair MDB 可以与数据库产品一起部署，以提供高吞吐量和低延迟的存储。 MDB 响应速度快，一般毫秒级完成请求。而且，MDB 支持更高的 QPS 速率，可以处理比数据库更多的并发请求。 通过观察业务，用户可以将热点数据存储在MDB中，显着减轻数据库的负载。这不仅降低了数据库成本，还提高了系统可用性。 ","date":"2022-11-27","objectID":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/:4:1","tags":["cache"],"title":"Tair:分布式键/值存储系统","uri":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/"},{"categories":["后台开发"],"content":"临时数据存储 社交网站、电商网站、游戏、广告等应用需要维护大量的临时数据。 在 MDB 中存储临时数据可以减少内存管理开销和应用程序负载。在分布式环境中，MDB可以作为统一的全局存储，可以防止单点故障造成的数据丢失，解决多个应用之间同步的问题。 一个常见的例子是使用 MDB 作为会话管理器。如果网站采用分布式部署，并且流量很大，同一用户的不同请求可能会发送到不同的Web服务器。 在这种情况下，MDB 可以作为全局存储解决方案来保存会话数据、用户令牌、权限信息等数据。 ","date":"2022-11-27","objectID":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/:4:2","tags":["cache"],"title":"Tair:分布式键/值存储系统","uri":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/"},{"categories":["后台开发"],"content":"数据存储 推荐和广告业务通常需要离线计算大量数据。 LDB 支持持久存储并提供卓越的性能。 支持在线服务，允许用户定期将离线数据导入LDB进行在线服务。 经过计算，列表业务可以将最终列表存储在LDB中，直接展示给前端应用程序。 这样，LDB 就满足了存储和高速访问的需求。 ","date":"2022-11-27","objectID":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/:4:3","tags":["cache"],"title":"Tair:分布式键/值存储系统","uri":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/"},{"categories":["后台开发"],"content":"黑名单/白名单 安全应用程序有许多黑名单/白名单方案。这些黑名单/白名单场景的特点是命中率低、访问量大、数据丢失导致业务损失。 LDB 支持数据持久化和高访问量，因此在这些场景中被广泛使用。 ","date":"2022-11-27","objectID":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/:4:4","tags":["cache"],"title":"Tair:分布式键/值存储系统","uri":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/"},{"categories":["后台开发"],"content":"分布式锁 分布式锁通常用于防止多线程并发导致的数据不一致和逻辑混乱。分布式锁可以使用 Tair 的版本特性或计算功能来实现。 得益于LBS的持久化，即使服务宕机，锁也不会丢失，可以正常释放。 ","date":"2022-11-27","objectID":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/:4:5","tags":["cache"],"title":"Tair:分布式键/值存储系统","uri":"/posts/tair-a-distributed-key-value-storage-system-developed-by-alibaba-group/"},{"categories":["后台开发"],"content":"程序员大部分时间都在承接一个个的需求，在做需求的过程中，有一些问题是我们容易忽视的，究其原因，主要是在做需求的过程中缺少思考，或者思考不够全面。而思考的缺失，正是导致部分人所说的“做业务需求没有成长”的主要原因之一。今天主要从研发流程中重要的几个阶段出发，跟大家谈谈做需求的过程中有哪些是我们容易忽视的问题。 ","date":"2022-11-20","objectID":"/posts/some-problems-that-programmers-tend-to-ignore-when-making-requirements/:0:0","tags":["advice"],"title":"程序员做需求时容易忽视的若干问题","uri":"/posts/some-problems-that-programmers-tend-to-ignore-when-making-requirements/"},{"categories":["后台开发"],"content":"需求分析 PM是我们的需求的最主要来源，在需求分析阶段，需要避免的问题是：一、没有理解清楚需求细节，而直接进入后续的方案设计和开发阶段；二、需求里说怎么干，我们就怎么干。 问题一容易造成的结果是，功能开发上线完成了，结果发现不是PM想要的，导致不必要的返工成本。另外，由于没有真正理清需求，也有可能导致项目的整体架构设计产生重大偏差，从而给后续的架构迭代留下隐患。 问题二容易造成的结果是，PM想做的功能点都做好了，却只是解决了一个本就不存在的问题，导致人力的浪费。特斯拉进行生产线自动化的时候，有一个零件的自动化安装总是出问题，特斯拉的工程师为了优化这个自动化流程，投入了大量的资金和精力。 后来马斯克问他们的技术人员，为什么需要这个零件，结果发现大家居然并不清楚。最后证明其实在电动车上，根本不需要这个零件。 为了避免以上两个问题，当我们接到PM需求时，应该详细地了解需求的功能细节，以及这个需求需要解决的问题是什么，最终是服务于什么目的，是否有助于达成业务的总体目标。以电商行业为例，我们应该思考所做的需求是否有助于提升商品的导购和流通效率，是否能帮卖家多挣钱，是否能帮买家更快找到想要的商品，是否能帮助平台提升竞争力。 ","date":"2022-11-20","objectID":"/posts/some-problems-that-programmers-tend-to-ignore-when-making-requirements/:1:0","tags":["advice"],"title":"程序员做需求时容易忽视的若干问题","uri":"/posts/some-problems-that-programmers-tend-to-ignore-when-making-requirements/"},{"categories":["后台开发"],"content":"方案设计 在方案设计阶段，需要避免的问题是：“这个需求很简单，不用走方案设计和评审环节了，我直接开发吧，很快就可以上线了”。有些需求可能只是简单的修改一两个接口，或者只是对现有的流程做部分调整，这往往容易让我们过于自信，认为直接开干也不会有问题。其实，在我们真正理清楚方案之前，它并不简单，而确保我们真正理清方案的方式，就是按照部门的方案设计模板，把技术方案写出来，对照CheckList，逐一完成各个检查项。 所谓磨刀不误砍柴工，在方案设计阶段多花一些时间，可以帮助我们建设出更加合理的系统架构，让我们在技术架构上不断积累资产，资产的不断增值会让我们在能力建设和研发效率等方面长期受益。相反，如果我们忽视了方案设计，则会不断地积累技术债，后续需要投入很多精力去还债。 ","date":"2022-11-20","objectID":"/posts/some-problems-that-programmers-tend-to-ignore-when-making-requirements/:2:0","tags":["advice"],"title":"程序员做需求时容易忽视的若干问题","uri":"/posts/some-problems-that-programmers-tend-to-ignore-when-making-requirements/"},{"categories":["后台开发"],"content":"代码开发 在代码开发方面，需要避免的问题是：“对工程质量要求低，认为能实现功能就行”。实际上，代码也是一种语言，它不仅用于人与机器之间的交流，而且也用于人与人之间的交流。逻辑复杂、晦涩难懂的代码可能会导致以下问题：一、隐藏bug，而且往往很不好改；二、后续有功能迭代时，逻辑修改非常复杂。 逻辑的正确性，是我们编码时的最低要求，编码时应该尽可能的追求信、达、雅。在编码方面主要给两点建议：一、遵守公司和部门的研发规范，包括分支规范、代码规范等；二、写代码时要多思考自己的写法是不是最优的，还有没有更好的写法。 ","date":"2022-11-20","objectID":"/posts/some-problems-that-programmers-tend-to-ignore-when-making-requirements/:3:0","tags":["advice"],"title":"程序员做需求时容易忽视的若干问题","uri":"/posts/some-problems-that-programmers-tend-to-ignore-when-making-requirements/"},{"categories":["后台开发"],"content":"服务上线 在服务上线阶段，需要避免的是观察不细致，想当然的认为没问题，结果到最后导致了一个大问题。在上线阶段，我们应该加强检查，从多角度对服务进行观察，包括：上游角度、服务本身角度、下游角度，观察的指标，既包括错误率、时延、错误日志等通用指标，也包括业务自定义指标（应该在方案设计阶段考虑清楚后续有什么手段可以观测服务是否正常）。 值得一提的是，服务上线完成并不是结束，而是一个新的开始。我们需要采取各种手段保障服务的稳定运行，并不断发现其中的可优化点，推动服务SLI稳步提升。 ","date":"2022-11-20","objectID":"/posts/some-problems-that-programmers-tend-to-ignore-when-making-requirements/:4:0","tags":["advice"],"title":"程序员做需求时容易忽视的若干问题","uri":"/posts/some-problems-that-programmers-tend-to-ignore-when-making-requirements/"},{"categories":["后台开发"],"content":"我是一位在大厂打拼多年的程序员，今天想结合自己的工作经历给新人程序员们提出若干建议，希望能够在一定程度上帮助大家在职场脱颖而出。 ","date":"2022-11-20","objectID":"/posts/career-advice-for-beginning-programmers/:0:0","tags":["advice"],"title":"给新人程序员的职场建议","uri":"/posts/career-advice-for-beginning-programmers/"},{"categories":["后台开发"],"content":"积极主动 第一个建议是要积极主动，有owner意识，勇于承担工作职责，并在工作中做出成绩。 首先，领取任务或接受任务应该积极主动。在工作中可以主动向领导提出来自己对什么方向的项目感兴趣，希望承担什么样的任务。当领导知道你是积极主动的人，而且也发现你确实有能力胜任某项工作时，就会优先想到你。在领导主动布置工作任务时，也不应该过多的考虑这项工作好不好干、难度怎么样，而是应该要积极主动的接受。 其次，在执行任务的过程中，应该发挥主观能动性，从而使成果达到预期或尽可能的超出预期。这就要求我们理清任务的本质，思考任务背后的更深层次的逻辑，从而确定目标、理清思路、拆解任务、贯彻执行。这里特别需要避免的是，简单地成为“任务执行器”，即机械的执行任务，而不知道做完这个任务之后能解决什么问题，后续又还需要做什么。 ","date":"2022-11-20","objectID":"/posts/career-advice-for-beginning-programmers/:1:0","tags":["advice"],"title":"给新人程序员的职场建议","uri":"/posts/career-advice-for-beginning-programmers/"},{"categories":["后台开发"],"content":"善于沟通 作为研发，工作中不免要和很多同事进行沟通，比如跟PM对接需求、跟其他前后端RD聊技术方案、跟QA聊测试用例等，因此高效的沟通可以在很大程度上提升我们的工作效率。在善于沟通方面，主要的建议是：一、不要与人争吵；二、换位思考。 争吵不能解决任何的问题，反而容易让人丧失理智，而且容易影响自己在旁观者心里的印象。换位思考是解决沟通问题的利器，先谈对方最关心的点，让对方感受到你的真诚。遇到分歧时，先找共同点，求同存异，往往事半功倍。 ","date":"2022-11-20","objectID":"/posts/career-advice-for-beginning-programmers/:2:0","tags":["advice"],"title":"给新人程序员的职场建议","uri":"/posts/career-advice-for-beginning-programmers/"},{"categories":["后台开发"],"content":"保持好奇心 软件研发方面的技术日新月异，不断有新的编程语言、存储组件、技术框架等出现，为了保持保持和增加自己的核心竞争力，对于工作中用到的相关组件和框架，应该不断去挖掘背后的底层原理。比如说工作中用到了HTTP协议，那么就应该思考：为什么会有HTTP？它的演进过程是怎样的？有什么设计理念是值得我们学习的？它还有什么缺陷是需要改进的吗？ 除了熟悉工作中用到的技术组件的原理之外，也应该多关注一些前沿的技术趋势，了解业界同行的一些优秀的实践经验，可能的方式包括关注InfoQ、美团技术博客等公众号发布的高质量文档。 这里特别需要避免的是，整天抱怨自己的工作只是CRUD，认为自己的工作没价值，但是却不愿去发掘自己的工作背后的有价值的东西。 ","date":"2022-11-20","objectID":"/posts/career-advice-for-beginning-programmers/:3:0","tags":["advice"],"title":"给新人程序员的职场建议","uri":"/posts/career-advice-for-beginning-programmers/"},{"categories":["后台开发"],"content":"引人注目 程序员是技术性很强的工作，技术是我们的立身之本，但我们也要避免只会研究技术、埋头苦干。对于交到我们手里的工作，我们要尽可能地做好，同时也需要积极地向领导汇报进展和成果，这样领导才会知道事情的进度是可控的、成果是可预期的，对于你个人的工作产出也自然心里有数了。 在引人注目方面，另外很重要的一点是：发表文章。如果只有你自己知道你是绝顶高手，是没有意义的，你需要通过发表文章的方式表述所学所思所想，让其他人知道你的实力，从而扩大你的影响力。 ","date":"2022-11-20","objectID":"/posts/career-advice-for-beginning-programmers/:4:0","tags":["advice"],"title":"给新人程序员的职场建议","uri":"/posts/career-advice-for-beginning-programmers/"},{"categories":["后台开发"],"content":"一提到元素查找，我们会很自然的想到HashMap。通过将哈希函数作用于key上，我们得到了哈希值，基于哈希值我们可以去表里的相应位置获取对应的数据。除了存在哈希冲突问题之外，HashMap一个很大的问题就是空间效率低。引入Bloom Filter则可以很好的解决空间效率的问题。 ","date":"2021-06-12","objectID":"/posts/introduction-to-the-basic-principles-of-bloom-filter/:0:0","tags":["bloom filter"],"title":"浅谈Bloom Filter基本原理及使用方式","uri":"/posts/introduction-to-the-basic-principles-of-bloom-filter/"},{"categories":["后台开发"],"content":"原理 Bloom Filter是一种空间效率很高的随机数据结构，Bloom filter 可以看做是对bit-map 的扩展，布隆过滤器被设计为一个具有N的元素的位数组A（bit array），初始时所有的位都置为0。 当一个元素被加入集合时，通过K个Hash函数将这个元素映射成一个位阵列（Bit array）中的K个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了。 如果这些点有任何一个 0，则被检索元素一定不在； 如果都是 1，则被检索元素很可能在。 ","date":"2021-06-12","objectID":"/posts/introduction-to-the-basic-principles-of-bloom-filter/:1:0","tags":["bloom filter"],"title":"浅谈Bloom Filter基本原理及使用方式","uri":"/posts/introduction-to-the-basic-principles-of-bloom-filter/"},{"categories":["后台开发"],"content":"添加元素 要添加一个元素，我们需要提供k个哈希函数。每个函数都能返回一个值，这个值必须能够作为位数组的索引（可以通过对数组长度进行取模得到）。然后，我们把位数组在这个索引处的值设为1。例如，第一个哈希函数作用于元素I上，返回x。类似的，第二个第三个哈希函数返回y与z，那么： A[x]=A[y]=A[z] = 1 ","date":"2021-06-12","objectID":"/posts/introduction-to-the-basic-principles-of-bloom-filter/:2:0","tags":["bloom filter"],"title":"浅谈Bloom Filter基本原理及使用方式","uri":"/posts/introduction-to-the-basic-principles-of-bloom-filter/"},{"categories":["后台开发"],"content":"查找元素 查找的过程与上面的过程类似，元素将会被会被不同的哈希函数处理三次，每个哈希函数都返回一个作为位数组索引值的整数，然后我们检测位数组在x、y与z处的值是否为1。如果有一处不为1，那么就说明这个元素没有被添加到这个布隆过滤器中。如果都为1，就说明这个元素在布隆过滤器里面。当然，会有一定误判的概率。 ","date":"2021-06-12","objectID":"/posts/introduction-to-the-basic-principles-of-bloom-filter/:3:0","tags":["bloom filter"],"title":"浅谈Bloom Filter基本原理及使用方式","uri":"/posts/introduction-to-the-basic-principles-of-bloom-filter/"},{"categories":["后台开发"],"content":"算法优化 通过上面的解释我们可以知道，如果想设计出一个好的布隆过滤器，我们必须遵循以下准则： 好的哈希函数能够尽可能的返回宽范围的哈希值。 位数组的大小（用m表示）非常重要：如果太小，那么所有的位很快就都会被赋值为1，这样就增加了误判的几率。 哈希函数的个数（用k表示）对索引值的均匀分配也很重要。 计算m的公式如下： m = - nlog p / (log2)^2 这里p为可接受的误判率。 计算k的公式如下： k = m/n log(2) 这里k=哈希函数个数，m=位数组个数，n=待检测元素的个数（后面会用到这几个字母）。 ","date":"2021-06-12","objectID":"/posts/introduction-to-the-basic-principles-of-bloom-filter/:4:0","tags":["bloom filter"],"title":"浅谈Bloom Filter基本原理及使用方式","uri":"/posts/introduction-to-the-basic-principles-of-bloom-filter/"},{"categories":["后台开发"],"content":"哈希算法 哈希算法是影响布隆过滤器性能的地方。我们需要选择一个效率高但不耗时的哈希函数，在论文《更少的哈希函数，相同的性能指标：构造一个更好的布隆过滤器》中，讨论了如何选用2个哈希函数来模拟k个哈希函数。首先，我们需要计算两个哈希函数h1(x)与h2(x)。然后，我们可以用这两个哈希函数来模仿产生k个哈希函数的效果： gi(x) = h1(x) + ih2(x) 这里i的取值范围是1到k的整数。 Google Guava类库使用这个技巧实现了一个布隆过滤器，哈希算法的主要逻辑如下： long hash64 = ...; int hash1 = (int) hash64; int hash2 = (int) (hash64 \u003e\u003e\u003e 32); for (int i = 1; i \u003c= numHashFunctions; i++) { int combinedHash = hash1 + (i * hash2); // Flip all the bits if it's negative (guaranteed positive number) if (combinedHash \u003c 0) { combinedHash = ~combinedHash; } } Guava中的Bloom Filter使用示例： int expectedInsertions = ...; //待检测元素的个数 double fpp = 0.03; //误判率(desired false positive probability) BloomFilter\u003cCharSequence\u003e bloomFilter = BloomFilter.create(Funnels.stringFunnel(Charset.forName(\"UTF-8\")), expectedInsertions,fpp); ","date":"2021-06-12","objectID":"/posts/introduction-to-the-basic-principles-of-bloom-filter/:5:0","tags":["bloom filter"],"title":"浅谈Bloom Filter基本原理及使用方式","uri":"/posts/introduction-to-the-basic-principles-of-bloom-filter/"},{"categories":["后台开发"],"content":"优点 它的优点是空间效率和查询时间都远远超过一般的算法，布隆过滤器存储空间和插入/查询时间都是常数O(k)。另外, 散列函数相互之间没有关系，方便由硬件并行实现。布隆过滤器不需要存储元素本身，在某些对保密要求非常严格的场合有优势。 ","date":"2021-06-12","objectID":"/posts/introduction-to-the-basic-principles-of-bloom-filter/:6:0","tags":["bloom filter"],"title":"浅谈Bloom Filter基本原理及使用方式","uri":"/posts/introduction-to-the-basic-principles-of-bloom-filter/"},{"categories":["后台开发"],"content":"缺点 布隆过滤器的缺点和优点一样明显，误算率是其中之一。 另外，一般情况下不能从布隆过滤器中删除元素。我们很容易想到把位数组变成整数数组，每插入一个元素相应的计数器加 1，这样删除元素时将计数器减掉就可以了。然而要保证安全地删除元素并非如此简单。首先我们必须保证删除的元素的确在布隆过滤器里面，而这一点单凭这个过滤器是无法保证的。 参考来源： https://www.javacodegeeks.com/2014/07/how-to-use-bloom-filter-to-build-a-large-in-memory-cache-in-java.html https://www.cnblogs.com/haippy/archive/2012/07/13/2590351.html https://segmentfault.com/a/1190000002729689 ","date":"2021-06-12","objectID":"/posts/introduction-to-the-basic-principles-of-bloom-filter/:7:0","tags":["bloom filter"],"title":"浅谈Bloom Filter基本原理及使用方式","uri":"/posts/introduction-to-the-basic-principles-of-bloom-filter/"},{"categories":["后台开发"],"content":"1 nc命令 执行如下命令，在目标机器(假设ip为10.11.12.13)上监听端口8415 nc -l 8415 \u003e data.txt 往目标机器发送数据 nc -v 10.11.12.13 8415 \u003c ~/Downloads/data.txt ","date":"2021-06-12","objectID":"/posts/three-ways-to-transfer-files-in-linux/:1:0","tags":["linux"],"title":"Linux文件传输的三种方式","uri":"/posts/three-ways-to-transfer-files-in-linux/"},{"categories":["后台开发"],"content":"2 SimpleHTTPServer 在服务器(假设ip为10.11.12.13)上执行如下命令: python -m SimpleHTTPServer 8411 然后在本地机器打开浏览器，输入http://10.11.12.13:8411/可以访问。 ","date":"2021-06-12","objectID":"/posts/three-ways-to-transfer-files-in-linux/:2:0","tags":["linux"],"title":"Linux文件传输的三种方式","uri":"/posts/three-ways-to-transfer-files-in-linux/"},{"categories":["后台开发"],"content":"3 scp命令 Linux scp命令用于Linux之间复制文件和目录。 scp是 secure copy的缩写, scp是linux系统下基于ssh登陆进行安全的远程文件拷贝命令。 在目标机器执行如下命令： scp -l 700000 username@dev.test.com:~/data.txt ./ 即可把目标机器dev.test.com的文件~/data.txt拷贝到当前目录。 ","date":"2021-06-12","objectID":"/posts/three-ways-to-transfer-files-in-linux/:3:0","tags":["linux"],"title":"Linux文件传输的三种方式","uri":"/posts/three-ways-to-transfer-files-in-linux/"},{"categories":["后台开发"],"content":"什么是WebSocket？ WebSocket是一种网络传输协议，可在单个TCP连接上进行全双工通信，位于OSI模型的应用层。WebSocket协议在2011年由IETF标准化为RFC 6455，后由RFC 7936补充规范。 WebSocket使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。在WebSocket API中，浏览器和服务器只需要完成一次握手，两者之间就可以创建持久性的连接，并进行双向数据传输。 ","date":"2021-06-12","objectID":"/posts/introduction-of-websocket/:1:0","tags":["websocket"],"title":"Websocket介绍","uri":"/posts/introduction-of-websocket/"},{"categories":["后台开发"],"content":"有哪些优点？ 较少的控制开销。在连接创建后，服务器和客户端之间交换数据时，用于协议控制的数据包头部相对较小。在不包含扩展的情况下，对于服务器到客户端的内容，此头部大小只有2至10字节（和数据包长度有关）；对于客户端到服务器的内容，此头部还需要加上额外的4字节的掩码。相对于HTTP请求每次都要携带完整的头部，此项开销显著减少了。 强的实时性。由于协议是全双工的，所以服务器可以随时主动给客户端下发数据。相对于HTTP请求需要等待客户端发起请求服务端才能响应，延迟明显更少；即使是和Comet等类似的长轮询比较，其也能在短时间内更多次地传递数据。 保持连接状态。与HTTP不同的是，Websocket需要先创建连接，这就使得其成为一种有状态的协议，之后通信时可以省略部分状态信息。而HTTP请求可能需要在每个请求都携带状态信息（如身份认证等）。 更好的二进制支持。Websocket定义了二进制帧，相对HTTP，可以更轻松地处理二进制内容。 可以支持扩展。Websocket定义了扩展，用户可以扩展协议、实现部分自定义的子协议。如部分浏览器支持压缩等。 ","date":"2021-06-12","objectID":"/posts/introduction-of-websocket/:1:1","tags":["websocket"],"title":"Websocket介绍","uri":"/posts/introduction-of-websocket/"},{"categories":["后台开发"],"content":"握手协议 WebSocket是一种与HTTP不同的协议。两者都位于OSI模型的应用层，并且都依赖于传输层的TCP协议。 虽然它们不同，但是RFC 6455中规定：it is designed to work over HTTP ports 80 and 443 as well as to support HTTP proxies and intermediaries（WebSocket通过HTTP端口80和443进行工作，并支持HTTP代理和中介），从而使其与HTTP协议兼容。 为了实现兼容性，WebSocket握手使用HTTP Upgrade头从HTTP协议更改为WebSocket协议。 ","date":"2021-06-12","objectID":"/posts/introduction-of-websocket/:2:0","tags":["websocket"],"title":"Websocket介绍","uri":"/posts/introduction-of-websocket/"},{"categories":["后台开发"],"content":"握手例子 一个典型的Websocket握手请求如下： 客户端请求： GET /chat HTTP/1.1 Host: server.example.com Upgrade: websocket Connection: Upgrade Sec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ== Origin: http://example.com Sec-WebSocket-Protocol: chat, superchat Sec-WebSocket-Version: 13 服务器回应： HTTP/1.1 101 Switching Protocols Upgrade: websocket Connection: Upgrade Sec-WebSocket-Accept: s3pPLMBiTxaQ9kYGzzhZRbK+xOo= Sec-WebSocket-Protocol: chat ","date":"2021-06-12","objectID":"/posts/introduction-of-websocket/:2:1","tags":["websocket"],"title":"Websocket介绍","uri":"/posts/introduction-of-websocket/"},{"categories":["后台开发"],"content":"字段说明 Connection必须设置Upgrade，表示客户端希望连接升级。 Upgrade字段必须设置Websocket，表示希望升级到Websocket协议。 Sec-WebSocket-Key是随机的字符串，服务器端会用这些数据来构造出一个SHA-1的信息摘要。把“Sec-WebSocket-Key”加上一个特殊字符串“258EAFA5-E914-47DA-95CA-C5AB0DC85B11”，然后计算SHA-1摘要，之后进行Base64编码，将结果做为“Sec-WebSocket-Accept”头的值，返回给客户端。如此操作，可以尽量避免普通HTTP请求被误认为Websocket协议。 Sec-WebSocket-Version 表示支持的Websocket版本。RFC6455要求使用的版本是13，之前草案的版本均应当弃用。 Origin字段是必须的。如果缺少origin字段，WebSocket服务器需要回复HTTP 403 状态码（禁止访问）。 ","date":"2021-06-12","objectID":"/posts/introduction-of-websocket/:2:2","tags":["websocket"],"title":"Websocket介绍","uri":"/posts/introduction-of-websocket/"},{"categories":["后台开发"],"content":"体验一下 https://www.websocket.org/echo.html 握手报文： 数据传输： ","date":"2021-06-12","objectID":"/posts/introduction-of-websocket/:2:3","tags":["websocket"],"title":"Websocket介绍","uri":"/posts/introduction-of-websocket/"},{"categories":["后台开发"],"content":"数据帧 WebSocket客户端、服务端通信的最小单位是帧（frame），由1个或多个帧组成一条完整的消息（message）。 发送端：将消息切割成多个帧，并发送给服务端； 接收端：接收消息帧，并将关联的帧重新组装成完整的消息； ","date":"2021-06-12","objectID":"/posts/introduction-of-websocket/:3:0","tags":["websocket"],"title":"Websocket介绍","uri":"/posts/introduction-of-websocket/"},{"categories":["后台开发"],"content":"帧结构 +-+-+-+-+-------+-+-------------+-------------------------------+ |F|R|R|R| opcode|M| Payload len | Extended payload length | |I|S|S|S| (4) |A| (7) | (16/64) | |N|V|V|V| |S| | (if payload len==126/127) | | |1|2|3| |K| | | +-+-+-+-+-------+-+-------------+ - - - - - - - - - - - - - - - + | Extended payload length continued, if payload len == 127 | + - - - - - - - - - - - - - - - +-------------------------------+ | |Masking-key, if MASK set to 1 | +-------------------------------+-------------------------------+ | Masking-key (continued) | Payload Data | +-------------------------------- - - - - - - - - - - - - - - - + : Payload Data continued ... : + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - + | Payload Data continued ... | +---------------------------------------------------------------+ ","date":"2021-06-12","objectID":"/posts/introduction-of-websocket/:3:1","tags":["websocket"],"title":"Websocket介绍","uri":"/posts/introduction-of-websocket/"},{"categories":["后台开发"],"content":"字段说明 FIN：1个比特。 如果是1，表示这是消息（message）的最后一个分片（fragment），如果是0，表示不是是消息（message）的最后一个分片（fragment）。 RSV1, RSV2, RSV3：各占1个比特。 一般情况下全为0。当客户端、服务端协商采用WebSocket扩展时，这三个标志位可以非0，且值的含义由扩展进行定义。如果出现非零的值，且并没有采用WebSocket扩展，连接出错。 Opcode: 4个比特。 操作代码，Opcode的值决定了应该如何解析后续的数据载荷（data payload）。如果操作代码是不认识的，那么接收端应该断开连接（fail the connection）。可选的操作代码如下： %x0：表示一个延续帧。当Opcode为0时，表示本次数据传输采用了数据分片，当前收到的数据帧为其中一个数据分片。 %x1：表示这是一个文本帧（frame） %x2：表示这是一个二进制帧（frame） %x3-7：保留的操作代码，用于后续定义的非控制帧。 %x8：表示连接断开。 %x9：表示这是一个ping操作。 %xA：表示这是一个pong操作。 %xB-F：保留的操作代码，用于后续定义的控制帧。 Mask: 1个比特。 表示是否要对数据载荷进行掩码操作。从客户端向服务端发送数据时，需要对数据进行掩码操作；从服务端向客户端发送数据时，不需要对数据进行掩码操作。 如果服务端接收到的数据没有进行过掩码操作，服务端需要断开连接。 如果Mask是1，那么在Masking-key中会定义一个掩码键（masking key），并用这个掩码键来对数据载荷进行反掩码。所有客户端发送到服务端的数据帧，Mask都是1。 掩码的算法、用途在下一小节讲解。 Payload length：数据载荷的长度，单位是字节。为7位，或7+16位，或1+64位。 假设数Payload length === x，如果 x为0~126：数据的长度为x字节。 x为126：后续2个字节代表一个16位的无符号整数，该无符号整数的值为数据的长度。 x为127：后续8个字节代表一个64位的无符号整数（最高位为0），该无符号整数的值为数据的长度。 此外，如果payload length占用了多个字节的话，payload length的二进制表达采用网络序（big endian，重要的位在前）。 Masking-key：0或4字节（32位） 所有从客户端传送到服务端的数据帧，数据载荷都进行了掩码操作，Mask为1，且携带了4字节的Masking-key。如果Mask为0，则没有Masking-key。 备注：载荷数据的长度，不包括mask key的长度。 Payload data：(x+y) 字节 载荷数据：包括了扩展数据、应用数据。其中，扩展数据x字节，应用数据y字节。 扩展数据：如果没有协商使用扩展的话，扩展数据数据为0字节。所有的扩展都必须声明扩展数据的长度，或者可以如何计算出扩展数据的长度。此外，扩展如何使用必须在握手阶段就协商好。如果扩展数据存在，那么载荷数据长度必须将扩展数据的长度包含在内。 应用数据：任意的应用数据，在扩展数据之后（如果存在扩展数据），占据了数据帧剩余的位置。载荷数据长度 减去 扩展数据长度，就得到应用数据的长度。 ","date":"2021-06-12","objectID":"/posts/introduction-of-websocket/:3:2","tags":["websocket"],"title":"Websocket介绍","uri":"/posts/introduction-of-websocket/"},{"categories":["后台开发"],"content":"掩码算法 掩码键（Masking-key）是由客户端挑选出来的32位的随机数。掩码操作不会影响数据载荷的长度。掩码、反掩码操作都采用如下算法： 首先，预设： original-octet-i：为原始数据的第i字节。 transformed-octet-i：为转换后的数据的第i字节。 j：为i mod 4的结果。 masking-key-octet-j：为mask key第j字节。 流程为： original-octet-i 与 masking-key-octet-j 异或后，得到 transformed-octet-i。 伪代码大概是： var DECODED = \"\"; for (var i = 0; i \u003c ENCODED.length; i++) { DECODED[i] = ENCODED[i] ^ MASK[i % 4]; } 数据掩码的作用： WebSocket 协议中，数据掩码的作用是增强协议的安全性。但数据掩码并不是为了保护数据本身，因为算法本身是公开的，运算也不复杂。除了加密通道本身，似乎没有太多有效的保护通信安全的办法。 那么为什么还要引入掩码计算呢，除了增加计算机器的运算量外似乎并没有太多的收益（这也是不少同学疑惑的点）。 答案还是两个字：安全。但并不是为了防止数据泄密，而是为了防止早期版本的协议中存在的代理缓存污染攻击（proxy cache poisoning attacks）等问题。 ","date":"2021-06-12","objectID":"/posts/introduction-of-websocket/:3:3","tags":["websocket"],"title":"Websocket介绍","uri":"/posts/introduction-of-websocket/"},{"categories":["后台开发"],"content":"数据传递 一旦WebSocket客户端、服务端建立连接后，后续的操作都是基于数据帧的传递。 WebSocket根据opcode来区分操作的类型。比如0x8表示断开连接，0x0-0x2表示数据交互。 ","date":"2021-06-12","objectID":"/posts/introduction-of-websocket/:4:0","tags":["websocket"],"title":"Websocket介绍","uri":"/posts/introduction-of-websocket/"},{"categories":["后台开发"],"content":"数据分片 WebSocket的每条消息可能被切分成多个数据帧。当WebSocket的接收方收到一个数据帧时，会根据FIN的值来判断，是否已经收到消息的最后一个数据帧。 FIN=1表示当前数据帧为消息的最后一个数据帧，此时接收方已经收到完整的消息，可以对消息进行处理。FIN=0，则接收方还需要继续监听接收其余的数据帧。 此外，opcode在数据交换的场景下，表示的是数据的类型。0x01表示文本，0x02表示二进制。而0x00比较特殊，表示延续帧（continuation frame），顾名思义，就是完整消息对应的数据帧还没接收完。 ","date":"2021-06-12","objectID":"/posts/introduction-of-websocket/:4:1","tags":["websocket"],"title":"Websocket介绍","uri":"/posts/introduction-of-websocket/"},{"categories":["后台开发"],"content":"数据分片例子 下面例子来自MDN，可以很好地演示数据的分片。客户端向服务端两次发送消息，服务端收到消息后回应客户端，这里主要看客户端往服务端发送的消息。 第一条消息 FIN=1, 表示是当前消息的最后一个数据帧。服务端收到当前数据帧后，可以处理消息。opcode=0x1，表示客户端发送的是文本类型。 第二条消息 FIN=0，opcode=0x1，表示发送的是文本类型，且消息还没发送完成，还有后续的数据帧。 FIN=0，opcode=0x0，表示消息还没发送完成，还有后续的数据帧，当前的数据帧需要接在上一条数据帧之后。 FIN=1，opcode=0x0，表示消息已经发送完成，没有后续的数据帧，当前的数据帧需要接在上一条数据帧之后。服务端可以将关联的数据帧组装成完整的消息。 Client: FIN=1, opcode=0x1, msg=\"hello\" Server: (process complete message immediately) Hi. Client: FIN=0, opcode=0x1, msg=\"and a\" Server: (listening, new message containing text started) Client: FIN=0, opcode=0x0, msg=\"happy new\" Server: (listening, payload concatenated to previous message) Client: FIN=1, opcode=0x0, msg=\"year!\" Server: (process complete message) Happy new year to you too! ","date":"2021-06-12","objectID":"/posts/introduction-of-websocket/:4:2","tags":["websocket"],"title":"Websocket介绍","uri":"/posts/introduction-of-websocket/"},{"categories":["后台开发"],"content":"心跳 WebSocket 为了保持客户端、服务端的实时双向通信，需要确保客户端、服务端之间的 TCP 通道保持连接没有断开。 对于长时间没有数据往来的连接，如果依旧长时间保持着，可能会浪费包括的连接资源。但不排除有些场景，客户端、服务端虽然长时间没有数据往来，但仍需要保持连接。这个时候，可以采用心跳来实现。 发送方 -\u003e 接收方：ping 接收方 -\u003e 发送方：pong ping、pong 的操作，对应的是 WebSocket 的两个控制帧，opcode分别是0x9、0xA。 ","date":"2021-06-12","objectID":"/posts/introduction-of-websocket/:5:0","tags":["websocket"],"title":"Websocket介绍","uri":"/posts/introduction-of-websocket/"},{"categories":["后台开发"],"content":"安全性 WebSocket协议中规定在连接建立时检查Upgrade请求中的某些字段（如Origin，查看每次请求是否一致），对于不符合要求的请求立即断开，在通信过程中，也对Frame中的控制位做了很多限制，以便禁止异常连接。 websocket协议中也规定了数据加密传输的方式，允许使用TLS/SSL来对通信加密，默认ws的端口为80，wss端口为433，类似HTTP与HTTPS。 ","date":"2021-06-12","objectID":"/posts/introduction-of-websocket/:6:0","tags":["websocket"],"title":"Websocket介绍","uri":"/posts/introduction-of-websocket/"},{"categories":["后台开发"],"content":"Go实战：Gorilla WebSocket Github：https://github.com/gorilla/websocket 文件监控例子（当文件被修改后，把文件发给客户端）： func main() { http.HandleFunc(\"/ws\", serveWs) if err := http.ListenAndServe(*addr, nil); err != nil { log.Fatal(err) } } func serveWs(w http.ResponseWriter, r *http.Request) { //升级为Websocket协议 ws, err := upgrader.Upgrade(w, r, nil) if err != nil { if _, ok := err.(websocket.HandshakeError); !ok { log.Println(err) } return } var lastMod time.Time if n, err := strconv.ParseInt(r.FormValue(\"lastMod\"), 16, 64); err == nil { lastMod = time.Unix(0, n) } go writer(ws, lastMod) //发送数据、Pong reader(ws) //读数据、处理Ping } func writer(ws *websocket.Conn, lastMod time.Time) { pingTicker := time.NewTicker(pingPeriod) fileTicker := time.NewTicker(filePeriod) ... for { select { case \u003c-fileTicker.C: p, fileModified, err := readFileIfModified(lastMod) ... if fileModified { ws.SetWriteDeadline(time.Now().Add(writeWait)) if err := ws.WriteMessage(websocket.TextMessage, p); err != nil { return } } case \u003c-pingTicker.C: ws.SetWriteDeadline(time.Now().Add(writeWait)) if err := ws.WriteMessage(websocket.PingMessage, []byte{}); err != nil { return } } } } func reader(ws *websocket.Conn) { defer ws.Close() ws.SetReadLimit(512) ws.SetReadDeadline(time.Now().Add(pongWait)) ws.SetPongHandler(func(string) error { ws.SetReadDeadline(time.Now().Add(pongWait)); return nil }) for { _, _, err := ws.ReadMessage() if err != nil { break } } } 其中最重要的几个方法是Upgrade、ReadMessage和WriteMessage，下面逐一介绍。 ","date":"2021-06-12","objectID":"/posts/introduction-of-websocket/:7:0","tags":["websocket"],"title":"Websocket介绍","uri":"/posts/introduction-of-websocket/"},{"categories":["后台开发"],"content":"Upgrade 协议升级 // Upgrade upgrades the HTTP server connection to the WebSocket protocol. func (u *Upgrader) Upgrade(w http.ResponseWriter, r *http.Request, responseHeader http.Header) (*Conn, error) { const badHandshake = \"websocket: the client is not using the websocket protocol: \" //检查必要的头部字段 if !tokenListContainsValue(r.Header, \"Connection\", \"upgrade\") { return u.returnError(w, r, http.StatusBadRequest, badHandshake+\"'upgrade' token not found in 'Connection' header\") } if !tokenListContainsValue(r.Header, \"Upgrade\", \"websocket\") { return u.returnError(w, r, http.StatusBadRequest, badHandshake+\"'websocket' token not found in 'Upgrade' header\") } if r.Method != \"GET\" { return u.returnError(w, r, http.StatusMethodNotAllowed, badHandshake+\"request method is not GET\") } if !tokenListContainsValue(r.Header, \"Sec-Websocket-Version\", \"13\") { return u.returnError(w, r, http.StatusBadRequest, \"websocket: unsupported version: 13 not found in 'Sec-Websocket-Version' header\") } if !checkOrigin(r) { return u.returnError(w, r, http.StatusForbidden, \"websocket: request origin not allowed by Upgrader.CheckOrigin\") } challengeKey := r.Header.Get(\"Sec-Websocket-Key\") if challengeKey == \"\" { return u.returnError(w, r, http.StatusBadRequest, \"websocket: not a websocket handshake: 'Sec-WebSocket-Key' header is missing or blank\") } h, ok := w.(http.Hijacker) if !ok { return u.returnError(w, r, http.StatusInternalServerError, \"websocket: response does not implement http.Hijacker\") } //创建websocket.Conn c := newConn(netConn, true, u.ReadBufferSize, u.WriteBufferSize, u.WriteBufferPool, br, writeBuf) var p []byte p = append(p, \"HTTP/1.1 101 Switching Protocols\\r\\nUpgrade: websocket\\r\\nConnection: Upgrade\\r\\nSec-WebSocket-Accept: \"...) p = append(p, computeAcceptKey(challengeKey)...) //计算accept p = append(p, \"\\r\\n\"...) if c.subprotocol != \"\" { p = append(p, \"Sec-WebSocket-Protocol: \"...) p = append(p, c.subprotocol...) p = append(p, \"\\r\\n\"...) } if _, err = netConn.Write(p); err != nil { netConn.Close() return nil, err } return c, nil } var keyGUID = []byte(\"258EAFA5-E914-47DA-95CA-C5AB0DC85B11\") func computeAcceptKey(challengeKey string) string { h := sha1.New() h.Write([]byte(challengeKey)) h.Write(keyGUID) return base64.StdEncoding.EncodeToString(h.Sum(nil)) } func newConn(conn net.Conn, isServer bool, readBufferSize, writeBufferSize int, writeBufferPool BufferPool, br *bufio.Reader, writeBuf []byte) *Conn { c := \u0026Conn{ isServer: isServer, br: br, conn: conn, mu: mu, readFinal: true, writeBuf: writeBuf, writePool: writeBufferPool, writeBufSize: writeBufferSize, enableWriteCompression: true, compressionLevel: defaultCompressionLevel, } //设置对应的消息处理Handler c.SetCloseHandler(nil) c.SetPingHandler(nil) c.SetPongHandler(nil) return c } func (c *Conn) SetCloseHandler(h func(code int, text string) error) { if h == nil { h = func(code int, text string) error { message := FormatCloseMessage(code, \"\") c.WriteControl(CloseMessage, message, time.Now().Add(writeWait)) return nil } } c.handleClose = h } func (c *Conn) SetPingHandler(h func(appData string) error) { if h == nil { h = func(message string) error { err := c.WriteControl(PongMessage, []byte(message), time.Now().Add(writeWait)) return err } } c.handlePing = h } func (c *Conn) SetPongHandler(h func(appData string) error) { if h == nil { h = func(string) error { return nil } } c.handlePong = h } ","date":"2021-06-12","objectID":"/posts/introduction-of-websocket/:7:1","tags":["websocket"],"title":"Websocket介绍","uri":"/posts/introduction-of-websocket/"},{"categories":["后台开发"],"content":"ReadMessage func (c *Conn) ReadMessage() (messageType int, p []byte, err error) { var r io.Reader messageType, r, err = c.NextReader() if err != nil { return messageType, nil, err } p, err = ioutil.ReadAll(r) return messageType, p, err } func (c *Conn) NextReader() (messageType int, r io.Reader, err error) { for c.readErr == nil { frameType, err := c.advanceFrame() if err != nil { c.readErr = hideTempErr(err) break } if frameType == TextMessage || frameType == BinaryMessage { c.messageReader = \u0026messageReader{c} c.reader = c.messageReader if c.readDecompress { c.reader = c.newDecompressionReader(c.reader) } return frameType, c.reader, nil } } } //解析数据帧 func (c *Conn) advanceFrame() (int, error) { p, err := c.read(2) final := p[0]\u0026finalBit != 0 frameType := int(p[0] \u0026 0xf) mask := p[1]\u0026maskBit != 0 c.setReadRemaining(int64(p[1] \u0026 0x7f)) switch frameType { case CloseMessage, PingMessage, PongMessage: if c.readRemaining \u003e maxControlFramePayloadSize { return noFrame, c.handleProtocolError(\"control frame length \u003e 125\") } if !final { return noFrame, c.handleProtocolError(\"control frame not final\") } case TextMessage, BinaryMessage: if !c.readFinal { return noFrame, c.handleProtocolError(\"message start before final message frame\") } c.readFinal = final case continuationFrame: if c.readFinal { return noFrame, c.handleProtocolError(\"continuation after final message frame\") } c.readFinal = final default: return noFrame, c.handleProtocolError(\"unknown opcode \" + strconv.Itoa(frameType)) } switch c.readRemaining { case 126: p, err := c.read(2) if err := c.setReadRemaining(int64(binary.BigEndian.Uint16(p))); err != nil { return noFrame, err } case 127: p, err := c.read(8) if err != nil { return noFrame, err } if err := c.setReadRemaining(int64(binary.BigEndian.Uint64(p))); err != nil { return noFrame, err } } if mask != c.isServer { return noFrame, c.handleProtocolError(\"incorrect mask flag\") } if mask { c.readMaskPos = 0 p, err := c.read(len(c.readMaskKey)) if err != nil { return noFrame, err } copy(c.readMaskKey[:], p) } //处理控制帧 switch frameType { case PongMessage: if err := c.handlePong(string(payload)); err != nil { return noFrame, err } case PingMessage: if err := c.handlePing(string(payload)); err != nil { return noFrame, err } case CloseMessage: closeCode := CloseNoStatusReceived closeText := \"\" if len(payload) \u003e= 2 { closeCode = int(binary.BigEndian.Uint16(payload)) if !isValidReceivedCloseCode(closeCode) { return noFrame, c.handleProtocolError(\"invalid close code\") } closeText = string(payload[2:]) if !utf8.ValidString(closeText) { return noFrame, c.handleProtocolError(\"invalid utf8 payload in close frame\") } } if err := c.handleClose(closeCode, closeText); err != nil { return noFrame, err } return noFrame, \u0026CloseError{Code: closeCode, Text: closeText} } return frameType, nil } ","date":"2021-06-12","objectID":"/posts/introduction-of-websocket/:7:2","tags":["websocket"],"title":"Websocket介绍","uri":"/posts/introduction-of-websocket/"},{"categories":["后台开发"],"content":"WriteMessage func (c *Conn) WriteMessage(messageType int, data []byte) error { var mw messageWriter // beginMessage prepares a connection and message writer for a new message. if err := c.beginMessage(\u0026mw, messageType); err != nil { return err } n := copy(c.writeBuf[mw.pos:], data) mw.pos += n data = data[n:] return mw.flushFrame(true, data) } //组装数据帧 func (w *messageWriter) flushFrame(final bool, extra []byte) error { c := w.c length := w.pos - maxFrameHeaderSize + len(extra) b0 := byte(w.frameType) if final { b0 |= finalBit } if w.compress { b0 |= rsv1Bit } w.compress = false b1 := byte(0) if !c.isServer { b1 |= maskBit } // Assume that the frame starts at beginning of c.writeBuf. framePos := 0 if c.isServer { // Adjust up if mask not included in the header. framePos = 4 } switch { case length \u003e= 65536: c.writeBuf[framePos] = b0 c.writeBuf[framePos+1] = b1 | 127 binary.BigEndian.PutUint64(c.writeBuf[framePos+2:], uint64(length)) case length \u003e 125: framePos += 6 c.writeBuf[framePos] = b0 c.writeBuf[framePos+1] = b1 | 126 binary.BigEndian.PutUint16(c.writeBuf[framePos+2:], uint16(length)) default: framePos += 8 c.writeBuf[framePos] = b0 c.writeBuf[framePos+1] = b1 | byte(length) } if !c.isServer { key := newMaskKey() copy(c.writeBuf[maxFrameHeaderSize-4:], key[:]) maskBytes(key, 0, c.writeBuf[maxFrameHeaderSize:w.pos]) if len(extra) \u003e 0 { return w.endMessage(c.writeFatal(errors.New(\"websocket: internal error, extra used in client mode\"))) } } // Write the buffers to the connection with best-effort detection of // concurrent writes. See the concurrency section in the package // documentation for more info. if c.isWriting { panic(\"concurrent write to websocket connection\") } c.isWriting = true err := c.write(w.frameType, c.writeDeadline, c.writeBuf[framePos:w.pos], extra) ... return nil } Ref： https://datatracker.ietf.org/doc/html/rfc6455# https://zh.wikipedia.org/wiki/WebSocket http://www.ruanyifeng.com/blog/2017/05/websocket.html https://pkg.go.dev/github.com/gorilla/websocket ","date":"2021-06-12","objectID":"/posts/introduction-of-websocket/:7:3","tags":["websocket"],"title":"Websocket介绍","uri":"/posts/introduction-of-websocket/"},{"categories":null,"content":"Consul是什么？ Consul是一个服务发现和配置工具，它是分布式和高可用的，而且极易扩展。 Consul主要提供了以下特性： 服务发现：Consul使得服务注册和服务发现（通过DNS或HTTP接口）变得非常简单。 健康检查：健康检查使得Consul可以快速向管理员报告集群状况。将它与服务发现集成，可以防止流量路由到故障节点，实现服务熔断。 KV存储：灵活的KV存储，可用于尺寸出动态配置、功能特性、协调信息和选举信息等。简单的HTTP API使其易于在任何地方地方。 多数据中心：Consul支持多数据中心，不需要负责的配置就可以支持任意数量的数据中心。 服务鉴权（Service Segmentation）：Consul连接基于自动TLS加密和基于签名的鉴权实现安全的服务间通信。 Consul支持Linux, Mac OS X, FreeBSD, Solaris, Windows等操作系统。 ","date":"2020-01-30","objectID":"/posts/manual-of-consul/:1:0","tags":["console"],"title":"Consul入门手册","uri":"/posts/manual-of-consul/"},{"categories":null,"content":"基本架构 每个提供服务给Consul的节点都运行了一个Consul Agent。运行一个Agent并不需要对其他服务做发现或读写KV存储。Agent负责对该节点上的服务做健康检查。 Agent会与一个或多个Consul Server通信。Consul Server通常有多个实例，负责数据存储和备份、选举主节点等。虽然Consul支持在只有一个Server实例的情况下工具，但通常推荐使用3至5个实例，从而避免由于某些异常场景而导致数据丢失。同时，推荐在每个数据中心部署一个Consul集群。 每个数据中运行了一个Consul server集群。当一个跨数据中心的服务发现和配置请求创建时，本地Consul Server转发请求到远程的数据中心并返回结果. ","date":"2020-01-30","objectID":"/posts/manual-of-consul/:1:1","tags":["console"],"title":"Consul入门手册","uri":"/posts/manual-of-consul/"},{"categories":null,"content":"安装Consul Consul集群的每个节点都必须先安装Consul，安装非常简单。在Mac上安装Consul命令如下： $ brew install consul 安装成功后执行consul命令输出如下结果： $ consul Usage: consul [--version] [--help] \u003ccommand\u003e [\u003cargs\u003e] Available commands are: acl Interact with Consul's ACLs agent Runs a Consul agent catalog Interact with the catalog config Interact with Consul's Centralized Configurations connect Interact with Consul Connect debug Records a debugging archive for operators event Fire a new event exec Executes a command on Consul nodes force-leave Forces a member of the cluster to enter the \"left\" state info Provides debugging information for operators. intention Interact with Connect service intentions join Tell Consul agent to join cluster keygen Generates a new encryption key keyring Manages gossip layer encryption keys kv Interact with the key-value store leave Gracefully leaves the Consul cluster and shuts down lock Execute a command holding a lock login Login to Consul using an auth method logout Destroy a Consul token created with login maint Controls node or service maintenance mode members Lists the members of a Consul cluster monitor Stream logs from a Consul agent operator Provides cluster-level tools for Consul operators reload Triggers the agent to reload configuration files rtt Estimates network round trip time between nodes services Interact with services snapshot Saves, restores and inspects snapshots of Consul server state tls Builtin helpers for creating CAs and certificates validate Validate config files/directories version Prints the Consul version watch Watch for changes in Consul ","date":"2020-01-30","objectID":"/posts/manual-of-consul/:2:0","tags":["console"],"title":"Consul入门手册","uri":"/posts/manual-of-consul/"},{"categories":null,"content":"运行Agent 完成Consul的安装后，可运行Agent。Agent可以运行为Server或Client模式。每个数据中心至少必须拥有一台server，建议在一个集群中部署或者3至5个Server。部署单一的Server，在出现失败时会不可避免的造成数据丢失. 其他的Agent运行为Client模式，一个Client是一个非常轻量级的进程，用于注册服务，运行健康检查和转发对Server的查询，Agent必须在集群中的每个主机上运行。 ","date":"2020-01-30","objectID":"/posts/manual-of-consul/:3:0","tags":["console"],"title":"Consul入门手册","uri":"/posts/manual-of-consul/"},{"categories":null,"content":"启动Agent 命令consul agent -dev可以启动一个开发模式的Agent，这种模式不能用于生产环境，因为它不持久化任何状态。 $ consul agent -dev ==\u003e Starting Consul agent... Version: 'v1.6.1' Node ID: '2e524113-7caf-643a-80bb-a2fa00c2673b' Node name: 'C02Z35N9LVCF' Datacenter: 'dc1' (Segment: '\u003call\u003e') Server: true (Bootstrap: false) Client Addr: [127.0.0.1] (HTTP: 8500, HTTPS: -1, gRPC: 8502, DNS: 8600) Cluster Addr: 127.0.0.1 (LAN: 8301, WAN: 8302) Encrypt: Gossip: false, TLS-Outgoing: false, TLS-Incoming: false, Auto-Encrypt-TLS: false ==\u003e Log data will now stream in as it occurs: 2019/11/20 21:56:09 [DEBUG] agent: Using random ID \"2e524113-7caf-643a-80bb-a2fa00c2673b\" as node ID 2019/11/20 21:56:09 [DEBUG] tlsutil: Update with version 1 2019/11/20 21:56:09 [DEBUG] tlsutil: OutgoingRPCWrapper with version 1 2019/11/20 21:56:09 [INFO] raft: Initial configuration (index=1): [{Suffrage:Voter ID:2e524113-7caf-643a-80bb-a2fa00c2673b Address:127.0.0.1:8300}] 2019/11/20 21:56:09 [INFO] raft: Node at 127.0.0.1:8300 [Follower] entering Follower state (Leader: \"\") 2019/11/20 21:56:09 [INFO] serf: EventMemberJoin: C02Z35N9LVCF.dc1 127.0.0.1 2019/11/20 21:56:09 [INFO] serf: EventMemberJoin: C02Z35N9LVCF 127.0.0.1 2019/11/20 21:56:09 [INFO] consul: Adding LAN server C02Z35N9LVCF (Addr: tcp/127.0.0.1:8300) (DC: dc1) 2019/11/20 21:56:09 [INFO] consul: Handled member-join event for server \"C02Z35N9LVCF.dc1\" in area \"wan\" 2019/11/20 21:56:09 [INFO] agent: Started DNS server 127.0.0.1:8600 (tcp) 2019/11/20 21:56:09 [INFO] agent: Started DNS server 127.0.0.1:8600 (udp) 2019/11/20 21:56:09 [INFO] agent: Started HTTP server on 127.0.0.1:8500 (tcp) 2019/11/20 21:56:09 [INFO] agent: Started gRPC server on 127.0.0.1:8502 (tcp) 2019/11/20 21:56:09 [INFO] agent: started state syncer ==\u003e Consul agent running! 2019/11/20 21:56:09 [WARN] raft: Heartbeat timeout from \"\" reached, starting election 2019/11/20 21:56:09 [INFO] raft: Node at 127.0.0.1:8300 [Candidate] entering Candidate state in term 2 2019/11/20 21:56:09 [DEBUG] raft: Votes needed: 1 2019/11/20 21:56:09 [DEBUG] raft: Vote granted from 2e524113-7caf-643a-80bb-a2fa00c2673b in term 2. Tally: 1 2019/11/20 21:56:09 [INFO] raft: Election won. Tally: 1 2019/11/20 21:56:09 [INFO] raft: Node at 127.0.0.1:8300 [Leader] entering Leader state 2019/11/20 21:56:09 [INFO] consul: cluster leadership acquired 2019/11/20 21:56:09 [INFO] consul: New leader elected: C02Z35N9LVCF 2019/11/20 21:56:09 [INFO] connect: initialized primary datacenter CA with provider \"consul\" 2019/11/20 21:56:09 [DEBUG] consul: Skipping self join check for \"C02Z35N9LVCF\" since the cluster is too small 2019/11/20 21:56:09 [INFO] consul: member 'C02Z35N9LVCF' joined, marking health alive 2019/11/20 21:56:09 [DEBUG] agent: Skipping remote check \"serfHealth\" since it is managed automatically 2019/11/20 21:56:09 [INFO] agent: Synced node info 2019/11/20 21:56:09 [DEBUG] agent: Node info in sync 2019/11/20 21:56:09 [DEBUG] agent: Skipping remote check \"serfHealth\" since it is managed automatically 2019/11/20 21:56:09 [DEBUG] agent: Node info in sync 2019/11/20 21:56:11 [DEBUG] tlsutil: OutgoingRPCWrapper with version 1 ","date":"2020-01-30","objectID":"/posts/manual-of-consul/:3:1","tags":["console"],"title":"Consul入门手册","uri":"/posts/manual-of-consul/"},{"categories":null,"content":"集群成员 新开一个终端窗口运行consul members, 就可以看到Consul集群的成员。 $ consul members Node Address Status Type Build Protocol DC Segment C02Z35N9LVCF 127.0.0.1:8301 alive server 1.6.1 2 dc1 \u003call\u003e 以上输出显示了我们自己的节点运行的节点、地址、健康状态、自己在集群中的角色、版本信息等。添加-detailed选项可以查看到额外的信息，如下： $ consul members --detailed Node Address Status Tags C02Z35N9LVCF 127.0.0.1:8301 alive acls=0,build=1.6.1:9be6dfc+,dc=dc1,id=2e524113-7caf-643a-80bb-a2fa00c2673b,port=8300,raft_vsn=3,role=consul,segment=\u003call\u003e,vsn=2,vsn_max=3,vsn_min=2,wan_join_port=8302 members命令的输出是基于gossip协议，它是最终一致的。这意味着，在任何时候，通过你本地Agent看到的结果可能不能准确匹配server的状态。为了查看到一致的信息，可使用HTTP API(将自动转发)到Consul Server上去进行查询： $ curl localhost:8500/v1/catalog/nodes [ { \"ID\": \"2e524113-7caf-643a-80bb-a2fa00c2673b\", \"Node\": \"C02Z35N9LVCF\", \"Address\": \"127.0.0.1\", \"Datacenter\": \"dc1\", \"TaggedAddresses\": { \"lan\": \"127.0.0.1\", \"wan\": \"127.0.0.1\" }, \"Meta\": { \"consul-network-segment\": \"\" }, \"CreateIndex\": 9, \"ModifyIndex\": 10 } ] ","date":"2020-01-30","objectID":"/posts/manual-of-consul/:3:2","tags":["console"],"title":"Consul入门手册","uri":"/posts/manual-of-consul/"},{"categories":null,"content":"停止Agent 你可以使用 Ctrl-C 优雅的关闭Agent，中断Agent之后你可以看到它离开了集群并关闭. 退出后，Consul提醒其他集群成员，这个节点离开了。如果你强行杀掉进程，集群的其他成员应该能检测到这个节点失效了。当一个成员离开，他的服务和检测也会从目录中移除。当一个成员失效了，他的健康状况被简单的标记为危险，但是不会从目录中移除。Consul会自动尝试对失效的节点进行重连，允许他从某些网络条件下恢复过来。 ","date":"2020-01-30","objectID":"/posts/manual-of-consul/:3:3","tags":["console"],"title":"Consul入门手册","uri":"/posts/manual-of-consul/"},{"categories":null,"content":"注册服务 在之前的步骤我们运行了第一个agent，看到了集群的成员。现在我们将注册第一个服务并查询这些服务。 ","date":"2020-01-30","objectID":"/posts/manual-of-consul/:4:0","tags":["console"],"title":"Consul入门手册","uri":"/posts/manual-of-consul/"},{"categories":null,"content":"定义一个服务 可以通过提供服务定义或者调用HTTP API来注册一个服务，服务定义文件是注册服务的最通用的方式。 首先，为Consul配置创建一个目录： $ sudo mkdir /etc/consul.d 然后，编写服务定义配置文件。假设我们有一个名叫web的服务运行在 80端口。另外，我们将给他设置一个标签，这样我们可以使用它作为额外的查询方式： echo '{\"service\": {\"name\": \"web\", \"tags\": [\"rails\"], \"port\": 80}}' \u003e /etc/consul.d/web.json 重新启动Agent，设置配置目录： $ sudo consul agent -dev -config-dir /etc/consul.d/web.json ==\u003e Starting Consul agent... Version: 'v1.6.1' Node ID: 'feba8d74-4a3a-9b42-305f-eea7da207c9c' Node name: 'C02Z35N9LVCF' Datacenter: 'dc1' (Segment: '\u003call\u003e') Server: true (Bootstrap: false) Client Addr: [127.0.0.1] (HTTP: 8500, HTTPS: -1, gRPC: 8502, DNS: 8600) Cluster Addr: 127.0.0.1 (LAN: 8301, WAN: 8302) Encrypt: Gossip: false, TLS-Outgoing: false, TLS-Incoming: false, Auto-Encrypt-TLS: false ==\u003e Log data will now stream in as it occurs: 2019/11/20 22:17:29 [DEBUG] agent: Using random ID \"feba8d74-4a3a-9b42-305f-eea7da207c9c\" as node ID 2019/11/20 22:17:29 [DEBUG] tlsutil: Update with version 1 2019/11/20 22:17:29 [DEBUG] tlsutil: OutgoingRPCWrapper with version 1 2019/11/20 22:17:29 [INFO] raft: Initial configuration (index=1): [{Suffrage:Voter ID:feba8d74-4a3a-9b42-305f-eea7da207c9c Address:127.0.0.1:8300}] 2019/11/20 22:17:29 [INFO] raft: Node at 127.0.0.1:8300 [Follower] entering Follower state (Leader: \"\") 2019/11/20 22:17:29 [INFO] serf: EventMemberJoin: C02Z35N9LVCF.dc1 127.0.0.1 2019/11/20 22:17:29 [INFO] serf: EventMemberJoin: C02Z35N9LVCF 127.0.0.1 2019/11/20 22:17:29 [INFO] consul: Adding LAN server C02Z35N9LVCF (Addr: tcp/127.0.0.1:8300) (DC: dc1) 2019/11/20 22:17:29 [INFO] consul: Handled member-join event for server \"C02Z35N9LVCF.dc1\" in area \"wan\" 2019/11/20 22:17:29 [INFO] agent: Started DNS server 127.0.0.1:8600 (tcp) 2019/11/20 22:17:29 [INFO] agent: Started DNS server 127.0.0.1:8600 (udp) 2019/11/20 22:17:29 [INFO] agent: Started HTTP server on 127.0.0.1:8500 (tcp) 2019/11/20 22:17:29 [INFO] agent: Started gRPC server on 127.0.0.1:8502 (tcp) 2019/11/20 22:17:29 [INFO] agent: started state syncer ==\u003e Consul agent running! 2019/11/20 22:17:30 [WARN] raft: Heartbeat timeout from \"\" reached, starting election 2019/11/20 22:17:30 [INFO] raft: Node at 127.0.0.1:8300 [Candidate] entering Candidate state in term 2 2019/11/20 22:17:30 [DEBUG] raft: Votes needed: 1 2019/11/20 22:17:30 [DEBUG] raft: Vote granted from feba8d74-4a3a-9b42-305f-eea7da207c9c in term 2. Tally: 1 2019/11/20 22:17:30 [INFO] raft: Election won. Tally: 1 2019/11/20 22:17:30 [INFO] raft: Node at 127.0.0.1:8300 [Leader] entering Leader state 2019/11/20 22:17:30 [INFO] consul: cluster leadership acquired 2019/11/20 22:17:30 [INFO] consul: New leader elected: C02Z35N9LVCF 2019/11/20 22:17:30 [INFO] connect: initialized primary datacenter CA with provider \"consul\" 2019/11/20 22:17:30 [DEBUG] consul: Skipping self join check for \"C02Z35N9LVCF\" since the cluster is too small 2019/11/20 22:17:30 [INFO] consul: member 'C02Z35N9LVCF' joined, marking health alive 2019/11/20 22:17:30 [DEBUG] agent: Skipping remote check \"serfHealth\" since it is managed automatically 2019/11/20 22:17:30 [INFO] agent: Synced service \"web\" 2019/11/20 22:17:30 [DEBUG] agent: Node info in sync 2019/11/20 22:17:32 [DEBUG] tlsutil: OutgoingRPCWrapper with version 1 2019/11/20 22:17:32 [DEBUG] agent: Skipping remote check \"serfHealth\" since it is managed automatically 2019/11/20 22:17:32 [DEBUG] agent: Service \"web\" in sync 2019/11/20 22:17:32 [DEBUG] agent: Node info in sync 2019/11/20 22:17:32 [DEBUG] agent: Service \"web\" in sync 2019/11/20 22:17:32 [DEBUG] agent: Node info in sync 日志中的Synced service 'web'表示Agent从配置文件中载入了服务定义，并且成功注册到服务目录。 如果想注册多个服务，就可以在Consul配置目录创建多个服务定义文件。 ","date":"2020-01-30","objectID":"/posts/manual-of-consul/:4:1","tags":["console"],"title":"Consul入门手册","uri":"/posts/manual-of-consul/"},{"categories":null,"content":"查询服务 一旦Agent启动并且服务同步了，我们可就以通过DNS或者HTTP API来查询服务。 DNS API 我们首先使用DNS API来查询。在DNS API中，服务的DNS名字是 NAME.service.consul。虽然是可配置的，但默认的所有DNS名字会都在consul命名空间下，这个子域告诉Consul，我们在查询服务，NAME则是服务的名称. 对于我们上面注册的Web服务.它的域名是 web.service.consul: $ dig @127.0.0.1 -p 8600 web.service.consul ; \u003c\u003c\u003e\u003e DiG 9.10.6 \u003c\u003c\u003e\u003e @127.0.0.1 -p 8600 web.service.consul ; (1 server found) ;; global options: +cmd ;; Got answer: ;; -\u003e\u003eHEADER\u003c\u003c- opcode: QUERY, status: NOERROR, id: 27222 ;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 2 ;; WARNING: recursion requested but not available ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 4096 ;; QUESTION SECTION: ;web.service.consul. IN A ;; ANSWER SECTION: web.service.consul. 0 IN A 127.0.0.1 ;; ADDITIONAL SECTION: web.service.consul. 0 IN TXT \"consul-network-segment=\" ;; Query time: 8 msec ;; SERVER: 127.0.0.1#8600(127.0.0.1) ;; WHEN: Wed Nov 20 22:26:14 CST 2019 ;; MSG SIZE rcvd: 99 如你所见,一个A记录返回了一个可用的服务所在的节点的IP地址。A记录只能设置为IP地址，有也可用使用 DNS API 来接收包含地址和端口的 SRV 记录： $ dig @127.0.0.1 -p 8600 web.service.consul SRV ; \u003c\u003c\u003e\u003e DiG 9.10.6 \u003c\u003c\u003e\u003e @127.0.0.1 -p 8600 web.service.consul SRV ; (1 server found) ;; global options: +cmd ;; Got answer: ;; -\u003e\u003eHEADER\u003c\u003c- opcode: QUERY, status: NOERROR, id: 49043 ;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 3 ;; WARNING: recursion requested but not available ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 4096 ;; QUESTION SECTION: ;web.service.consul. IN SRV ;; ANSWER SECTION: web.service.consul. 0 IN SRV 1 1 80 C02Z35N9LVCF.node.dc1.consul. ;; ADDITIONAL SECTION: C02Z35N9LVCF.node.dc1.consul. 0 IN A 127.0.0.1 C02Z35N9LVCF.node.dc1.consul. 0 IN TXT \"consul-network-segment=\" ;; Query time: 1 msec ;; SERVER: 127.0.0.1#8600(127.0.0.1) ;; WHEN: Wed Nov 20 22:28:14 CST 2019 ;; MSG SIZE rcvd: 147 SRV记录告诉我们 web 这个服务运行于节点C02Z35N9LVCF.node.dc1.consul 的80端口，DNS额外返回了节点的A记录。 最后，我们也可以用 DNS API 通过标签来过滤服务，基于标签的服务查询格式为TAG.NAME.service.consul。在下面的例子中，我们请求Consul返回有 rails标签的 web服务： $ dig @127.0.0.1 -p 8600 rails.web.service.consul SRV # 输出信息略 HTTP API 除了DNS API之外，也可以使用HTTP API查询所有服务实例： $ curl http://localhost:8500/v1/catalog/service/web [ { \"ID\": \"feba8d74-4a3a-9b42-305f-eea7da207c9c\", \"Node\": \"C02Z35N9LVCF\", \"Address\": \"127.0.0.1\", \"Datacenter\": \"dc1\", \"TaggedAddresses\": { \"lan\": \"127.0.0.1\", \"wan\": \"127.0.0.1\" }, \"NodeMeta\": { \"consul-network-segment\": \"\" }, \"ServiceKind\": \"\", \"ServiceID\": \"web\", \"ServiceName\": \"web\", \"ServiceTags\": [ \"rails\" ], \"ServiceAddress\": \"\", \"ServiceWeights\": { \"Passing\": 1, \"Warning\": 1 }, \"ServiceMeta\": {}, \"ServicePort\": 80, \"ServiceEnableTagOverride\": false, \"ServiceProxy\": { \"MeshGateway\": {} }, \"ServiceConnect\": {}, \"CreateIndex\": 10, \"ModifyIndex\": 10 } ] 只查看健康服务实例的方法： $ curl http://localhost:8500/v1/catalog/service/web?passing # 输出信息略 ","date":"2020-01-30","objectID":"/posts/manual-of-consul/:4:2","tags":["console"],"title":"Consul入门手册","uri":"/posts/manual-of-consul/"},{"categories":null,"content":"更新服务 服务定义可以通过修改配置文件并发送SIGHUP给Agent来进行更新，这样可以在不关闭服务或者保持服务请求可用的情况下进行更新。 参考来源： https://github.com/hashicorp/consul https://www.consul.io/intro/getting-started.html https://book-consul-guide.vnzmi.com/01_what_is_consul.html ","date":"2020-01-30","objectID":"/posts/manual-of-consul/:4:3","tags":["console"],"title":"Consul入门手册","uri":"/posts/manual-of-consul/"},{"categories":["后台开发"],"content":"跨域认证问题 互联网服务离不开用户认证。一般流程是下面这样： 用户向服务器发送用户名和密码。 服务器验证通过后，在当前对话（session）里面保存相关数据，比如用户角色、登录时间等等。 服务器向用户返回一个 session_id，写入用户的 Cookie。 用户随后的每一次请求，都会通过 Cookie，将 session_id 传回服务器。 服务器收到 session_id，找到前期保存的数据，由此得知用户的身份。 这种模式的问题在于，扩展性（scaling）不好。单机当然没有问题，如果是服务器集群，或者是跨域的服务导向架构，就要求 session 数据共享，每台服务器都能够读取 session。 举例来说，A 网站和 B 网站是同一家公司的关联服务。现在要求，用户只要在其中一个网站登录，再访问另一个网站就会自动登录，请问怎么实现？ 一种解决方案是 session 数据持久化，写入数据库或别的持久层。各种服务收到请求后，都向持久层请求数据。这种方案的优点是架构清晰，缺点是工程量比较大。另外，持久层万一挂了，就会单点失败。 另一种方案是服务器索性不保存 session 数据了，所有数据都保存在客户端，每次请求都发回服务器。JWT 就是这种方案的一个代表。 ","date":"2020-01-30","objectID":"/posts/usage-of-json-web-token/:1:0","tags":["jwt"],"title":"JSON Web Token入门手册","uri":"/posts/usage-of-json-web-token/"},{"categories":["后台开发"],"content":"什么是JWT？ Json web token (JWT)，是为了在网络应用环境间传递声明而执行的一种基于JSON的开放标准（(RFC 7519)。该token被设计为紧凑且安全的，特别适用于分布式站点的单点登录（SSO）场景。JWT的声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源，也可以增加一些额外的其它业务逻辑所必须的声明信息，该token可直接被用于认证，也可被加密。 ","date":"2020-01-30","objectID":"/posts/usage-of-json-web-token/:2:0","tags":["jwt"],"title":"JSON Web Token入门手册","uri":"/posts/usage-of-json-web-token/"},{"categories":["后台开发"],"content":"JWT 的原理 服务器认证以后，生成一个经过签名的 JSON 对象，发回给用户，服务器则不用保存任何 session 数据了。从而把服务器变成无状态的，易于实现扩展。 ","date":"2020-01-30","objectID":"/posts/usage-of-json-web-token/:3:0","tags":["jwt"],"title":"JSON Web Token入门手册","uri":"/posts/usage-of-json-web-token/"},{"categories":["后台开发"],"content":"JWT 的使用场景 以下是两个JWT的应用场景： 鉴权：这是JWT最常见的应用场景。当用户登录成功后，随后的每个请求都将带上JWT，从而允许用户访问被授权的服务和资源。由于它开销小切易于使用，当前被广泛应用于单点登录（Single Sign On）。 信息交换：JWT是不同组织间交换信息的一种很好的方式。因为JWT可以被签名（例如，通过公钥/私钥对），你可以确信信息发送者就是它们说声明的身份。此外，签名是用Header和Payload计算出来的，你可以验证内容是否被篡改。 ","date":"2020-01-30","objectID":"/posts/usage-of-json-web-token/:4:0","tags":["jwt"],"title":"JSON Web Token入门手册","uri":"/posts/usage-of-json-web-token/"},{"categories":["后台开发"],"content":"JWT 的数据结构 扁平化形式的JWT是由通过 . 分隔的三部分组成，他们分别是： Header Payload Signature 所以，一个JWT看起来通常是如下的形式： xxxxx.yyyyy.zzzzz ","date":"2020-01-30","objectID":"/posts/usage-of-json-web-token/:5:0","tags":["jwt"],"title":"JSON Web Token入门手册","uri":"/posts/usage-of-json-web-token/"},{"categories":["后台开发"],"content":"Header 头部由两部分组成： token类型，即JWT； 签名算法，例如HMAC SHA256或RSA。 一个Header的例子： { \"alg\": \"HS256\", \"typ\": \"JWT\" } 随后，以上JSON对象会通过 Base64Url 编码为JWT的第一部分。 ","date":"2020-01-30","objectID":"/posts/usage-of-json-web-token/:5:1","tags":["jwt"],"title":"JSON Web Token入门手册","uri":"/posts/usage-of-json-web-token/"},{"categories":["后台开发"],"content":"Payload 载荷就是存放有效信息的地方。这个名字像是特指飞机上承载的货品，这些有效信息包含三个部分 标准中注册的声明 公共的声明 私有的声明 标准中注册的声明： iss: jwt签发者 sub: jwt所面向的用户 aud: 接收jwt的一方 exp: jwt的过期时间，这个过期时间必须要大于签发时间 nbf: 定义在什么时间之前，该jwt都是不可用的. iat: jwt的签发时间 jti: jwt的唯一身份标识，主要用来作为一次性token,从而回避重放攻击。 公共的声明 ： 公共的声明可以添加任何的信息，一般添加用户的相关信息或其他业务需要的必要信息.但不建议添加敏感信息，因为该部分在客户端可解密。 私有的声明 ： 私有声明是提供者和消费者所共同定义的声明，一般不建议存放敏感信息，因为base64是对称解密的，意味着该部分信息可以归类为明文信息。 一个Payload的例子： { \"sub\": \"1234567890\", \"name\": \"John Doe\", \"admin\": true } 随后，Payload会通过 Base64Url 编码为JWT的第二部分。 ","date":"2020-01-30","objectID":"/posts/usage-of-json-web-token/:5:2","tags":["jwt"],"title":"JSON Web Token入门手册","uri":"/posts/usage-of-json-web-token/"},{"categories":["后台开发"],"content":"Signature 创建签名需要用到编码后的 Header、编码后的 Payload、秘钥、Header中指定的算法。 如果你想使用HMAC SHA256算法，签名将通过如下方式生成： HMACSHA256( base64UrlEncode(header) + \".\" + base64UrlEncode(payload), secret) 如果你想把以上概念付诸实践，可以通过 https://jwt.io/ 提供的工具来玩一玩 JWT 。如下图所示： ","date":"2020-01-30","objectID":"/posts/usage-of-json-web-token/:5:3","tags":["jwt"],"title":"JSON Web Token入门手册","uri":"/posts/usage-of-json-web-token/"},{"categories":["后台开发"],"content":"JWT 的使用方式 客户端收到服务器返回的 JWT，可以储存在 Cookie 里面，也可以储存在 localStorage。 此后，客户端每次与服务器通信，都要带上这个 JWT。你可以把它放在 Cookie 里面自动发送，但是这样不能跨域，所以更好的做法是放在 HTTP 请求的头信息Authorization字段里面。 Authorization: Bearer \u003ctoken\u003e 另一种做法是，跨域的时候，JWT 就放在 POST 请求的数据体里面。 ","date":"2020-01-30","objectID":"/posts/usage-of-json-web-token/:6:0","tags":["jwt"],"title":"JSON Web Token入门手册","uri":"/posts/usage-of-json-web-token/"},{"categories":["后台开发"],"content":"JWT 的几个特点 JWT 默认是不加密，但也是可以加密的。生成原始 Token 以后，可以用密钥再加密一次。 JWT 不加密的情况下，不能将秘密数据写入 JWT。 JWT 不仅可以用于认证，也可以用于交换信息。有效使用 JWT，可以降低服务器查询数据库的次数。 JWT 的最大缺点是，由于服务器不保存 session 状态，因此无法在使用过程中废止某个 token，或者更改 token 的权限。也就是说，一旦 JWT 签发了，在到期之前就会始终有效，除非服务器部署额外的逻辑。 JWT 本身包含了认证信息，一旦泄露，任何人都可以获得该令牌的所有权限。为了减少盗用，JWT 的有效期应该设置得比较短。对于一些比较重要的权限，使用时应该再次对用户进行认证。 为了减少盗用，JWT 不应该使用 HTTP 协议明码传输，要使用 HTTPS 协议传输。 ","date":"2020-01-30","objectID":"/posts/usage-of-json-web-token/:7:0","tags":["jwt"],"title":"JSON Web Token入门手册","uri":"/posts/usage-of-json-web-token/"},{"categories":["后台开发"],"content":"示例代码 Go语言版本： package util import ( \"crypto/rsa\" \"crypto/x509\" \"encoding/pem\" \"errors\" \"fmt\" \"github.com/dgrijalva/jwt-go\" ) var ErrVerifyFailed = fmt.Errorf(\"verify failed\") //https://godoc.org/github.com/dgrijalva/jwt-go#example-New--Hmac func CreateToken(claims jwt.MapClaims, privateKey []byte) (string, error) { token := jwt.NewWithClaims(jwt.SigningMethodRS512, claims) block, _ := pem.Decode(privateKey) if block == nil { return \"\", errors.New(\"private key error\") } priv, err := x509.ParsePKCS8PrivateKey(block.Bytes) if err != nil { return \"\", err } return token.SignedString(priv) } //https://godoc.org/github.com/dgrijalva/jwt-go#example-Parse--Hmac func VerifyToken(tokenString string, publicKey []byte) (jwt.MapClaims, error) { token, err := jwt.Parse(tokenString, func(token *jwt.Token) (interface{}, error) { if _, ok := token.Method.(*jwt.SigningMethodRSA); !ok { return nil, fmt.Errorf(\"unexpected signing method: %v\", token.Header[\"alg\"]) } if token.Header[\"alg\"] != \"RS512\" { return nil, fmt.Errorf(\"unexpected siging alg: %v\", token.Header[\"alg\"]) } block, _ := pem.Decode(publicKey) if block == nil { return nil, ErrVerifyFailed } pubInterface, err := x509.ParsePKIXPublicKey(block.Bytes) if err != nil { return nil, ErrVerifyFailed } pub := pubInterface.(*rsa.PublicKey) return pub, nil }) if err != nil { return nil, ErrVerifyFailed } if claims, ok := token.Claims.(jwt.MapClaims); ok \u0026\u0026 token.Valid { return claims, nil } return nil, ErrVerifyFailed } 参考来源： https://jwt.io/introduction/ https://www.jianshu.com/p/576dbf44b2ae https://www.ruanyifeng.com/blog/2018/07/json_web_token-tutorial.html ","date":"2020-01-30","objectID":"/posts/usage-of-json-web-token/:8:0","tags":["jwt"],"title":"JSON Web Token入门手册","uri":"/posts/usage-of-json-web-token/"},{"categories":["docker"],"content":"获取镜像 $ docker pull ubuntu ","date":"2020-01-30","objectID":"/posts/usage-of-docker-container/:1:0","tags":["docker"],"title":"Docker之容器使用","uri":"/posts/usage-of-docker-container/"},{"categories":["docker"],"content":"启动容器： $ docker run -it ubuntu /bin/bash # 要退出终端，直接输入 exit ","date":"2020-01-30","objectID":"/posts/usage-of-docker-container/:2:0","tags":["docker"],"title":"Docker之容器使用","uri":"/posts/usage-of-docker-container/"},{"categories":["docker"],"content":"启动已停止运行的容器 $ docker ps -a ","date":"2020-01-30","objectID":"/posts/usage-of-docker-container/:3:0","tags":["docker"],"title":"Docker之容器使用","uri":"/posts/usage-of-docker-container/"},{"categories":["docker"],"content":"启动已停止运行的容器 $ docker start b750bbbcfd88 ","date":"2020-01-30","objectID":"/posts/usage-of-docker-container/:4:0","tags":["docker"],"title":"Docker之容器使用","uri":"/posts/usage-of-docker-container/"},{"categories":["docker"],"content":"后台运行 $ docker run -itd --name ubuntu-test ubuntu /bin/bash ","date":"2020-01-30","objectID":"/posts/usage-of-docker-container/:5:0","tags":["docker"],"title":"Docker之容器使用","uri":"/posts/usage-of-docker-container/"},{"categories":["docker"],"content":"停止一个容器 $ docker stop \u003c容器 ID\u003e 停止的容器可以通过 docker restart 重启： $ docker restart \u003c容器 ID\u003e ","date":"2020-01-30","objectID":"/posts/usage-of-docker-container/:6:0","tags":["docker"],"title":"Docker之容器使用","uri":"/posts/usage-of-docker-container/"},{"categories":["docker"],"content":"进入容器 在使用 -d 参数时，容器启动后会进入后台。此时想要进入容器，可以通过以下指令进入： docker attach： 如果从这个容器退出（exit），会导致容器的停止。 docker exec：推荐大家使用 docker exec 命令，因为此退出容器终端，不会导致容器的停止。 exec命令使用： $ docker exec -it 243c32535da7 /bin/bash ","date":"2020-01-30","objectID":"/posts/usage-of-docker-container/:7:0","tags":["docker"],"title":"Docker之容器使用","uri":"/posts/usage-of-docker-container/"},{"categories":["docker"],"content":"导出和导入容器 ","date":"2020-01-30","objectID":"/posts/usage-of-docker-container/:8:0","tags":["docker"],"title":"Docker之容器使用","uri":"/posts/usage-of-docker-container/"},{"categories":["docker"],"content":"导出容器 $ docker export 1e560fca3906 \u003e ubuntu.tar ","date":"2020-01-30","objectID":"/posts/usage-of-docker-container/:8:1","tags":["docker"],"title":"Docker之容器使用","uri":"/posts/usage-of-docker-container/"},{"categories":["docker"],"content":"导入容器 $ cat docker/ubuntu.tar | docker import - test/ubuntu:v1 或 $ docker import docker/ubuntu.tar test/ubuntu:v1 也可以通过指定 URL 或者某个目录来导入，例如： $ docker import http://example.com/exampleimage.tgz example/imagerepo 参考来源： [1] https://www.runoob.com/docker/docker-container-usage.html ","date":"2020-01-30","objectID":"/posts/usage-of-docker-container/:8:2","tags":["docker"],"title":"Docker之容器使用","uri":"/posts/usage-of-docker-container/"},{"categories":["docker"],"content":"获取镜像 用法： $ docker pull [OPTIONS] NAME[:TAG|@DIGEST] 例如：docker pull ubuntu:18.04 ","date":"2020-01-30","objectID":"/posts/usage-of-docker-image/:1:0","tags":["docker"],"title":"Docker之镜像使用","uri":"/posts/usage-of-docker-image/"},{"categories":["docker"],"content":"启动容器 $ docker run -it --rm ubuntu:18.04 bash 简要的说明一下上面用到的参数: -it：这是两个参数，一个是 -i表示交互式操作，一个是-t表示终端。我们这里打算进入 bash 执行一些命令并查看返回结果，因此我们需要交互式终端。 --rm：这个参数是说容器退出后随之将其删除。默认情况下，为了排障需求，退出的容器并不会立即删除，除非手动 docker rm。我们这里只是随便执行个命令，看看结果，不需要排障和保留结果，因此使用--rm 可以避免浪费空间。 ubuntu:18.04：这是指用 ubuntu:18.04 镜像为基础来启动容器。 bash：放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是 bash。 ","date":"2020-01-30","objectID":"/posts/usage-of-docker-image/:2:0","tags":["docker"],"title":"Docker之镜像使用","uri":"/posts/usage-of-docker-image/"},{"categories":["docker"],"content":"查看镜像列表 使用docker image ls或者docker images: $ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE ubuntu 18.04 93fd78260bd1 5 weeks ago 86.2MB ubuntu latest 93fd78260bd1 5 weeks ago 86.2MB hello-world latest 4ab4c602aa5e 3 months ago 1.84kB $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE ubuntu 18.04 93fd78260bd1 5 weeks ago 86.2MB ubuntu latest 93fd78260bd1 5 weeks ago 86.2MB hello-world latest 4ab4c602aa5e 3 months ago 1.84kB 列表包含了 仓库名、标签、镜像 ID、创建时间 以及 所占用的空间。 ","date":"2020-01-30","objectID":"/posts/usage-of-docker-image/:3:0","tags":["docker"],"title":"Docker之镜像使用","uri":"/posts/usage-of-docker-image/"},{"categories":["docker"],"content":"镜像体积 这里标识的所占用空间和在 Docker Hub 上看到的镜像大小不同。比如，ubuntu:18.04 镜像大小，在这里是 127 MB，但是在 Docker Hub 显示的却是 50 MB。这是因为 Docker Hub 中显示的体积是压缩后的体积。在镜像下载和上传过程中镜像是保持着压缩状态的，因此 Docker Hub 所显示的大小是网络传输中更关心的流量大小。而 docker image ls 显示的是镜像下载到本地后展开的大小，准确说，是展开后的各层所占空间的总和，因为镜像到本地后，查看空间的时候，更关心的是本地磁盘空间占用的大小。 另外一个需要注意的问题是，docker image ls 列表中的镜像体积总和并非是所有镜像实际硬盘消耗。由于 Docker 镜像是多层存储结构，并且可以继承、复用，因此不同镜像可能会因为使用相同的基础镜像，从而拥有共同的层。由于 Docker 使用 Union FS，相同的层只需要保存一份即可，因此实际镜像硬盘占用空间很可能要比这个列表镜像大小的总和要小的多。 你可以通过以下命令来便捷的查看镜像、容器、数据卷所占用的空间。 $ docker system df TYPE TOTAL ACTIVE SIZE RECLAIMABLE Images 2 2 86.18MB 0B (0%) Containers 14 2 148B 25B (16%) Local Volumes 0 0 0B 0B Build Cache 0 0 0B 0B ","date":"2020-01-30","objectID":"/posts/usage-of-docker-image/:4:0","tags":["docker"],"title":"Docker之镜像使用","uri":"/posts/usage-of-docker-image/"},{"categories":["docker"],"content":"虚悬镜像 由于新旧镜像同名，旧镜像名称被取消，从而出现仓库名、标签均为\u003cnone\u003e的镜像。这类无标签镜像也被称为 虚悬镜像(dangling image) 。 ","date":"2020-01-30","objectID":"/posts/usage-of-docker-image/:5:0","tags":["docker"],"title":"Docker之镜像使用","uri":"/posts/usage-of-docker-image/"},{"categories":["docker"],"content":"中间层镜像 为了加速镜像构建、重复利用资源，Docker 会利用 中间层镜像。所以在使用一段时间后，可能会看到一些依赖的中间层镜像。默认的 docker image ls 列表中只会显示顶层镜像，如果希望显示包括中间层镜像在内的所有镜像的话，需要加 -a 参数。 $ docker image ls -a 这样会看到很多无标签的镜像，与之前的虚悬镜像不同，这些无标签的镜像很多都是中间层镜像，是其它镜像所依赖的镜像。这些无标签镜像不应该删除，否则会导致上层镜像因为依赖丢失而出错。实际上，这些镜像也没必要删除，因为之前说过，相同的层只会存一遍，而这些镜像是别的镜像的依赖，因此并不会因为它们被列出来而多存了一份，无论如何你也会需要它们。只要删除那些依赖它们的镜像后，这些依赖的中间层镜像也会被连带删除。 以特定格式显示： $ docker image ls --format \"{{.ID}}: {{.Repository}}\" 93fd78260bd1: ubuntu 93fd78260bd1: ubuntu 4ab4c602aa5e: hello-world $ docker image ls --format \"table {{.ID}}\\t{{.Repository}}\\t{{.Tag}}\" IMAGE ID REPOSITORY TAG 93fd78260bd1 ubuntu 18.04 93fd78260bd1 ubuntu latest 4ab4c602aa5e hello-world latest ","date":"2020-01-30","objectID":"/posts/usage-of-docker-image/:6:0","tags":["docker"],"title":"Docker之镜像使用","uri":"/posts/usage-of-docker-image/"},{"categories":["docker"],"content":"删除本地镜像 如果要删除本地的镜像，可以使用 docker image rm 命令，其格式为： $ docker image rm [选项] \u003c镜像1\u003e [\u003c镜像2\u003e ...] 其中，\u003c镜像\u003e 可以是 镜像短 ID、镜像长 ID、镜像名 或者 镜像摘要。 ","date":"2020-01-30","objectID":"/posts/usage-of-docker-image/:7:0","tags":["docker"],"title":"Docker之镜像使用","uri":"/posts/usage-of-docker-image/"},{"categories":["docker"],"content":"Untagged 和 Deleted 如果观察上面这几个命令的运行输出信息的话，你会注意到删除行为分为两类，一类是Untagged，另一类是 Deleted。我们之前介绍过，镜像的唯一标识是其 ID 和摘要，而一个镜像可以有多个标签。 因此当我们使用上面命令删除镜像的时候，实际上是在要求删除某个标签的镜像。所以首先需要做的是将满足我们要求的所有镜像标签都取消，这就是我们看到的 Untagged 的信息。因为一个镜像可以对应多个标签，因此当我们删除了所指定的标签后，可能还有别的标签指向了这个镜像，如果是这种情况，那么 Delete 行为就不会发生。所以并非所有的 docker image rm 都会产生删除镜像的行为，有可能仅仅是取消了某个标签而已。 当该镜像所有的标签都被取消了，该镜像很可能会失去了存在的意义，因此会触发删除行为。镜像是多层存储结构，因此在删除的时候也是从上层向基础层方向依次进行判断删除。镜像的多层结构让镜像复用变动非常容易，因此很有可能某个其它镜像正依赖于当前镜像的某一层。这种情况，依旧不会触发删除该层的行为。直到没有任何层依赖当前层时，才会真实的删除当前层。 除了镜像依赖以外，还需要注意的是容器对镜像的依赖。如果有用这个镜像启动的容器存在（即使容器没有运行），那么同样不可以删除这个镜像。之前讲过，容器是以镜像为基础，再加一层容器存储层，组成这样的多层存储结构去运行的。因此该镜像如果被这个容器所依赖的，那么删除必然会导致故障。如果这些容器是不需要的，应该先将它们删除，然后再来删除镜像。 ","date":"2020-01-30","objectID":"/posts/usage-of-docker-image/:8:0","tags":["docker"],"title":"Docker之镜像使用","uri":"/posts/usage-of-docker-image/"},{"categories":["docker"],"content":"利用 commit 理解镜像构成 注意： docker commit 命令除了学习之外，还有一些特殊的应用场合，比如被入侵后保存现场等。但是，不要使用 docker commit 定制镜像，定制镜像应该使用 Dockerfile 来完成。 镜像是多层存储，每一层是在前一层的基础上进行的修改；而容器同样也是多层存储，是在以镜像为基础层，在其基础上加一层作为容器运行时的存储层。 现在让我们以定制一个 Web 服务器为例子，来讲解镜像是如何构建的。 $ docker run --name webserver -d -p 80:80 nginx 这条命令会用 nginx 镜像启动一个容器，命名为 webserver，并且映射了 80 端口，这样我们可以用浏览器去访问这个 nginx 服务器。 用浏览器访问的话，我们会看到默认的 Nginx 欢迎页面内容： Welcome to nginx! If you see this page, the nginx web server is successfully installed and working. Further configuration is required. For online documentation and support please refer to nginx.org. Commercial support is available at nginx.com. Thank you for using nginx. 如果我们想要修改欢迎页面的内容，可以使用 docker exec 命令进入容器，修改其内容。 $ docker exec -it webserver bash root@3729b97e8226:/# echo '\u003ch1\u003eHello, Docker!\u003c/h1\u003e' \u003e /usr/share/nginx/html/index.html root@3729b97e8226:/# exit exit 我们以交互式终端方式进入 webserver 容器，并执行了 bash 命令，也就是获得一个可操作的 Shell。 然后，我们用 \u003ch1\u003eHello, Docker!\u003c/h1\u003e 覆盖了 /usr/share/nginx/html/index.html 的内容。现在我们再刷新浏览器的话，会发现内容被改变了。 我们修改了容器的文件，也就是改动了容器的存储层。我们可以通过 docker diff 命令看到具体的改动。 $ docker diff webserver C /usr C /usr/share C /usr/share/nginx C /usr/share/nginx/html C /usr/share/nginx/html/index.html C /root A /root/.bash_history C /var C /var/cache C /var/cache/nginx A /var/cache/nginx/scgi_temp A /var/cache/nginx/uwsgi_temp A /var/cache/nginx/client_temp A /var/cache/nginx/fastcgi_temp A /var/cache/nginx/proxy_temp C /run A /run/nginx.pid 当我们运行一个容器的时候（如果不使用卷的话），我们做的任何文件修改都会被记录于容器存储层里。Docker 提供了一个 docker commit 命令，可以将容器的存储层保存下来成为镜像。换句话说，就是在原有镜像的基础上，再叠加上容器的存储层，并构成新的镜像。 docker commit 的语法格式为： docker commit [选项] \u003c容器ID或容器名\u003e [\u003c仓库名\u003e[:\u003c标签\u003e]] 我们可以用下面的命令将容器保存为镜像： $ docker commit --author \"chuxing\" --message \"update page\" webserver nginx:v2 sha256:8aaa0b63a1b842fb301d5d691cae92d9fdb52c73f37858eefada4325a36474f0 我们可以在 docker image ls 中看到这个新定制的镜像： $ docker image ls nginx REPOSITORY TAG IMAGE ID CREATED SIZE nginx v2 8aaa0b63a1b8 About a minute ago 109MB nginx latest 568c4670fa80 4 weeks ago 109MB 新的镜像定制好后，我们可以运行这个镜像: docker run --name web2 -d -p 81:80 nginx:v2 ","date":"2020-01-30","objectID":"/posts/usage-of-docker-image/:9:0","tags":["docker"],"title":"Docker之镜像使用","uri":"/posts/usage-of-docker-image/"},{"categories":["docker"],"content":"慎用 docker commit 使用 docker commit 命令虽然可以比较直观的帮助理解镜像分层存储的概念，但是实际环境中并不会这样使用。 如果仔细观察之前的 docker diff webserver 的结果，你会发现除了真正想要修改的 /usr/share/nginx/html/index.html 文件外，还有很多文件被改动或添加了。这还仅仅是最简单的操作，如果是安装软件包、编译构建，那会有大量的无关内容被添加进来，如果不小心清理，将会导致镜像极为臃肿。 使用 docker commit 意味着所有对镜像的操作都是黑箱操作，生成的镜像也被称为黑箱镜像，换句话说，就是除了制作镜像的人知道执行过什么命令、怎么生成的镜像，别人根本无从得知。 回顾之前提及的镜像所使用的分层存储的概念，任何修改的结果仅仅是在当前层进行标记、添加、修改，而不会改动上一层。如果使用 docker commit 制作镜像，每一次修改都会让镜像更加臃肿一次，这会让镜像更加臃肿。 ","date":"2020-01-30","objectID":"/posts/usage-of-docker-image/:10:0","tags":["docker"],"title":"Docker之镜像使用","uri":"/posts/usage-of-docker-image/"},{"categories":["docker"],"content":"镜像导入和导出 ","date":"2020-01-30","objectID":"/posts/usage-of-docker-image/:11:0","tags":["docker"],"title":"Docker之镜像使用","uri":"/posts/usage-of-docker-image/"},{"categories":["docker"],"content":"导出镜像 $ docker save -o nginx.tar nginx:latest 或 $ docker save \u003e nginx.tar nginx:latest ","date":"2020-01-30","objectID":"/posts/usage-of-docker-image/:11:1","tags":["docker"],"title":"Docker之镜像使用","uri":"/posts/usage-of-docker-image/"},{"categories":["docker"],"content":"导入镜像 $ docker load -i nginx.tar 或 $ docker load \u003c nginx.tar ","date":"2020-01-30","objectID":"/posts/usage-of-docker-image/:11:2","tags":["docker"],"title":"Docker之镜像使用","uri":"/posts/usage-of-docker-image/"},{"categories":["docker"],"content":"1. 移除旧的版本 sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine ","date":"2020-01-30","objectID":"/posts/centos-install-docker/:0:1","tags":["docker"],"title":"CentOS安装docker","uri":"/posts/centos-install-docker/"},{"categories":["docker"],"content":"2. 安装一些必要的系统工具 sudo yum install -y yum-utils device-mapper-persistent-data lvm2 ","date":"2020-01-30","objectID":"/posts/centos-install-docker/:0:2","tags":["docker"],"title":"CentOS安装docker","uri":"/posts/centos-install-docker/"},{"categories":["docker"],"content":"3. 添加软件源信息 sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo ","date":"2020-01-30","objectID":"/posts/centos-install-docker/:0:3","tags":["docker"],"title":"CentOS安装docker","uri":"/posts/centos-install-docker/"},{"categories":["docker"],"content":"4. 更新 yum 缓存 sudo yum makecache fast ","date":"2020-01-30","objectID":"/posts/centos-install-docker/:0:4","tags":["docker"],"title":"CentOS安装docker","uri":"/posts/centos-install-docker/"},{"categories":["docker"],"content":"5. 安装 Docker-ce sudo yum -y install docker-ce ","date":"2020-01-30","objectID":"/posts/centos-install-docker/:0:5","tags":["docker"],"title":"CentOS安装docker","uri":"/posts/centos-install-docker/"},{"categories":["docker"],"content":"6. 启动 Docker 后台服务 sudo systemctl start docker ","date":"2020-01-30","objectID":"/posts/centos-install-docker/:0:6","tags":["docker"],"title":"CentOS安装docker","uri":"/posts/centos-install-docker/"},{"categories":["docker"],"content":"7. 测试运行 hello-world 初次运行可能会报如下的错误信息： [root@VM_0_6_centos ~]# docker run hello-world Unable to find image 'hello-world:latest' locally docker: Error response from daemon: Get https://registry-1.docker.io/v2/library/hello-world/manifests/latest: Get https://auth.docker.io/token?scope=repository%3Alibrary%2Fhello-world%3Apull\u0026service=registry.docker.io: net/http: TLS handshake timeout. See 'docker run --help'. 解决方式是使用国内的镜像地址，新建/etc/docker/daemon.json文件，填写如下配置信息： { \"registry-mirrors\": [\"http://hub-mirror.c.163.com\"] } 之后运行正常，如下： [root@VM_0_6_centos docker]# docker run hello-world Unable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world d1725b59e92d: Pull complete Digest: sha256:0add3ace90ecb4adbf7777e9aacf18357296e799f81cabc9fde470971e499788 Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ ","date":"2020-01-30","objectID":"/posts/centos-install-docker/:0:7","tags":["docker"],"title":"CentOS安装docker","uri":"/posts/centos-install-docker/"},{"categories":null,"content":"SO_REUSEADDR 当有一个有相同本地地址和端口的socket1处于TIME_WAIT状态时，而你启动的程序的socket2要占用该地址和端口，你的程序就要用到该选项。 SO_REUSEADDR允许同一port上启动同一服务器的多个实例(多个进程)。但每个实例绑定的IP地址是不能相同的。在有多块网卡或用IP Alias技术的机器可 以测试这种情况。 SO_REUSEADDR允许单个进程绑定相同的端口到多个socket上，但每个socket绑定的ip地址不同。这和2很相似，区别请看UNPv1。 SO_REUSEADDR允许完全相同的地址和端口的重复绑定。但这只用于UDP的多播，不用于TCP。 ","date":"2020-01-30","objectID":"/posts/so-reuseaddr-so-reuseport/:1:0","tags":["REUSEADDR","REUSEPORT"],"title":"SO_REUSEADDR \u0026 SO_REUSEPORT","uri":"/posts/so-reuseaddr-so-reuseport/"},{"categories":null,"content":"SO_REUSEPORT The new socket option allows multiple sockets on the same host to bind to the same port, and is intended to improve the performance of multithreaded network server applications running on top of multicore systems. linux kernel 3.9引入了最新的SO_REUSEPORT选项，使得多进程或者多线程可以创建多个绑定同一个ip:port的监听socket，提高服务器的接收连接的并发能力,程序的扩展性更好；此时需要设置SO_REUSEPORT（注意所有进程都要设置才生效）。 目的：每一个进程有一个独立的监听socket，并且bind相同的ip:port，独立的listen()和accept()；提高接收连接的能力。（例如nginx多进程同时监听同一个ip:port） 解决的问题： 避免了应用层多线程或者进程监听同一ip:port的“惊群效应”。 内核层面实现负载均衡，保证每个进程或者线程接收均衡的连接数。 只有effective-user-id相同的服务器进程才能监听同一ip:port （安全性考虑） golang开源实现：https://github.com/kavu/go_reuseport 注意：SO_REUSEPORT只支持TCP和UDP。对unix domain socket不生效。 ","date":"2020-01-30","objectID":"/posts/so-reuseaddr-so-reuseport/:2:0","tags":["REUSEADDR","REUSEPORT"],"title":"SO_REUSEADDR \u0026 SO_REUSEPORT","uri":"/posts/so-reuseaddr-so-reuseport/"},{"categories":["Kubernetes"],"content":"Kubernetes 简介 Kubernetes 是谷歌开源的容器集群管理系统，是 Google 多年大规模容器管理技术 Borg 的开源版本，主要功能包括： 基于容器的应用部署、维护和滚动升级 负载均衡和服务发现 跨机器和跨地区的集群调度 自动伸缩 无状态服务和有状态服务 广泛的 Volume 支持 插件机制保证扩展性 ","date":"2020-01-29","objectID":"/posts/introduction-of-k8s/:1:0","tags":["Kubernetes"],"title":"Kubernetes概述","uri":"/posts/introduction-of-k8s/"},{"categories":["Kubernetes"],"content":"Kubernetes 是一个平台 Kubernetes 提供了很多的功能，它可以简化应用程序的工作流，加快开发速度。 用户可以使用 Label 以自己的方式组织管理资源，还可以使用 Annotation 来自定义资源的描述信息，比如为管理工具提供状态检查等。 Kubernetes 控制器也是构建在跟开发人员和用户使用的相同的 API 之上。用户还可以编写自己的控制器和调度器，也可以通过各种插件机制扩展系统的功能。 ","date":"2020-01-29","objectID":"/posts/introduction-of-k8s/:1:1","tags":["Kubernetes"],"title":"Kubernetes概述","uri":"/posts/introduction-of-k8s/"},{"categories":["Kubernetes"],"content":"Kubernetes 不是什么 Kubernetes 不是一个传统意义上，包罗万象的 PaaS (平台即服务) 系统，它给用户保留了选择的自由和灵活性。 不限制支持的应用程序类型。Kubernetes 旨在支持极其多样化的工作负载，包括无状态、有状态和数据处理工作负载。只要应用可以在容器中运行，那么它就可以很好的在 Kubernetes 上运行。 不提供内置的中间件 (如消息中间件)、数据处理框架 (如 Spark)、数据库 (如 mysql) 或集群存储系统 (如 Ceph) 等。 不直接部署代码，也不会构建您的应用程序。 允许用户选择自己的日志、监控和告警系统。 不提供应用程序配置语言或系统 (如 jsonnet)。 不提供机器配置、维护、管理或自愈系统。 ","date":"2020-01-29","objectID":"/posts/introduction-of-k8s/:1:2","tags":["Kubernetes"],"title":"Kubernetes概述","uri":"/posts/introduction-of-k8s/"},{"categories":["Kubernetes"],"content":"核心组件 Kubernetes 主要由以下几个核心组件组成： etcd 保存了整个集群的状态； apiserver 提供了资源操作的唯一入口，并提供认证、授权、访问控制、API 注册和发现等机制； controller manager 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等； scheduler 负责资源的调度，按照预定的调度策略将 Pod 调度到相应的机器上； kubelet 负责维护容器的生命周期，同时也负责 Volume（CVI）和网络（CNI）的管理； Container runtime 负责镜像管理以及 Pod 和容器的真正运行（CRI）； kube-proxy 负责为 Service 提供 cluster 内部的服务发现和负载均衡 ","date":"2020-01-29","objectID":"/posts/introduction-of-k8s/:1:3","tags":["Kubernetes"],"title":"Kubernetes概述","uri":"/posts/introduction-of-k8s/"},{"categories":["Kubernetes"],"content":"Kubernetes 基本概念 ","date":"2020-01-29","objectID":"/posts/introduction-of-k8s/:2:0","tags":["Kubernetes"],"title":"Kubernetes概述","uri":"/posts/introduction-of-k8s/"},{"categories":["Kubernetes"],"content":"Container Container（容器）是一种便携式、轻量级的操作系统级虚拟化技术。它使用 namespace 隔离不同的软件运行环境，并通过镜像自包含软件的运行环境，从而使得容器可以很方便的在任何地方运行。 使用容器，不需要与外部的基础架构环境绑定，因为每一个应用程序都不需要外部依赖，更不需要与外部的基础架构环境依赖。完美解决了从开发到生产环境的一致性问题。 容器同样比虚拟机更加透明，这有助于监测和管理。尤其是容器进程的生命周期由基础设施管理，而不是被进程管理器隐藏在容器内部。最后，每个应用程序用容器封装，管理容器部署就等同于管理应用程序部署。 容器的其他优点： 敏捷的应用程序创建和部署：与虚拟机镜像相比，容器镜像更易用、更高效。 持续开发、集成和部署：提供可靠与频繁的容器镜像构建、部署和快速简便的回滚（镜像是不可变的）。 开发与运维的关注分离：在构建/发布时即创建容器镜像，从而将应用与基础架构分离。 开发、测试与生产环境的一致性：在笔记本电脑上运行和云中一样。 可观测：不仅显示操作系统的信息和度量，还显示应用自身的信息和度量。 云和操作系统的分发可移植性：可运行在 Ubuntu, RHEL, CoreOS, 物理机, GKE 以及其他任何地方。 以应用为中心的管理：从传统的硬件上部署操作系统提升到操作系统中部署应用程序。 松耦合、分布式、弹性伸缩、微服务：应用程序被分成更小，更独立的模块，并可以动态管理和部署。 资源隔离：可预测的应用程序性能。 资源利用：高效率和高密度。 ","date":"2020-01-29","objectID":"/posts/introduction-of-k8s/:2:1","tags":["Kubernetes"],"title":"Kubernetes概述","uri":"/posts/introduction-of-k8s/"},{"categories":["Kubernetes"],"content":"Pod Kubernetes 使用 Pod 来管理容器，每个 Pod 可以包含一个或多个紧密关联的容器。 Pod 是一组紧密关联的容器集合，它们共享 PID、IPC、Network 和 UTS namespace，是 Kubernetes 调度的基本单位。Pod 内的多个容器共享网络和文件系统，可以通过进程间通信和文件共享这种简单高效的方式组合完成服务。 在 Kubernetes 中，所有对象都使用 manifest（yaml 或 json）来定义，比如一个简单的 nginx 服务可以定义为 nginx.yaml，它包含一个镜像为 nginx 的容器： apiVersion: v1 kind: Pod metadata: name: nginx labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 ","date":"2020-01-29","objectID":"/posts/introduction-of-k8s/:2:2","tags":["Kubernetes"],"title":"Kubernetes概述","uri":"/posts/introduction-of-k8s/"},{"categories":["Kubernetes"],"content":"Node Node 是 Pod 真正运行的主机，可以是物理机，也可以是虚拟机。为了管理 Pod，每个 Node 节点上至少要运行 container runtime（比如 docker 或者 rkt）、kubelet 和 kube-proxy 服务。 ","date":"2020-01-29","objectID":"/posts/introduction-of-k8s/:2:3","tags":["Kubernetes"],"title":"Kubernetes概述","uri":"/posts/introduction-of-k8s/"},{"categories":["Kubernetes"],"content":"Namespace Namespace 是对一组资源和对象的抽象集合，比如可以用来将系统内部的对象划分为不同的项目组或用户组。常见的 pods, services, replication controllers 和 deployments 等都是属于某一个 namespace 的（默认是 default），而 node, persistentVolumes 等则不属于任何 namespace。 ","date":"2020-01-29","objectID":"/posts/introduction-of-k8s/:2:4","tags":["Kubernetes"],"title":"Kubernetes概述","uri":"/posts/introduction-of-k8s/"},{"categories":["Kubernetes"],"content":"Service Service 是应用服务的抽象，通过 labels 为应用提供负载均衡和服务发现。匹配 labels 的 Pod IP 和端口列表组成 endpoints，由 kube-proxy 负责将服务 IP 负载均衡到这些 endpoints 上。 每个 Service 都会自动分配一个 cluster IP（仅在集群内部可访问的虚拟地址）和 DNS 名，其他容器可以通过该地址或 DNS 来访问服务，而不需要了解后端容器的运行。 apiVersion: v1 kind: Service metadata: name: nginx spec: ports: - port: 8078 # the port that this service should serve on name: http # the container on each pod to connect to, can be a name # (e.g. 'www') or a number (e.g. 80) targetPort: 80 protocol: TCP selector: app: nginx ","date":"2020-01-29","objectID":"/posts/introduction-of-k8s/:2:5","tags":["Kubernetes"],"title":"Kubernetes概述","uri":"/posts/introduction-of-k8s/"},{"categories":["Kubernetes"],"content":"Label Label 是识别 Kubernetes 对象的标签，以 key/value 的方式附加到对象上（key 最长不能超过 63 字节，value 可以为空，也可以是不超过 253 字节的字符串）。 Label 不提供唯一性，并且实际上经常是很多对象（如 Pods）都使用相同的 label 来标志具体的应用。 Label 定义好后其他对象可以使用 Label Selector 来选择一组相同 label 的对象（比如 ReplicaSet 和 Service 用 label 来选择一组 Pod）。Label Selector 支持以下几种方式： 等式，如 app=nginx 和 env!=production 集合，如 env in (production, qa) 多个 label（它们之间是 AND 关系），如 app=nginx,env=test ","date":"2020-01-29","objectID":"/posts/introduction-of-k8s/:2:6","tags":["Kubernetes"],"title":"Kubernetes概述","uri":"/posts/introduction-of-k8s/"},{"categories":["Kubernetes"],"content":"Annotations Annotations 是 key/value 形式附加于对象的注解。不同于 Labels 用于标志和选择对象，Annotations 则是用来记录一些附加信息，用来辅助应用部署、安全策略以及调度策略等。比如 deployment 使用 annotations 来记录 rolling update 的状态。 参考来源： https://feisky.gitbooks.io/kubernetes/introduction/ https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/ ","date":"2020-01-29","objectID":"/posts/introduction-of-k8s/:2:7","tags":["Kubernetes"],"title":"Kubernetes概述","uri":"/posts/introduction-of-k8s/"},{"categories":["Cloud Native"],"content":"云原生的定义 云原生技术有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展的应用。云原生的代表技术包括容器、服务网格、微服务、不可变基础设施和声明式API。 这些技术能够构建容错性好、易于管理和便于观察的松耦合系统。结合可靠的自动化手段，云原生技术使工程师能够轻松地对系统作出频繁和可预测的重大变更。 ","date":"2020-01-28","objectID":"/posts/introduction-of-cloud-native/:1:0","tags":["Cloud Native"],"title":"云原生概述","uri":"/posts/introduction-of-cloud-native/"},{"categories":["Cloud Native"],"content":"云原生的设计哲学 云原生本身甚至不能称为是一种架构，它首先是一种基础设施，运行在其上的应用称作云原生应用，只有符合云原生设计哲学的应用架构才叫云原生应用架构。 ","date":"2020-01-28","objectID":"/posts/introduction-of-cloud-native/:2:0","tags":["Cloud Native"],"title":"云原生概述","uri":"/posts/introduction-of-cloud-native/"},{"categories":["Cloud Native"],"content":"云原生的设计理念 云原生系统的设计理念如下: 面向分布式设计（Distribution）：容器、微服务、API 驱动的开发； 面向配置设计（Configuration）：一个镜像，多个环境配置； 面向韧性设计（Resistancy）：故障容忍和自愈； 面向弹性设计（Elasticity）：弹性扩展和对环境变化（负载）做出响应； 面向交付设计（Delivery）：自动拉起，缩短交付时间； 面向性能设计（Performance）：响应式，并发和资源高效利用； 面向自动化设计（Automation）：自动化的 DevOps； 面向诊断性设计（Diagnosability）：集群级别的日志、metric 和追踪； 面向安全性设计（Security）：安全端点、API Gateway、端到端加密； ","date":"2020-01-28","objectID":"/posts/introduction-of-cloud-native/:2:1","tags":["Cloud Native"],"title":"云原生概述","uri":"/posts/introduction-of-cloud-native/"},{"categories":["Cloud Native"],"content":"云原生应用程序 云原生应用程序被设计为在平台上运行，并设计用于弹性，敏捷性，可操作性和可观察性。弹性包含失败而不是试图阻止它们；它利用了在平台上运行的动态特性。敏捷性允许快速部署和快速迭代。可操作性从应用程序内部控制应用程序生命周期，而不是依赖外部进程和监视器。可观察性提供信息来回答有关应用程序状态的问题。 实现云原生应用程序所需特性的常用方法： 微服务 健康报告 遥测数据 弹性 声明式的，而不是命令式的 微服务 微服务 (Microservices) 是一种软件架构风格，它是以专注于单一责任与功能的小型功能区块 (Small Building Blocks) 为基础，利用模块化的方式组合出复杂的大型应用程序，各功能区块使用与语言无关 (Language-Independent/Language agnostic) 的 API 集相互通信。 微服务是一种以业务功能为主的服务设计概念，每一个服务都具有自主运行的业务功能，对外开放不受语言限制的 API (最常用的是 HTTP)，应用程序则是由一个或多个微服务组成。 健康报告 为了提高云原生应用程序的可操作性，应用程序应该暴露健康检查。开发人员可以将其实施为命令或过程信号，以便应用程序在执行自我检查之后响应，或者更常见的是：通过应用程序提供Web服务，返回HTTP状态码来检查健康状态。 一个很好的例子就是当平台需要知道应用程序何时可以接收流量。在应用程序启动时，如果它不能正确处理流量，它就应该表现为未准备好。 遥测数据 遥测数据是进行决策所需的信息。确实，遥测数据可能与健康报告重叠，但它们有不同的用途。健康报告通知我们应用程序生命周期状态，而遥测数据通知我们应用程序业务目标。 测量的指标有时称为服务级指标（SLI）或关键性能指标（KPI）。这些是特定于应用程序的数据，可以确保应用程序的性能处于服务级别目标（SLO）内。 弹性 一旦你有遥测和监测数据，你需要确保你的应用程序对故障有适应能力。弹性是基础设施的责任，但云原生应用程序也需要承担部分工作。在云原生应用程序中考虑弹性的两个主要方面：为失败设计和优雅降级。 为失败设计 设计一个以失败期望为目标的应用程序将比假定可用性的应用程序更具防御性。当故障不可避免时，将会有额外的检查，故障模式和日志内置到应用程序中。 优雅降级 云原生应用程序处理过载的一种方式。 声明式，非命令式 声明式编程是一种编程范式，与命令式编程相对立。它描述目标的性质，让电脑明白目标，而非流程。声明式编程不用告诉电脑问题领域，从而避免随之而来的副作用。而命令式编程则需要用算法来明确的指出每一步该怎么做。 声明式通信模型规范了通信模型，并且它将功能实现从应用程序转移到远程API或服务端点，从而实现某种状态到达期望状态。这有助于简化应用程序，并使它们彼此的行为更具可预测性。 例子：SQL数据库 其实你很早就接触过声明式编程语言， SQL语言就是很典型的例子： SELECT * from user WHERE user_name = Ben 上面是一个很普通的SQL查询语句，我只只声明我想要找一个叫Ben的用户（What) , 就是不说SQL该怎么（How）去寻找怎么做。接下来我们看看如果用命令式语言写会是什么样的： //user=[{user_name:'ou',user_id=1},.....] var user for(var i = 0; i \u003c user.length; i++){ if(user.user_name == \"Ben\") { print(\"find\"); break; } } 通过上面的对比你可以看出声明式语言的优势-短小精悍，你并不会知道程序的控制流（control flow）我们不需要告诉程序如何去寻找（How），而是只告诉程序我们想要的结果（What），让程序自己来解决过程（How）。当然SQL具体的细节还是用命令式的编程风格来实现的。 ","date":"2020-01-28","objectID":"/posts/introduction-of-cloud-native/:2:2","tags":["Cloud Native"],"title":"云原生概述","uri":"/posts/introduction-of-cloud-native/"},{"categories":["Cloud Native"],"content":"Play with Kubernetes ","date":"2020-01-28","objectID":"/posts/introduction-of-cloud-native/:3:0","tags":["Cloud Native"],"title":"云原生概述","uri":"/posts/introduction-of-cloud-native/"},{"categories":["Cloud Native"],"content":"创建Kubernetes集群 登陆Play with Kubernetes，启动第一个实例作为Master节点，在web终端上执行： 初始化master节点： kubeadm init --apiserver-advertise-address $(hostname -i) 输出如下： [node1 ~]$ kubeadm init --apiserver-advertise-address $(hostname -i) Initializing machine ID from random generator. [init] using Kubernetes version: v1.11.10 [preflight] running pre-flight checks [WARNING Service-Docker]: docker service is not active, please run 'systemctl start docker.service' [WARNING FileContent--proc-sys-net-bridge-bridge-nf-call-iptables]: /proc/sys/net/bridge/bridge-nf-call-iptables does not exist I1117 13:53:18.409493 885 kernel_validator.go:81] Validating kernel version I1117 13:53:18.409685 885 kernel_validator.go:96] Validating kernel config [preflight] The system verification failed. Printing the output from the verification: KERNEL_VERSION: 4.4.0-148-generic DOCKER_VERSION: 18.06.1-ce OS: Linux CGROUPS_CPU: enabled CGROUPS_CPUACCT: enabled CGROUPS_CPUSET: enabled CGROUPS_DEVICES: enabled CGROUPS_FREEZER: enabled CGROUPS_MEMORY: enabled [WARNING SystemVerification]: docker version is greater than the most recently validated version. Docker version: 18.06.1-ce. Max validated version: 17.03 [WARNING SystemVerification]: failed to parse kernel config: unable to load kernel module \"configs\": output - \"\", err - exit status 1 [preflight/images] Pulling images required for setting up a Kubernetes cluster [preflight/images] This might take a minute or two, depending on the speed of your internet connection [preflight/images] You can also perform this action in beforehand using 'kubeadm config images pull' [kubelet] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\" [kubelet] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\" [preflight] Activating the kubelet service [certificates] Generated ca certificate and key. [certificates] Generated apiserver certificate and key. [certificates] apiserver serving cert is signed for DNS names [node1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.0.18] [certificates] Generated apiserver-kubelet-client certificate and key. [certificates] Generated sa key and public key. [certificates] Generated front-proxy-ca certificate and key. [certificates] Generated front-proxy-client certificate and key. [certificates] Generated etcd/ca certificate and key. [certificates] Generated etcd/server certificate and key. [certificates] etcd/server serving cert is signed for DNS names [node1 localhost] and IPs [127.0.0.1 ::1] [certificates] Generated etcd/peer certificate and key. [certificates] etcd/peer serving cert is signed for DNS names [node1 localhost] and IPs [192.168.0.18 127.0.0.1 ::1] [certificates] Generated etcd/healthcheck-client certificate and key. [certificates] Generated apiserver-etcd-client certificate and key. [certificates] valid certificates and keys now exist in \"/etc/kubernetes/pki\" [kubeconfig] Wrote KubeConfig file to disk: \"/etc/kubernetes/admin.conf\" [kubeconfig] Wrote KubeConfig file to disk: \"/etc/kubernetes/kubelet.conf\" [kubeconfig] Wrote KubeConfig file to disk: \"/etc/kubernetes/controller-manager.conf\" [kubeconfig] Wrote KubeConfig file to disk: \"/etc/kubernetes/scheduler.conf\" [controlplane] wrote Static Pod manifest for component kube-apiserver to \"/etc/kubernetes/manifests/kube-apiserver.yaml\" [controlplane] wrote Static Pod manifest for component kube-controller-manager to \"/etc/kubernetes/manifests/kube-controller-manager.yaml\" [controlplane] wrote Static Pod manifest for component kube-scheduler to \"/etc/kubernetes/manifests/kube-scheduler.yaml\" [etcd] Wrote Static Pod manifest for a local etcd instance to \"/etc/kubernetes/manifests/etcd.yaml\" [init] waiting for the kubelet to boot up the control plane as Static Pods from directory \"/etc/kubernetes/manifests\" [init] this might take a minute or longer if the control plane images have to be pulled [apiclient] All control plane componen","date":"2020-01-28","objectID":"/posts/introduction-of-cloud-native/:3:1","tags":["Cloud Native"],"title":"云原生概述","uri":"/posts/introduction-of-cloud-native/"},{"categories":["Cloud Native"],"content":"创建nginx deployment [node1 ~]$ curl https://raw.githubusercontent.com/kubernetes/website/master/content/en/examples/application/nginx-app.yaml \u003e nginx-app.yaml % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 497 100 497 0 0 1252 0 --:--:-- --:--:-- --:--:-- 1255 [node1 ~]$ [node1 ~]$ kubectl apply -f nginx-app.yaml service/my-nginx-svc created deployment.apps/my-nginx created 此时查看nodes和pods： [node1 ~]$ kubectl get nodes NAME STATUS ROLES AGE VERSION node1 Ready master 29m v1.11.3 node2 Ready \u003cnone\u003e 11m v1.11.3 node3 Ready \u003cnone\u003e 11m v1.11.3 [node1 ~]$ [node1 ~]$ kubectl get pods NAME READY STATUS RESTARTS AGE my-nginx-67594d6bf6-2cbbz 1/1 Running 0 1m my-nginx-67594d6bf6-r2p6w 1/1 Running 0 1m my-nginx-67594d6bf6-vjqn4 1/1 Running 0 1m 参考来源： https://github.com/cncf/toc/blob/master/DEFINITION.md https://zh.wikipedia.org/wiki/%E5%BE%AE%E6%9C%8D%E5%8B%99 https://zh.wikipedia.org/zh-cn/%E5%AE%A3%E5%91%8A%E5%BC%8F%E7%B7%A8%E7%A8%8B https://zhuanlan.zhihu.com/p/34445114 https://labs.play-with-k8s.com/ ","date":"2020-01-28","objectID":"/posts/introduction-of-cloud-native/:3:2","tags":["Cloud Native"],"title":"云原生概述","uri":"/posts/introduction-of-cloud-native/"},{"categories":["Service Mesh"],"content":"什么是服务网格？ 服务网格是用于处理服务间通信的专用基础设施层。它负责通过包含现代云原生应用程序的复杂服务拓扑来可靠地传递请求。实际上，服务网格通常通过一组轻量级网络代理来实现，这些代理与应用程序代码一起部署，而不需要感知应用程序本身。 ","date":"2020-01-28","objectID":"/posts/introduction-of-service-mesh/:1:0","tags":["Service Mesh","Istio"],"title":"Service Mesh概述","uri":"/posts/introduction-of-service-mesh/"},{"categories":["Service Mesh"],"content":"服务网格的特点 服务网格有如下几个特点： 应用程序间通讯的中间层 轻量级网络代理 应用程序无感知 解耦应用程序的重试/超时、监控、追踪和服务发现 ","date":"2020-01-28","objectID":"/posts/introduction-of-service-mesh/:1:1","tags":["Service Mesh","Istio"],"title":"Service Mesh概述","uri":"/posts/introduction-of-service-mesh/"},{"categories":["Service Mesh"],"content":"理解服务网格 如果用一句话来解释什么是服务网格，可以将它比作是应用程序或者说微服务间的 TCP/IP，负责服务之间的网络调用、限流、熔断和监控。 服务网格的架构如下图所示： ","date":"2020-01-28","objectID":"/posts/introduction-of-service-mesh/:1:2","tags":["Service Mesh","Istio"],"title":"Service Mesh概述","uri":"/posts/introduction-of-service-mesh/"},{"categories":["Service Mesh"],"content":"为何使用服务网格？ 服务网格并没有给我们带来新功能，它是用于解决其他工具已经解决过的问题，只不过这次是在云原生的 Kubernetes 环境下的实现。 在传统的 MVC 三层 Web 应用程序架构下，服务之间的通讯并不复杂，在应用程序内部自己管理即可，但是在现今的复杂的大型网站情况下，单体应用被分解为众多的微服务，服务之间的依赖和通讯十分复杂，出现了 twitter 开发的 Finagle、Netflix 开发的 Hystrix 和 Google 的 Stubby 这样的 “胖客户端” 库，这些就是早期的服务网格，但是它们都仅适用于特定的环境和特定的开发语言，并不能作为平台级的服务网格支持。 在云原生架构下，容器的使用给予了异构应用程序的更多可行性，Kubernetes 增强的应用的横向扩容能力，用户可以快速的编排出复杂环境、复杂依赖关系的应用程序，同时开发者又无须过多关心应用程序的监控、扩展性、服务发现和分布式追踪这些繁琐的事情而专注于程序开发，赋予开发者更多的创造性。 ","date":"2020-01-28","objectID":"/posts/introduction-of-service-mesh/:1:3","tags":["Service Mesh","Istio"],"title":"Service Mesh概述","uri":"/posts/introduction-of-service-mesh/"},{"categories":["Service Mesh"],"content":"服务网格架构 服务网格中分为控制平面和数据平面，当前流行的两款开源的服务网格 Istio 和 Linkerd 实际上都是这种架构，只不过 Istio 的划分更清晰，而且部署更零散，很多组件都被拆分，控制平面中包括 Mixer、Pilot、Citadel，数据平面默认是用 Envoy；而 Linkerd 中只分为 Linkerd 做数据平面，namerd 作为控制平面。 控制平面的特点 不直接解析数据包 与数据平面中的代理通信，下发策略和配置 负责网络行为的可视化 通常提供 API 或者命令行工具可用于配置版本化管理，便于持续集成和部署 数据平面的特点 通常是按照无状态目标设计的，但实际上为了提高流量转发性能，需要缓存一些数据，因此无状态也是有争议的 直接处理入站和出站数据包，转发、路由、健康检查、负载均衡、认证、鉴权、产生监控数据等 对应用来说透明，即可以做到无感知部署 ","date":"2020-01-28","objectID":"/posts/introduction-of-service-mesh/:2:0","tags":["Service Mesh","Istio"],"title":"Service Mesh概述","uri":"/posts/introduction-of-service-mesh/"},{"categories":["Service Mesh"],"content":"服务网格的实现模式 Service Mesh 架构示意图： ","date":"2020-01-28","objectID":"/posts/introduction-of-service-mesh/:2:1","tags":["Service Mesh","Istio"],"title":"Service Mesh概述","uri":"/posts/introduction-of-service-mesh/"},{"categories":["Service Mesh"],"content":"Istio 架构解析 Istio 是独立于平台的，可以在 Kubernetes 、 Consul 、虚拟机上部署的服务 Istio 的组成 Envoy：智能代理、流量控制 Pilot：服务发现、流量管理 Mixer：访问控制、遥测 Citadel：终端用户认证、流量加密 Galley（1.1新增）：验证、处理和分配配置 Service mesh 关注的方面 可观察性 安全性 可运维性 可拓展性 Istio 的策略执行组件可以扩展和定制，同时也是可拔插的 Istio 在数据平面为每个服务中注入一个 Envoy 代理以 Sidecar 形式运行来劫持所有进出服务的流量，同时对流量加以控制，通俗的讲就是应用程序你只管处理你的业务逻辑，其他的事情 Sidecar 会汇报给 Istio 控制平面处理 应用程序只需关注于业务逻辑（这才能生钱）即可，非功能性需求交给 Istio 设计目标 最大化透明度 可扩展性 可移植性 策略一致性 ","date":"2020-01-28","objectID":"/posts/introduction-of-service-mesh/:2:2","tags":["Service Mesh","Istio"],"title":"Service Mesh概述","uri":"/posts/introduction-of-service-mesh/"},{"categories":["Service Mesh"],"content":"从边车模式到 Service Mesh 什么是边车模式 Deploy components of an application into a separate process or container to provide isolation and encapsulation. — Sidecar pattern 边车模式设计 有两种方法来实现边车模式： 通过 SDK、Lib 等软件包的形式，在开发时引入该软件包依赖，使其与业务服务集成起来。 以 Sidecar 的形式，在运维的时候与应用服务集成在一起。 边车模式解决了什么问题 控制与逻辑分离的问题 业务代码只需要关心其复杂的业务逻辑 日志记录、监控、流量控制、服务注册、服务发现、服务限流、服务熔断、鉴权、访问控制等交给边车 解决服务之间调用越来越复杂的问题 随着分布式架构越来越复杂和微服务越拆越细，我们越来越迫切的希望有一个统一的控制面来管理我们的微服务，来帮助我们维护和管理所有微服务 从边车模式到 Service Mesh 遵循边车模式进行实践从很早以前就开始了，开发人员一直试图将服务治理等通用功能提取成一个标准化的 Sidecar ，通过 Sidecar 代理来与其他系统进行交互，这样可以大大简化业务开发和运维。而随着分布式架构和微服务被越来越多的公司和开发者接受并使用，这一需求日益凸显。这就是 Service Mesh 服务网格诞生的契机，它是 CNCF（Cloud Native Computing Foundation，云原生基金会）目前主推的新一代微服务架构。 Service Mesh 将底层那些难以控制的网络通讯统一管理，诸如：流量管控，丢包重试，访问控制等。而上层的应用层协议只需关心业务逻辑即可。Service Mesh 是一个用于处理服务间通信的基础设施层，它负责为构建复杂的云原生应用传递可靠的网络请求。 ","date":"2020-01-28","objectID":"/posts/introduction-of-service-mesh/:2:3","tags":["Service Mesh","Istio"],"title":"Service Mesh概述","uri":"/posts/introduction-of-service-mesh/"},{"categories":["Service Mesh"],"content":"Kubernetes vs Service Mesh Kubernetes 管理的对象是 Pod，Service Mesh 中管理的对象是 Service。 Kubernetes 的本质是应用的生命周期管理，具体来说就是部署和管理（扩缩容、自动恢复、发布）。 Kubernetes 为微服务提供了可扩展、高弹性的部署和管理平台。 Service Mesh 的基础是透明代理，通过 sidecar proxy 拦截到微服务间流量后再通过控制平面配置管理微服务的行为。 Service Mesh 将流量管理从 Kubernetes 中解耦，Service Mesh 内部的流量无需 kube-proxy 组件的支持，通过为更接近微服务应用层的抽象，管理服务间的流量、安全性和可观察性。 Service Mesh 是对 Kubernetes 中的 service 更上层的抽象，它的下一步是 serverless。 本文是针对ServiceMesher社区系列文章而整理的学习笔记，文章地址：https://www.servicemesher.com/istio-handbook/intro/service-mesh-the-microservices-in-post-kubernetes-era.html ","date":"2020-01-28","objectID":"/posts/introduction-of-service-mesh/:3:0","tags":["Service Mesh","Istio"],"title":"Service Mesh概述","uri":"/posts/introduction-of-service-mesh/"},{"categories":["后台开发"],"content":"1 背景 由于后端的微服务拆分，客户端通常需要请求多个服务获取所需数据。 不同客户端所需要的数据不一样。例如，PC需要的数据通常比移动端更加详细。 不同客户端网络环境差异大。例如，WAN vs LAN，移动网络 vs 非移动网络。 服务端实例的地址信息（IP + port）会动态更新。 微服务的拆分逻辑会变化，这种变化应该应该对客户端透明。 不同的服务可能采用不同的协议，有些协议是非web的。 ","date":"2020-01-27","objectID":"/posts/introduction-of-api-gateway/:1:0","tags":["API网关"],"title":"API网关概述","uri":"/posts/introduction-of-api-gateway/"},{"categories":["后台开发"],"content":"2 什么是API网关？ API网关接收客户端的所有请求，并将请求路由到相应的后端服务，并提供接口聚合和协议转换。通常来说，API网关通过调用多个后端服务，并聚合结果的方式处理请求。它可将web协议转化为非web的内部后台协议。 核心功能： 服务发现： 负载均衡：以某种算法分摊系统压力。 服务熔断：直接返回失败或者执行降价逻辑，防止雪崩。 流量控制：防止短时间内大量请求转发到后台压垮服务器。 认证鉴权：验证客户端的请求是否被授权。 灰度发布： 其他功能： 协议转换：web协议转非Web协议。 参数校验：对入参设置校验规则，由网关根据规则对无效请求进行过滤。 API管理：包括 API 的创建、测试、发布、下线、版本切换等。 监控告警：监控API请求次数、API调用延迟和API错误信息。 SDK生成： ","date":"2020-01-27","objectID":"/posts/introduction-of-api-gateway/:2:0","tags":["API网关"],"title":"API网关概述","uri":"/posts/introduction-of-api-gateway/"},{"categories":["后台开发"],"content":"3 实现方式 将API网关作为客户端的唯一接入点。API网关主要有两种类型： one-size-fits-all网关 Backends for frontends网关 ","date":"2020-01-27","objectID":"/posts/introduction-of-api-gateway/:3:0","tags":["API网关"],"title":"API网关概述","uri":"/posts/introduction-of-api-gateway/"},{"categories":["后台开发"],"content":"3.1 One-size-fits-all网关 简单地将请求路由到相应服务。将请求扇出到多个后端服务。 ","date":"2020-01-27","objectID":"/posts/introduction-of-api-gateway/:3:1","tags":["API网关"],"title":"API网关概述","uri":"/posts/introduction-of-api-gateway/"},{"categories":["后台开发"],"content":"3.2 Backends for fronts网关 为每种客户端暴露不同的API。为每种客户端设计一个API网关，每个API网关为其客户端提供一种API。 ","date":"2020-01-27","objectID":"/posts/introduction-of-api-gateway/:3:2","tags":["API网关"],"title":"API网关概述","uri":"/posts/introduction-of-api-gateway/"},{"categories":["后台开发"],"content":"4 优点 使后端的微服务拆分对客户端透明。 客户端无需关心后端服务的实例地址（IP + port）。 可为每个客户端提供最优API。 减少请求次数。 简化客户端的逻辑（由调用多个后台服务变为只调用API网关）。 可将标准的Web API协议转化为任意的后端协议。 ","date":"2020-01-27","objectID":"/posts/introduction-of-api-gateway/:4:0","tags":["API网关"],"title":"API网关概述","uri":"/posts/introduction-of-api-gateway/"},{"categories":["后台开发"],"content":"5 缺点 增加复杂性。增加了API网关模块，带来了额外的开发、部署、管理成本。 增加响应时间。调用链路多了一跳（API网关）。 Issues: How implement the API gateway? event-driven/reactive approach is the best if it must scale to handle high loads. 参考来源： https://microservices.io/patterns/apigateway.html https://www.nginx.com/learn/api-gateway/ https://aws.amazon.com/cn/api-gateway/features/ https://cloud.tencent.com/document/product/628/11755 ","date":"2020-01-27","objectID":"/posts/introduction-of-api-gateway/:5:0","tags":["API网关"],"title":"API网关概述","uri":"/posts/introduction-of-api-gateway/"},{"categories":["其他"],"content":"安装Node $ brew install node ","date":"2020-01-27","objectID":"/posts/how-to-create-a-hexo-blog/:1:0","tags":["hexo"],"title":"如何通过GitHub+Hexo搭建博客","uri":"/posts/how-to-create-a-hexo-blog/"},{"categories":["其他"],"content":"安装Hexo $ npm install -g hexo ","date":"2020-01-27","objectID":"/posts/how-to-create-a-hexo-blog/:2:0","tags":["hexo"],"title":"如何通过GitHub+Hexo搭建博客","uri":"/posts/how-to-create-a-hexo-blog/"},{"categories":["其他"],"content":"初始化Hexo $ hexo init ","date":"2020-01-27","objectID":"/posts/how-to-create-a-hexo-blog/:3:0","tags":["hexo"],"title":"如何通过GitHub+Hexo搭建博客","uri":"/posts/how-to-create-a-hexo-blog/"},{"categories":["其他"],"content":"生成网页文件和开启服务器 $ hexo g $ hexo s ","date":"2020-01-27","objectID":"/posts/how-to-create-a-hexo-blog/:4:0","tags":["hexo"],"title":"如何通过GitHub+Hexo搭建博客","uri":"/posts/how-to-create-a-hexo-blog/"},{"categories":["其他"],"content":"关联Github 修改_config.yml，修改deploy为： deploy: type: 'git' repository: https://github.com/xzygis/xzygis.github.io.git branch: master 生成静态文件并上传Github $ hexo g $ hexo d 若执行hexo d出错则执行npm install hexo-deployer-git --save。 执行hexo d会提示输入用户名密码。 ","date":"2020-01-27","objectID":"/posts/how-to-create-a-hexo-blog/:5:0","tags":["hexo"],"title":"如何通过GitHub+Hexo搭建博客","uri":"/posts/how-to-create-a-hexo-blog/"},{"categories":["其他"],"content":"配置next主题 在blog目录下执行 git clone --branch v5.1.4 https://github.com/iissnan/hexo-theme-next themes/next 修改_config.yml，设置theme为next。 ","date":"2020-01-27","objectID":"/posts/how-to-create-a-hexo-blog/:6:0","tags":["hexo"],"title":"如何通过GitHub+Hexo搭建博客","uri":"/posts/how-to-create-a-hexo-blog/"}]